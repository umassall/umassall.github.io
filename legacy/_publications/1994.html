<ul>
<p><li>Singh, S. P. (1994)
<BR><b>Learning to Solve Markovian Decision Processes</b><BR>
Ph.D Thesis
<BR>[ <a href="pubs/1994/singh_THESIS94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P., Jaakkola, T., and Jordan, M. (1994)
<BR><b>Reinforcement Learning With Soft State Aggregation</b><BR>
NIPS-7 
<BR>[ <a href="pubs/1994/singh_jj_NIPS94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P. (1994)
<BR><b>Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes</b><BR>
AAAI-94
<BR>[ <a href="pubs/1994/singh_AAAI94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P., Jaakkola, T., and Jordan, M. (1994)
<BR><b>Learning Without State-Estimation in Partially Observable Markovian Decision Processes</b><BR>
ML-94
<BR>[ <a href="pubs/1994/singh_jj_ML94.ps.Z">zipped ps</a> ]

<p><li>Sutton, R. S., and Singh, S. P. (1994)
<BR><b>On Step-Size and Bias in Temporal-Difference Learning</b><BR>
Eighth Yale Workshop
<BR>[ <a href="pubs/1994/sutton_s_YALE94.ps.Z">zipped ps</a> ]

<p><li>Jaakkola, T., Jordan, M., and Singh, S. P. (1994)
<BR><b>On the Convergence of Stochastic Iterative Dynamic Programming Algorithms</b><BR>
Neural Computation
<BR>[ <a href="pubs/1994/jaakkola_js_NC94.ps.Z">zipped ps</a> ]

<p><li>J. T. Buckingham, J. C. Houk, and A. G. Barto (1994)
<BR><b>Controlling a nonlinear spring-mass system with a cerebellar model</b><BR>
8th Yale Workshop on Adaptive and Learning Systems,
Yale University, June 1994.  pp. 1-6.

<p><li>S. J. Bradtke, A. G. Barto, and B. E. Ydstie (1994)
<BR><b>A reinforcement learning method for direct adaptive linear quadratic control</b><BR>
8th Yale Workshop on Adaptive and Learning Systems,
Yale University, June 1994.  pp. 85-96.

<p><li>V. Gullapalli and A. Barto (1994)
<BR><b>Convergence of indirect adaptive asynchronous value iteration algorithms</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 695-702.

<p><li>A. Barto and M. Duff (1994)
<BR><b>Monte Carlo matrix inversion and reinforcement learning</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 687-694.

<p><li>S. P. Singh, A. G. Barto, R. Grupen, and C. Connolly (1994)
<BR><b>Robust reinforcement learning in motion planning</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994.  pp. 655-662.

<p><li>V. Gullapalli, A. G. Barto, and R. A. Grupen (1994)
<BR><b>Learning admittance mappings for force-guided assembly</b><BR>
Proceedings of the 1994 International Conference on Robotics and Automation,
1994, pp. 2633-2638.

<p><li>V. Gullapalli, J. A. Franklin, and H. Benbrahim (1994)
<BR><b>Acquiring robot skills via reinforcement learning</b><BR>
IEEE Control Systems Special Issue on Robotics: Capturing Natural Motion, 4(1): 13-24, Feb. 1994.

<p><li>Grupen RA, Coelho, J. A., Connolly, C. I., Gullapalli, V., Huber, M., and
Souccar, K. (1994)
<BR><b>Toward Physical Interaction and Manipulation: Screwing in a Light Bulb</b><BR>
AAAI 1994 Spring Symposium on Physical Interaction and Manipulation. 
<BR>[ <a href="pubs/1994/grupen_ccghs_AAAI94.ps.Z">zipped ps</a> ](large file)

<p><li>T. W. Sandholm and R. H. Crites (1994)
<BR><b>Multiagent Reinforcement Learning in the Iterated Prisoner's Dilemma</b><BR>
Submitted to Biosystems Journal, November 1994.

<p><li>S. J. Bradtke and A. G. Barto (1994)
<BR><b>New Algorithms for Temporal Difference Learning</b><BR>
Machine Learning, 108, Special Issue on Reinforcement Learning.

<p><li>Singh, S. P., and
Yee, R. C. (1994)
<BR><b>An Upper Bound on the Loss from Approximate Optimal-Value Functions</b><BR>
Machine Learning
<BR>[ <a href="pubs/1994/singh_y_ML94.ps.Z">zipped ps</a> ]

<p><li>Barto, A. G. (1994)
<BR><b>Reinforcement Learning Control</b><BR>
Current Opinion in Neurobiology, 4:888-893, 1994.

<p><li>V. Gullapalli (1994)
<BR><b>Skillful Control Under Uncertainty via Direct Reinforcement Learning</b><BR>
(Submitted to Robotics and Autonomous Systems.)

<p><li> N. Berthier, R. Clifton, V. Gullapalli, D. McCall, and D. Rubin (1994)
<BR><b>Visual information and object size in the control of reaching</b><BR>
(Submitted.)

<p><li>V. Gullapalli (1994)
<BR><b>Direct associative reinforcement learning methods for dynamic systems control</b><BR>
(Submitted to Neurocomputing.)

<p><li>S. J. Bradtke (1994)
<BR><b>Incremental Dynamic Programming for On-Line Adaptive Optimal Control</b><BR>
(Ph.D. Thesis) CMPSCI Technical Report 94-62, University of Massachusetts,
August 1994.

<p><li>Barto, A. G. (1994)
<BR><b>Learning as hillclimbing in weight space</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>Barto, A. G. (1994)
<BR><b>Reinforcement learning in motor control</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>Barto, A. G.(1994)
<BR><b>Reinforcement Learning</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>M. Duff (1994)
<BR><b>Solving Bellman's Equation by the method of continuity</b><BR>  
Proceedings of the 1994 American Control Conference, Baltimore, June 1994.

<p><li>S. J. Bradtke, B. E. Ydstie, and A. G. Barto (1994)
<BR><b>Adaptive linear quadratic control using policy iteration</b><BR>
CMPSCI Technical Report 94-49, University of Massachusetts, June 1994.
Submitted to IEEE Transactions on Automatic Control, April 1994.

<p><li>S. Bradtke and M. Duff (1994)
<BR><b>Reinforcement learning methods for continuous-time Markov decision problems</b><BR>
7th Annual Conference on Neural Information Processing Systems (NIPS 7),
November 1994.
</ul>