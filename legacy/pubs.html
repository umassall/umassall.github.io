<HTML>
<HEAD>
<TITLE>Publications - Autonomous Learning Laboratory</TITLE>
<link rel="stylesheet" type="text/css" href="styles.css" />
</HEAD>

<BODY>
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-35723838-1']);
    _gaq.push(['_trackPageview']);
    (function () {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    function toggle_visibility(id) {
      var style = document.getElementById(id).style;
      style.display = (style.display == 'block') ? 'none' : 'block';
    }
  </script>
  <A name="top"></A>

  <div id="main">

    <div id="header">
      <A HREF="../index.html">
        <IMG SRC="img/all_horiznamesm.gif" width=650 height=72 alt="ALL top" />
      </A>
      <A HREF="http://www.umass.edu">
        <img src="img/UMass_seal_color.jpg" alt="UMass" />
      </A>
    </div>

    <div id="main_inner">

      <!-- Killed by cnota. This page is being linked
to from the new site, so we didn't want to allow any navigation. 
-->
      <!-- <ul id="navbar">
  <li><a href="index.shtml">Home</a></li>
  <li><a href="people.shtml">People</a></li>
  <li><a href="research.shtml" onclick="toggle_visibility('subnavbar');">Research</a></li>
  <ul id="subnavbar">
    <li id="subnav_rl"><a href="rlearning.shtml">Reinforcement Learning</a></li>
    <li id="subnav_manifold"><a href="manifold.shtml">Manifold Learning</a></li>
    <li id="subnav_spectroscopy"><a href="spectroscopy.shtml">Spectroscopy</a></li>
    <li id="subnav_code"><a href="https://github.com/all-umass" target="_blank">Code Repository</a></li>
  </ul>
  <li><a href="/pubs".shtml">Publications</a></li>
  <li><a href="contact.shtml">Contact</a></li>
  <li><a href="http://all.cs.umass.edu/wiki/">Restricted Access</a></li>
</ul> -->

      <div id="content">

<H1>Publications</H1>

<ul id="pub_books">
<li><A HREF="#3"><IMG SRC="img/BookJPGs/PVFbook.jpg"></A></li>
<li><A HREF="#2"><IMG SRC="img/BookJPGs/HandbookLADP.jpg"></A></li>
<li><A HREF="#1"><IMG SRC="img/BookJPGs/RLbook.jpg"></A></li>
<li><A HREF="http://www.springer.com/engineering/robotics/book/978-0-7923-9365-8">
    <IMG SRC="img/BookJPGs/RobotLearningbook.jpg"></A></li>
</ul>

<p>
The following is a list of publications in reverse chronological order.
Many of the references have links that allow you access to that publication.
Please <a href="contact.shtml">contact the lab</a>
or <a href="people.shtml">a specific author</a> if you have any questions.
Links associated with a particular reference (e.g., conference)
were current at the time of publication.
</p>

<div id="pub_years">
  <a href="#2017">2017</a>
  <a href="#2016">2016</a>
  <a href="#2015">2015</a>
  <a href="#2014">2014</a>
  <a href="#2013">2013</a>
  <a href="#2012">2012</a>
  <a href="#2011">2011</a>
  <a href="#2010">2010</a>
  <a href="#2009">2009</a>
  <a href="#2008">2008</a>
  <a href="#2007">2007</a>
  <a href="#2006">2006</a>
  <a href="#2005">2005</a>
  <a href="#2004">2004</a>
  <a href="#2003">2003</a>
  <a href="#2002">2002</a>
  <a href="#2001">2001</a>
  <a href="#2000">2000</a>
  <a href="#1999">1999</a>
  <a href="#1998">1998</a>
  <a href="#1997">1997</a>
  <a href="#1996">1996</a>
  <a href="#1995">1995</a>
  <a href="#1994">1994</a>
  <a href="comp.html">before 1994</a>
</div>

<div id="pub_content">

<hr>
<A name="2017"></A>
<h3>2017</h3>
<ul>

<p><li>Durugkar, I., Gemp, I., Mahadevan, S.
<br><b>Generative Multi-Adversarial Networks</b>
<br>In International Conference on Learning Representations, 2017.
<br>[ <a href="https://arxiv.org/pdf/1611.01673.pdf">pdf</a> ]

<p><li>Guo, X., Klinger, T., Rosenbaum, C., Bigus, J. P., Campbell, M., Kawas, B., Talamadupula, K., Tesauro, G., Singh, S.
<br><b>Learning to Query, Reason, and Answer Questions On Ambiguous Texts</b>
<br>In International Conference on Learning Representations, 2017.
<br>[ <a href="https://openreview.net/pdf?id=rJ0-tY5xe">pdf</a> ]

</ul>


<hr>
<A name="2016"></A>
<h3>2016</h3>
<ul>

<p><li>Dernbach, S., Taft, N., Kurose, J., Weinsberg, U., Diot, C., and Ashkan, A.
<br><b>Cache Content-Selection Policies for Streaming Video Services</b>
<br>Proceedings of the IEEE International Conference on Computer Communications, 2016.
<br>[ <a href="https://people.cs.umass.edu/~dernbach/pubs/cachecontent.pdf">pdf</a> ]

</ul>


<hr>
<A name="2015"></A>
<h3>2015</h3>
<ul>

<p><li>Wang, L., Feng, M., Zhou, B., Xiang, B. and Mahadevan, S.
<br><b>Efficient hyper-parameter optimization for NLP applications</b>
<br>Empirical Methods in Natural language processing (EMNLP), Portugal, September 2015.
<br>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/emnlp2015-new.pdf">pdf</a> ]

<p><li>Mahadevan, S. and Chandar, S.
<br><b>Reasoning about Linguistic Regularities in Word Embeddings using Matrix Manifolds</b>
<br>Arxiv, July 2015.
<br>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/word-emb-grassmann.pdf">pdf</a> ]

<p><li>Theocharous, G., Thomas, P. and Ghavamzadeh, M.
<BR><b>Personalized Ad Recommendation Systems for Life-Time Value Optimization with Guarantees</b>
<BR>Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2015.
<BR>[ <a href="../pubs/2015/Theochar2015a.pdf">pdf</a> ]

<p><li>Giguere, S., Carey, C., Boucher, T., Mahadevan, S. and Dyar, M.D.
<BR><b>An Optimization Perspective on Baseline Removal for Spectroscopy</b>
<BR>Proceedings of the 5th IJCAI Workshop on Artificial Intelligence in Space, 2015.

<p><li>Boucher, T., Carey, C., Giguere, S., Mahadevan, S., Dyar, M.D., Clegg, S. and Wiens, R.
<BR><b>Manifold Learning for Regression of Mars Spectra</b>
<BR>Proceedings of the 5th IJCAI Workshop on Artificial Intelligence in Space, 2015.

<p><li>Carey, C., Boucher, T., Giguere, S., Mahadevan, S. and Dyar, M.D.
<BR><b>Automatic Whole-Spectrum Matching</b>
<BR>Proceedings of the 5th IJCAI Workshop on Artificial Intelligence in Space, 2015.

<p><li>Theocharous, G., Thomas, P. and Ghavamzadeh, M.
<BR><b>Ad Recommendation Systems for Life-Time Value Optimization</b>
<BR>TargetAd 2015: Ad Targeting at Scale, at the World Wide Web Conference, 2015.
<BR>[ <a href="../pubs/2015/Theochar2015b.pdf">pdf</a> ]

<p><li>Liu, B., Liu, J., Ghavamzadeh, M., Mahadevan, S., and Petrik, M.
<BR><b>Finite-Sample Analysis of Proximal Gradient TD Algorithms</b>
<BR>Proceedings of the 31th Conference on Uncertainty in Artificial Intelligence (UAI), 2015.
<BR>[ <a href="http://people.cs.umass.edu/~boliu/c-2015-uai.pdf">pdf</a> ]

<p><li>Thomas, P., Theocharous, G. and Ghavamzadeh, M.
<BR><b>High Confidence Policy Improvement</b>
<BR>Proceedings of the 32nd International Conference on Machine Learning (ICML), 2015.
<BR>[ <a href="http://jmlr.org/proceedings/papers/v37/thomas15.pdf">pdf</a> ]

<p><li>Boucher, T., Ozanne, M., Carmosino, M., Dyar, M.D., Mahadevan, S., Breves, E., Lepore, K. and Clegg, S.
<BR><b>A study of machine learning regression methods for major elemental analysis of rocks using laser-induced breakdown spectroscopy</b>
<BR>Spectrochimica Acta Part B, vol. 107, pp. 1-10, 2015.
<BR>[ <a href="http://www.sciencedirect.com/science/article/pii/S0584854715000518">pdf</a> ]

<p><li>Gemp, I. and Mahadevan, S.
<BR><b>Finding Equilibria in Large Games using Variational Inequalities</b>
<BR>AAAI Spring Symposium on Applied Computational Game Theory, Stanford, CA, 2015.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/VIGameTheory.pdf">pdf</a> ]

<p><li>Boucher, T., Carey C., Mahadevan, S., and Dyar, M.D.
<BR><b>Aligning Mixed Manifolds</b>
<BR>Proceedings of the AAAI Conference, Austin, Texas, 2015.
<BR>[ <a href="https://people.cs.umass.edu/~boucher/downloads/boucher_aaai15.pdf">pdf</a> ]

<p><li>Thomas, P., Theocharous, G., and Ghavamzadeh, M.
<BR><b>High Confidence Off-Policy Evaluation</b>
<BR>Proceedings of the AAAI Conference, Austin, Texas, 2015.
<BR>[ <a href="http://psthomas.com/papers/Thomas2015.pdf">pdf</a> ]

<p><li>Gemp, I. and Mahadevan, S.
<BR><b> Solving Large Scale Substainable Supply Chain Networks using Variational Inequalities</b>
<BR>AAAI Workshop on Computational Sustainability, Austin, TX, 2015.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/VISustainability.pdf">pdf</a> ]

</ul>


<hr>
<A name="2014"></A>
<h3>2014</h3>
<ul>

<p><li>da Silva, B.C., Konidaris, G., and Barto, A.G.
<BR><b>Active Learning of Parameterized Skills</b>
<BR>Proceedings of the 31st International Conference on Machine Learning (ICML 2014). Beijing, China, 2014.
<BR>[ <a href="https://people.cs.umass.edu/~bsilva/active_paramSkill_icml2014.pdf">pdf</a> ]

<p><li>Thomas, P. S.
<BR><b>GeNGA: A Generalization of Natural Gradient Ascent with Positive and Negative Convergence Results</b>
<BR>Proceedings of the 31st International Conference on Machine Learning (ICML 2014). Beijing, China, 2014.
<BR>[ <a href="http://psthomas.com/papers/Thomas2014.pdf">pdf</a> ]

<p><li>Thomas, P. S.
<BR><b>Bias in Natural Actor-Critic Algorithms</b>
<BR>Proceedings of the 31st International Conference on Machine Learning (ICML 2014). Beijing, China, 2014.
<BR>[ <a href="http://psthomas.com/papers/Thomas2014b.pdf">pdf</a> ]

<p><li>da Silva, B.C., Baldassarre, G., Konidaris, G., and Barto, A.G.
<BR><b>Learning Parameterized Motor Skills on a Humanoid Robot</b>
<BR>Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA 2014). Hong Kong, China, 2014.
<BR>[ <a href="https://people.cs.umass.edu/~bsilva/paramSkill_humanoid_icra2014.pdf">pdf</a> |
<a href="https://www.youtube.com/watch?v=BLt3GmjDN1o">video</a> ]

<p><li>Mahadevan, S., Liu, B., Thomas, P. S., Dabney, W., Giguere, S., Jacek, N., Gemp, I., and Liu, J.
<BR><b>Proximal Reinforcement Learning: A New Theory of Sequential Decision Making in Primal-Dual Spaces</b>
<BR>Arxiv, May 26, 2014.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/Arxiv-RL-paper-May-26-7-09-pm.pdf">pdf</a> |
<a href="http://arxiv.org/abs/1405.6757">arxiv</a> ]

<p><li>Carey, C. and Mahadevan, S.
<BR><b>Manifold Spanning Graphs</b>
<BR>Proceedings of the 28th Conference on Artificial Intelligence (AAAI), 2014.
<BR>[ <a href="http://people.cs.umass.edu/~ccarey/pubs/msg.pdf">pdf</a> ]

<p><li>Dabney, W., and Thomas, P. S.
<BR><b>Natural Temporal Difference Learning</b>
<BR>Proceedings of the 28th Conference on Artificial Intelligence (AAAI), 2014.
<BR>[ <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8568/8913">pdf</a> ]

</ul>


<hr>
<A name="2013"></A>
<h3>2013</h3>
<ul>

<p><li>Thomas, P. S., Dabney, W., Mahadevan, S., and Giguere, S.
<BR><b>Projected natural actor-critic.</b>
<BR>Advances in Neural Information Processing Systems 26, 2013.
<BR>[ <a href="http://psthomas.com/papers/Thomas2013a.pdf">pdf</a> ]

<p><li>Shah, A., Barto, A.G., and Fagg, A.H.
<BR><b>A Dual Process Account of Coarticulation in Motor Skill Acquisition.</b>
<BR><a href="http://www.tandfonline.com/toc/vjmb20/current">Journal of Motor Behavior</a>, volume 45, pages 531--549.
<BR>[ <a href="http://dx.doi.org/10.1080/00222895.2013.837423">DOI link</a> ]

<p><li>Wang, C. and Mahadevan, S.
<BR><b>Manifold Alignment Preserving Global Geometry.</b>
<BR>Proceedings of the IJCAI Conference, August 3-9, 2013, Beijing, China.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/IJCAI-2013-Global.pdf">pdf</a> ]

<p><li>Mahadevan, S., Giguere, S., and Jacek, N.
<BR><b>Basis Adaptation for Sparse Nonlinear Reinforcement Learning.</b>
<BR>Proceedings of the AAAI Conference, July 14-18, 2013, Bellevue, Washington.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/aaai2013-mdba.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S.
<BR><b>Multiscale Manifold Learning.</b>
<BR>Proceedings of the AAAI Conference, July 14-18, 2013, Bellevue, Washington.
<BR>[ <a href="http://www.cs.umass.edu/~mahadeva/papers/AAAI-2013-DP.pdf">pdf</a> ]

<p><li>Kuindersma, S., Grupen, R., and Barto, A.
<BR><b>Variable risk control via stochastic optimization.</b>
<BR>The International Journal of Robotics Research, June 2013, vol. 32 no. 7 806-825.
<BR>[ <a href="../pubs/2013/kuindersma_g_b_ijrr13.pdf">pdf</a> ]

</ul>


<hr>
<A name="2012"></A>
<h3>2012</h3>

<ul>
<p><li>Thomas, P. and Barto, A. G.
<BR><b>Motor primitive discovery</b>
<BR>Proceedings of the IEEE Conference on Development and Learning and Epigenetic Robotics, 2012.
<BR>[ <a href="http://psthomas.com/papers/Thomas2012a.pdf">pdf</a> ]

<p><li>Liu, B., Mahadevan, S., and Liu, J.
<BR><b>Regularized Off-Policy TD-Learning.</b>
<BR>Proceedings of the Conference on Neural Information Processing Systems (NIPS), December 1-3, 2012, Lake Tahoe, CA.
<BR>[ <a href="/pubs"/2012/liu_regularizedOffPolicy_NIPS2012.pdf">pdf</a> ]

<p><li>S. Niekum, S. Osentoski, G.D. Konidaris, and Andrew G. Barto.
<br><b>Learning and Generalization of Complex Tasks from Unstructured Demonstrations.</b>
<br>IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 5239-5246, October 2012.
<br>[ <a href="http://www.cs.umass.edu/~sniekum/pubs/NiekumIROS2012.pdf">pdf</a> ]

<p><li>Mahadevan, S. and Liu, B.
<BR><b>Sparse Q-learning with Mirror Descent.</b> 
<BR>Proceedings of the Conference on Uncertainty in AI (UAI), August 15-17, 2012, Catalina Island, CA.
<BR>[ <a href="/pubs"/2012/mahadevan_sparseQL_UAI2012.pdf">pdf</a> ]


<p><li>Vu, H., Carey, C., and Mahadevan, S.
<BR><b>Manifold Warping: Manifold Alignment over Time.</b> 
<BR>Proceedings of the 26th Conference on Artificial Intelligence (AAAI), July 22-26, 2012, Toronto, Canada.
<BR>[ <a href="/pubs"/2012/vu_manifoldWarping_AAAI2012.pdf">pdf</a> ]


<p><li>Wang, C. and Mahadevan, S.
<BR><b>Manifold Alignment Preserving Global Geometry.</b> 
<BR>Technical Report, UMass Computer Science Department UM-CS-2012-031, 2012.
<BR>[ <a href="/pubs"/2012/wang_manifoldAlign_techRep2012.pdf">pdf</a> ]


<p><li>Wang, C., Liu, B., Vu, H., and Mahadevan, S.
<BR><b>Sparse Manifold Alignment.</b> 
<BR>Technical Report, UMass Computer Science UM-2012-030, 2012.
<BR>[ <a href="/pubs"/2012/wang_sparseManifoldAlign_techRep2012.pdf">pdf</a> ]


<p><li>Kuindersma, S.R. 
<BR> <b>Variable Risk Policy Search for Dynamic Robot Control.</b>
<BR> PhD thesis, Department of Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2012/kuindersma_2012.pdf">pdf</a> ]

<p><li>da Silva, B.C. and Barto, A.G. 
<BR><b>TD-&Delta;&pi;: A Model-Free Algorithm for Efficient Exploration</b>
<BR>Proceedings of the 25th Conference on Artificial Intelligence (AAAI 2012). Toronto, Canada, July 2012.
<BR>
[ <a href="/pubs"/2012/da_silva_b_aaai12.pdf">pdf</a> ] 

<p><li>Kuindersma, S., Grupen, R., and Barto, A. 
<BR><b>Variational Bayesian Optimization for Runtime Risk-Sensitive Control.</b>
<BR>In Robotics: Science and Systems VIII, Sydney, Australia, July 2012. 
<BR>
[ <a href="/pubs"/2012/kuindersma_g_b_rss12.pdf">pdf</a> ] 

<p><li>Kuindersma, S., Grupen, R., and Barto, A. 
<BR><b>Variable Risk Dynamic Mobile Manipulation.</b>
<BR>In RSS 2012 Mobile Manipulation Workshop, Sydney, Australia, July 2012. 
<BR>
[ <a href="/pubs"/2012/kuindersma_g_b_mm12.pdf">pdf</a> ] 

<p><li>da Silva, B.C., Konidaris, G., and Barto, A.G. 
<BR><b>Learning Parameterized Skills.</b> 
<BR>In Proceedings of the 29th International Conference on Machine Learning (ICML 2012). Edinburg, Scotland, June 2012.
<BR>
[ <a href="/pubs"/2012/da_silva_k_b_icml12.pdf">pdf</a> ] 

<p><li>da Silva, B.C., Barto, A.G., and Kurose, J. 
<BR><b>Designing Adaptive Sensing Policies for Meteorological Phenomena via Spectral Analysis of Radar Images.</b> 
<BR>Technical Report UM-CS-2012-006, Department of Computer Science, University of Massachusetts Amherst, March 2012.
<BR>
[ <a href="/pubs"/2012/da_silva_b_k_tr12.pdf">pdf</a> ] 

<p><li>Konidaris, G., Kuindersma, S., Grupen, R., and Barto, A. 
<BR><b>Robot Learning from Demonstration by Constructing Skill Trees.</b>
<BR>The International Journal of Robotics Research 31(3), pages 260-275, March 2012. 
<BR>
[ <a href="/pubs"/2012/cst_ijrr_12.pdf">pdf</a> | <a href="http://ijr.sagepub.com/content/early/2011/12/02/0278364911428653.abstract">ijrr</a> ] 

</ul>


<hr>
<A name="2011"></A>
<h3>2011</h3>
<ul>
<p><li>Konidaris, G.D., Niekum, S., and Thomas, P.S. 
<BR><b>TD&#947;: Reevaluating Complex Backups in Temporal Difference Learning.</b>
<BR>In Advances in Neural Information Processing Systems 24 (<a href="http://nips.cc/Conferences/2011/">NIPS</a>). Granada, Spain. December 2011.
<BR>[ <a href="/pubs"/2011/konidaris_n_t_11.pdf">pdf</a> ] 

<p><li>Niekum, S., and Barto, A.G. 
<BR><b>Clustering via Dirichlet Process Mixture Models for Portable Skill Discovery.</b>
<BR>In Advances in Neural Information Processing Systems 24 (<a href="http://nips.cc/Conferences/2011/">NIPS</a>). Granada, Spain. December 2011.
<BR>[ <a href="/pubs"/2011/niekum_b_11.pdf">pdf</a> ] 

<p><li>Thomas, P.S. 
<BR><b>Policy Gradient Coagent Networks.</b>
<BR>In Advances in Neural Information Processing Systems 24 (<a href="http://nips.cc/Conferences/2011/">NIPS</a>). Granada, Spain. December 2011.
<BR>[ <a href="/pubs"/2011/thomas_11.pdf">pdf</a> ] 

<p><li>Kuindersma, S., Grupen, R., and Barto, A.
<BR><b>Learning Dynamic Arm Motions for Postural Recovery.</b>
<BR>Proceedings of the 11th IEEE-RAS International Conference on Humanoid Robots (<a href="http://www.humanoids2011.org/Welcome.html">Humanoids '11</a>). Bled, Slovenia, October 2011.
<BR>[ <a href="/pubs"/2011/kuindersma_g_b_11.pdf">pdf</a> ] 

<p><li>Thomas, P. and Barto, A. 
<BR><b>Conjugate Markov Decision Processes.</b>
<BR>Proceedings of the Twenty-Eighth International Conference on Machine Learning (<a href="http://www.icml-2011.org/">ICML '11</a>), June 2011.
<BR>[ <a href="/pubs"/2011/thomas_b_11.pdf">pdf</a> ] [ <a href="/pubs"/2011/thomas_b_11.zip">source code</a> ]

<p><li>Konidaris, G., Osentoski, S., and Thomas, P. 
<BR><b>Value Function Approximation in Reinforcement Learning using the Fourier Basis.</b>
<BR>Proceedings of the Twenty-Fifth Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai11.php">AAAI '11</a>), August 2011.
<BR>[ <a href="/pubs"/2011/konidaris_o_t_11.pdf">pdf</a> ]

<p><li>Konidaris, G., Kuindersma, S., Grupen, R., and Barto, A.
<BR><b>CST: Constructing Skill Trees by Demonstration.</b>
<BR>In Proceedings of the ICML Workshop on New Developments in Imitation Learning, July 2011.
<BR>[ <a href="/pubs"/2011/konidaris_k_g_b_11a.pdf">pdf</a> ]

<p><li>Konidaris, G., Kuindersma, S., Grupen, R., and Barto, A.
<BR><b>Acquiring Transferrable Mobile Manipulation Skills.</b>
<BR>In the RSS 2011 Workshop on Mobile Manipulation: Learning to Manipulate, June 2011.
<BR>[ <a href="/pubs"/2011/konidaris_k_g_b_11b.pdf">pdf</a> ]

<p><li>Konidaris, G. 
<BR> <b>Autonomous Robot Skill Acquisition.</b>
<BR> PhD thesis, Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2011/konidaris_11.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, M. 
<BR><b>Heterogeneous Domain Adaptation using Manifold Alignment.</b>
<BR>In Proceedings of the International Joint Conference on Artificial Intelligence (<a href="http://ijcai-11.iiia.csic.es/">IJCAI-11</a>). July 18-23, 2011, Barcelona, Spain.
<BR>[ <a href="/pubs"/2011/wang_m_11a.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, M. 
<BR><b>Jointly Learning Data-Depdendent Label and Locality-Preserving Projections.</b>
<BR>In Proceedings of the International Joint Conference on Artificial Intelligence (<a href="http://ijcai-11.iiia.csic.es/">IJCAI-11</a>). July 18-23, 2011, Barcelona, Spain.
<BR>[ <a href="/pubs"/2011/wang_m_11b.pdf">pdf</a> ]

<p><li>Foster, B., Mahadevan, S., and Wang, R. 
<BR><b>GPU-Based Approximate SVD Algorithm.</b>
<BR>9th International Conference on Parallel Programming and Mathematics, Torun, Poland, September 11-14, 2011.
<BR>[ <a href="/pubs"/2011/foster_m_w_11.pdf">pdf</a> ]
<BR>(also available as Technical Report UM-CS-2011-025, Univ. of Massachusetts, Amherst)

<p><li>Wang. C., Krafft, P., and Mahadevan, S.
<BR><b>Manifold Alignment.</b>
<BR>appearing in Manifold Learning: Theory and Applications, Taylor and Francis CRC Press, 2011
<BR>[ <a href="/pubs"/2011/wang_k_m_11.pdf">pdf</a> ]

<p><li>Liu, B. and Mahadevan, S.
<BR><b>Compressive Reinforcement Learning with Oblique Random Projections.</b>
<BR>Technical Report UM-CS-2011-024, Department of Computer Science, University of Massachusetts at Amherst, 2011.
<BR>[ <a href="/pubs"/2011/liu_m_11.pdf">pdf</a> ]

<p><li>Konidaris, G., Kuindersma, S., Grupen, R., and Barto, A. 
<BR><b>Autonomous Skill Acquisition on a Mobile Manipulator.</b>
<BR>In Proceedings of the Twenty-Fifth Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai11.php">AAAI-11</a>). San Francisco, CA. August 2011.
<BR>[ <a href="/pubs"/2011/konidaris_k_g_b_11.pdf">pdf</a> ]

</ul>

<hr>
<A name="2010"></A>
<h3>2010</h3>
<ul>
<p><li>Kuindersma, S., Konidaris, G., Grupen, R., and Barto, A. (2010).
<BR><b>Learning from a Single Demonstration: Motion Planning with Skill Segmentation (poster abstract).</b>
<BR><a href="http://nips.cc/Conferences/2010/Program/event.php?ID=2002">NIPS Workshop on Learning and Planning in Batch Time Series Data</a>. Whistler, BC. December 2010.
<BR>[ <a href="/pubs"/2010/kuindersma_k_g_b_10.pdf">pdf</a> ]

<p><li>Konidaris, G., Kuindersma, S., Barto, A., and Grupen, R. (2010).
<BR><b>Constructing Skill Trees for Reinforcement Learning Agents from Demonstration Trajectories.</b>
<BR>In Advances in Neural Information Processing Systems 23 (<a href="http://nips.cc/Conferences/2010/">NIPS</a>). Vancouver, BC. December 2010.
<BR>[ <a href="/pubs"/2010/konidaris_k_b_g_10.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S. (2010)
<BR><b>Multiscale Manifold Alignment.</b>
<BR>Technical Report UM-CS-2010-049, Department of Computer Science, University of Massachusetts at Amherst.
<BR>[ <a href="/pubs"/2010/wang_m_10b.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S. (2010)
<BR><b>Learning Locality Preserving Discriminative Features.</b>
<BR>Technical Report UM-CS-2010-048, Department of Computer Science, University of Massachusetts at Amherst.
<BR>[ <a href="/pubs"/2010/wang_m_10a.pdf">pdf</a> ]

<p><li>Wang, C. (2010)
<BR> <b>A Geometric Framework for Transfer Learning Using Manifold Alignment.</b>
<BR> PhD thesis, Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2010/wang_10.pdf">pdf</a> ]

<p><li>Theocharous, G. and Mahadevan, S. (2010)
<BR> <b>Compressing POMDPs using Locality Preserving Non-Negative Matrix Factorization.</b>
<BR> 24th Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai10.php">AAAI '10</a>), Atlanta, GA, July 11-15, 2010.
<BR> [ <a href="/pubs"/2010/theocharous_m_10.pdf">pdf</a> ]

<p><li>Mahadevan, S. (2010)
<BR> <b>Representation Discovery in Sequential Decision Making.</b>
<BR> 24th Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai10.php">AAAI '10</a>), Atlanta, GA, July 11-15, 2010.
<BR> [ <a href="/pubs"/2010/mahadevan_10.pdf">pdf</a> ]

<p><li>Osentoski, S. and Mahadevan, S. (2010)
<BR> <b>Basis Function Construction in Hierarchical Reinforcement Learning.</b>
<BR> 9th International Conference on Autonomous Agents and Multiagent Systems (<a href="http://www.cse.yorku.ca/AAMAS2010/">AAMAS '10</a>), Toronto, Canada, May 10-14, 2010.
<BR> [ <a href="/pubs"/2010/osentoski_m_10.pdf">pdf</a> ]

<p><li>Vigorito, C.M. and Barto, A.G. (2010)
<BR> <b>Intrinsically Motivated Hierarchical Skill Learning in Structured Environments.</b>
<BR> IEEE Transactions on Autonomous Mental Development (<a href=http://ieee-cis.org/pubs/tamd/>IEEE TAMD</a>). Volume 2, Issue 2.
<BR> [ <a href="/pubs"/2010/vigorito_b_10.pdf">pdf</a> ]

<p><li>Kuindersma, S. (2010)
<BR> <b>Control Model Learning for Whole-Body Mobile Manipulation (extended abstract).</b>
<BR> Proceedings of the Twenty-Fourth Conference on Artificial Intelligence (<a href=http://www.aaai.org/Conferences/AAAI/aaai10.php>AAAI-10</a>). Atlanta, GA. July, 2010.
<BR>[ <a href="/pubs"/2010/kuindersma_10.pdf">pdf</a> ]


<p><li>Niekum, S. (2010)
<BR> <b>Evolved Intrinsic Reward Functions for Reinforcement Learning (extended abstract).</b>
<BR> Proceedings of the Twenty-Fourth Conference on Artificial Intelligence (<a href=http://www.aaai.org/Conferences/AAAI/aaai10.php>AAAI-10</a>). Atlanta, GA. July, 2010.
<!--<BR>[ <a href="/pubs"/2010/niekum_10.pdf">pdf</a> ]-->


<p><li>Wolfe, A.P. (2010)
<BR> <b>Paying Attention To What Matters: Observation Abstraction In Partially Observable Environments.</b>
<BR> PhD thesis, Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2010/wolfe_thesis_10.pdf">pdf</a> ]

<p><li>Johns, J.T. (2010)
<BR> <b>Basis Construction and Utilization for Markov Decision Processes Using Graphs.</b>
<BR> PhD thesis, Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2010/johns_10.pdf">pdf</a> ]

</ul>

<hr>
<A name="2009"></A>
<h3>2009</h3>
<ul>
<p><li>Osentoski, S. (2009)
<BR><b>Action-Based Representation Discovery in Markov Decision Processes.</b>
<BR>PhD thesis, Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2009/osentoski_thesis09.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2009)
<BR><b>Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining.</b>
<BR>In Y. Bengio, D. Schuurmans, J. Lafferty, C.K.I. Williams and A. Culotta (Eds.),
Advances in Neural Information Processing Systems 22 (<a href="http://nips.cc/Conferences/2009/">NIPS '09</a>), 
pp. 1015-1023.
<BR>[ <a href="/pubs"/2009/konidaris_b_09d.pdf">pdf</a> ]


<p><li>Vigorito, C.M. and Barto, A.G. (2009)
<BR><b>Incremental Structure Learning in Factored MDPs with Continuous States and Actions.</b>
<BR>Technical Report UM-CS-2009-029, Department of Computer Science, University of Massachusetts at Amherst.
<BR>[ <a href="/pubs"/2009/vigorito_b_09.pdf">pdf</a> ]


<p><li>Singh, S., Lewis, R.L., and Barto A.G.(2009)
<BR><b>Where Do Rewards Come From?</b>
<BR>In N.A. Taatgen &amp; H. van Rijn (Eds.), Proceedings of the 31st Annual Conference of the Cognitive Science Society, pp. 2601-2606. Austin, TX.
<BR>[ <a href="/pubs"/2009/singh_l_b_09.pdf">pdf</a> ]


<p><li>Johns, J. and Mahadevan, S. (2009)
<BR><b>Sparse Approximate Policy Evaluation using Graph-based Basis Functions.</b>
<BR>Technical Report UM-CS-2009-041, Department of Computer Science, University of Massachusetts at Amherst.
<BR>[ <a href="/pubs"/2009/johns_m_09.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S. (2009)
<BR><b>A General Framework for Manifold Alignment.</b>
<BR><a href="http://odin.uncc.edu/aaai-manifold/">AAAI Fall Symposium on Manifold Learning</a>, Arlington, VA, November 5-7.
<BR>[ <a href="/pubs"/2009/wang_m_09d.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2009)
<BR><b>Towards the Autonomous Acquisition of Robot Skill Hierarchies</b> (poster abstract).
<BR>In the Robotics: Science and Systems Workshop on Bridging the Gap Between High-Level Discrete Representations and Low-Level Continuous Behaviors (RSS Workshop), Seattle, WA, June 2009.
<BR>[ <a href="/pubs"/2009/konidaris_b_09c.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Osentoski, S. (2009)
<BR><b>Value Function Approximation using the Fourier Basis</b> (extended abstract).
<BR>In the Multidisciplinary Symposium on Reinforcement Learning (<a href="http://msrl09.rl-community.org/">MSRL '09</a>), Montreal, Canada, June 2009.
<BR>[ <a href="/pubs"/2009/konidaris_o_09.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2009)
<BR><b>Skill Chaining: Skill Discovery in Continuous Domains</b> (extended abstract).
<BR>In the Multidisciplinary Symposium on Reinforcement Learning (<a href="http://msrl09.rl-community.org/">MSRL '09</a>), Montreal, Canada, June 2009.
<BR>[ <a href="/pubs"/2009/konidaris_b_09b.pdf">pdf</a> ]

<p><li>Mahadevan, S. (2009)
<BR><b>Learning Representation and Control in Markov Decision Processes: New Frontiers.</b>
<BR>Foundations and Trends in Machine Learning (editor, Michael, Jordan), Vol. 1, No. 4, pp. 403-565 (163 pages), 2009.
<BR>[ <a href="/pubs"/2009/mahadevan_09.pdf">pdf</a> ]

<p><li>Johns, J., Petrik, M., and Mahadevan, S. (to appear)
<BR><b>Hybrid Least-Squares Algorithms for Approximate Policy Evaluation.</b>
<BR><a href="http://www.springer.com/computer/artificial/journal/10994">Machine Learning journal</a>.
<BR>(One of only 7 papers selected to appear in Machine Learning journal from those to be presented at European Conference on Machine Learning (<a href="http://www.ecmlpkdd2009.net/program/accepted-papers/">ECML</a>), Bled, Slovenia, 2009.) 

<p><li>Wang, C. and Mahadevan, S. (2009)
<BR><b>Manifold Alignment without Correspondence.</b>
<BR>Proceedings of the 21st International Joint Conference on Artificial Intelligence (<a href="http://ijcai.org/~ijcai09/">IJCAI '09</a>), June 14-17, Pasadena, CA.
<BR>[ <a href="/pubs"/2009/wang_m_09a.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S. (2009)
<BR><b>Multiscale Analysis of Document Corpora based upon Diffusion Models.</b>
<BR>Proceedings of the 21st International Joint Conference on Artificial Intelligence (<a href="http://ijcai.org/~ijcai09/">IJCAI '09</a>), July 14-17, Pasadena, CA.
<BR>[ <a href="/pubs"/2009/wang_m_09b.pdf">pdf</a> ]

<p><li>Wang, C. and Mahadevan, S. (2009)
<BR><b>Multiscale Dimensionality Reduction with Diffusion Wavelets.</b>
<BR>Technical Report UM-CS-2009-030, Department of Computer Science, University of Massachusetts at Amherst, June 2009.
<BR>[ <a href="/pubs"/2009/wang_m_09c.pdf">pdf</a> ]

<p><li>Osentoski, S. and Mahadevan, S. (2009)
<BR><b>Basis Function Construction for Hierarchical Reinforcement Learning.</b>
<BR><a href="http://www-anw.cs.umass.edu/~gdk/arl/">ICML '09 Workshop on Abstraction in Reinforcement Learning</a>
<BR>[ <a href="/pubs"/2009/osentoski_m_09.pdf">pdf</a> ]

<p><li>Vigorito, C.M. (2009)
<BR><b>Temporal-Difference Networks for Dynamical Systems with Continuous Observations and Actions.</b>
<BR>Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (<a href="http://www.cs.mcgill.ca/~uai2009/">UAI '09</a>), June 19-21, Montreal, Canada.
<BR>[ <a href="/pubs"/2009/vigorito_09.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2009)
<BR><b>Efficient Skill Learning Using Abstraction Selection.</b>
<BR>In C. Boutilier (Ed.), Proceedings of the Twenty First International Joint Conference on Artificial Intelligence (<a 
href="http://ijcai.org/~ijcai09/">IJCAI '09</a>), pp. 1107-1112.
<BR>[ <a href="/pubs"/2009/konidaris_b_09a.pdf">pdf</a> ]


<p><li>Botvinick, M.M., Niv, Y., and Barto, A.G. (2009)
<BR><b>Hierarchically organized behavior and its neural foundations: A reinforcement-learning perspective.</b>
<BR> <a href="http://www.elsevier.com/wps/find/journaldescription.cws_home/505626/description">Cognition</a>, vol. 113 (special issue on Reinforcement Learning and Higher Cognition, edited by Michael Frank and Nathaniel Daw), pages 262--280.
<BR>[ <a href="/pubs"/2009/botvinick_nb_09.pdf">pdf</a> ]

<p><li>Shah, A. and Barto, A.G. (2009)
<BR><b>Effect on movement selection of an evolving sensory representation: a multiple controller model of skill acquisition.</b>
<BR><a href="http://www.elsevier.com/locate/brainres">Brain Research</a>, vol. 1299 (special issue on Computational Cognitive Neuroscience II, edited by Sue Becker and Nathaniel Daw), pages 55--73. 
<BR>[ <a href="/pubs"/2009/shah_b_BR09.pdf">pdf</a> ]
</ul>


<hr>
<A name="2008"></A>
<h3>2008</h3>
<ul>
<p><li>&#350;im&#351;ek, &#214. (2008)
<BR><b>Behavioral building blocks for autonomous agents: description, identification, and learning.</b>
<BR>PhD thesis, University of Massachusetts Amherst, 2008.
<BR>[ <a href="/pubs"/2008/simsek_thesis08.pdf">pdf</a> ]

<p><li>Shah, A. (2008)
<BR> <b>Biologically-Based Functional Mechanisms of Motor Skill Acquisition</b>
<BR> PhD thesis, Neuroscience and Behavior Program, University of Massachusetts Amherst 
<BR>[ <a href="/pubs"/2008/shah_thesis08.shtml">abstract</a> | <a href="/pubs"/2008/shah_thesis08b_single.pdf">pdf</a> ]

<p><li>&#350;im&#351;ek, &#214. and Barto, A.G. (2008)
<BR><b>Skill characterization based on betweenness</b>
<BR>Proceedings of the 22nd Annual Conference on Neural Information Processing Systems (<a href="http://nips.cc/Conferences/2008/">NIPS-08</a>), December 8-11, Vancouver, B.C., Canada.
<BR> [ <a href="/pubs"/2008/simsek_b_NIPS08.pdf">pdf</a> ]


<A name="3"></A>
<p><li>Mahadevan, S. (2008)
<BR><b>Representation Discovery using Harmonic Analysis</b>
<BR>from the series Brachman, R., and Dietterich, T. (editors), <a href="http://www.morganclaypool.com/toc/aim/2/1">Synthesis Lectures on Artificial Intelligence and Machine Learning</a>, Vol. 2, No. 1, <a href="http://www.morganclaypool.com/">Morgan and Claypool</a>. 
<BR>[ <A HREF="http://www.morganclaypool.com/doi/abs/10.2200/S00130ED1V01Y200806AIM004">publisher's website for this book</A> ] NOTE: this book is available, through the publisher, as both a hard copy and in pdf format. However, be warned that some figures use color, and while the pdf displays such colors, the hard copy is printed in grey-scale. 

<p><li>Wang, C. and Mahadevan, S. (2008)
<br><b>Multiscale Analysis of Document Corpora Using Diffusion Models</b>
<br>University of Massachusetts Technical Report 16.
<br>[ <a href="/pubs"/2008/wang_m_TECH08.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2008)
<BR><b>Sensorimotor Abstraction Selection for Efficient, Autonomous Robot Skill Acquisition</b>
<BR>Proceedings of the 7th IEEE International
Conference on Development and Learning (<a href="http://www.icdl08.org/">ICDL-08</a>), August 9 - 12, Monterey, CA
<BR>[ <A href="/pubs"/2008/konidaris_b_ICDL08.pdf">pdf</A> ]

<p><li>Konidaris, G.D. (2008)
<BR><b>Autonomous Robot Skill Acquisition (thesis summary)</b>
<BR>Doctoral Symposium, 23rd National Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai08.php">AAAI-08</a>), July 13 - 17, Chicago, Illinois

<p><li>Nelson, E.L., Konidaris, G.D., and Berthier, N.E. (2008)
<BR><b>Using Real-Time Motion Capture to Measure Handedness in Infants</b>
<BR>Poster at the XVIth Biennial International Conference on Infant Studies, June, Vancouver, Canada

<p><li>Konidaris, G.D. and Osentoski, S. (2008)
<BR><b>Value Function Approximation in Reinforcement Learning using the Fourier Basis</b>
<BR>Technical Report UM-CS-2008-19, Department of Computer Science, University of Massachusetts at Amherst, June 2008
<BR>[ <A href="/pubs"/2008/konidaris_o_TR08.pdf">pdf</A> ]


<p><li>Vigorito, C.M. and Barto, A.G. (2008)
<BR><b>Autonomous Hierarchical Skill Acquisition in Factored MDPs</b>
<BR>Proceedings of The Fourteenth Yale Workshop on Adaptive and Learning Systems, June 2 - 4, New Haven, CT
<BR>[ <A href="/pubs"/2008/vigorito_b_Yale08.pdf">pdf</A> ]

<p><li>Vigorito, C.M. and Barto, A.G. (2008)
<BR><b>Hierarchical Representations of Behavior for Efficient Creative Search</b>
<BR><a href="http://axon.cs.byu.edu/CreativeAI/">AAAI Spring Symposium on Creative Intelligent Systems</a>, March 26 - 28, Palo Alto, CA
<BR>[ <A href="/pubs"/2008/vigorito_b_AAAI08.pdf">pdf</A> ] [ <A href="/pubs"/2008/vigorito_b_AAAI08_poster.pdf">poster</A> ]

<p><li>Mahadevan, S. (2008)
<BR><b>Fast Spectral Learning using Lanczos Eigenspace Projections</b>
<BR>Proceedings from the Twenty-Third Conference on Artificial Intelligence (<a href="http://www.aaai.org/Conferences/AAAI/aaai08.php">AAAI-08</a>), July 13 - 17, Chicago, Illinois
<BR>[ <A href="/pubs"/2008/mahadevan_AAAI08.pdf">pdf</A> ]

<p><li>Wang, C. and Mahadevan, S. (2008)
<BR><b>Manifold Alignment using Procrustes Analysis</b>
<BR>Proceedings from the Twenty-Fifth International Conference on Machine Learning (<a href="http://icml2008.cs.helsinki.fi/">ICML-08</a>), July 5 - 9, Helsinki, Finland
<BR>[ <A href="/pubs"/2008/wang_m_ICML08.pdf">pdf</A> ]
</ul>

<hr>
<A name="2007"></A>
<h3>2007</h3>
<ul>
<p><li>Jonsson, A. and Barto, A.G. (2007) 
<BR><b>Active Learning of Dynamic Bayesian Networks in Markov Decision Processes</b>
<BR>Proceedings of the Seventh Symposium on Abstraction, Reformulation, and Approximation (<a href="http://www.cs.st-and.ac.uk/~ianm/SARA2007.html">SARA 2007</a>), Whistler, British Columbia, Canada, July 18 - 21, 2007.
<BR>Also published as Miguel, I. and Tuml, W. (editors) <a href="http://www.springer.com/computer/artificial/book/978-3-540-73579-3">Lecture Notes in Artificial Intelligence: Abstraction, Reformulation, and Approximation, vol. 4612</a>, pages 273-284, <a href="http://www.springer.com/?SGWID=0-102-0-0-0">Springer</a>, New York, NY, USA. 
<BR>[ <A href="/pubs"/2007/jonsson_b_SARA07.pdf">pdf</A> ]

<p><li>Barto, A.G. (2007) 
<BR><b>Temporal difference learning</b>
<BR><a href='http://www.scholarpedia.org'>Scholarpedia</a>, 2(11):1604
<BR>[ <a href='http://www.scholarpedia.org/article/Temporal_difference_learning'>webpage</a> ] for this article

<p><li>Ghavamzadeh, M., and Mahadevan, S. (2007)
<BR><b>Hierarchical Average Reward Reinforcement Learning</b>
<BR>Journal of Machine Learning Research <a href="http://jmlr.csail.mit.edu/">(JMLR)</a>, 8(Nov):2629--2669, 2007
<BR>[ <A href="/pubs"/2007/ghavamzadeh_m_JMLR07.pdf">pdf</A> ]

<p><li>Shah, A., and  Barto, A.G. (2007)
<BR><b>Effect on Movement Selection of Evolving Sensory Representation</b>
<BR>poster presented at the Third Annual Computational Cognitive Neuroscience Conference <a href="http://www.ccnconference.org/">(CCNC07)</a>, in conjunction with Dynamical Neuroscience XV, 
November 1 -- 2, San Diego, CA.
<BR>[ <A href="/pubs"/2007/shah_b_CCNC07.pdf">pdf</A> ]

<p><li>Mahadevan, S., and Maggioni, M. (2007)
<BR><b>Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes</b>
<BR>Journal of Machine Learning Research <a href="http://jmlr.csail.mit.edu/">(JMLR)</a>, 8(Oct):2169--2231, 2007, <a href="http://mitpress.mit.edu">MIT Press</a>
<BR>[ <A href="/pubs"/2007/mahadevan_m_JMLR07.pdf">pdf</A> ] <b>NOTE:</b> this is a revised version that corrects some errors found in the original published version.

<p><li>Shah, A., and  Barto, A.G. (2007)
<BR><b>Functional Mechanisms of Motor Skill Acquisition</b>
<BR>poster presented at the Sixteenth Annual Computational Neuroscience Meeting <a href="http://www.cnsorg.org/">(CNS*2007)</a>,
July 7th - 12th, Toronto, Ontario, Canada. Abstract published in <a href="http://www.biomedcentral.com/bmcneurosci">BMC Neuroscience</a> 2007, <b>8</b>(Suppl 2):P203 (6 July 2007)
<BR>[ <A HREF="http://www.biomedcentral.com/1471-2202/8/S2/P203">abstract</a> | <A href="/pubs"/2007/shah_b_CNS07.pdf">pdf of poster</A> ]

<p><li>Johns, J., Mahadevan, S., and Wang, C. (2007)
<BR><b>Compact Spectral Bases for Value Function Approximation Using Kronecker Factorization</b>
<BR>Proceedings of the Twenty-second National Conference on Artificial Intelligence <a href="http://www.aaai.org/Conferences/AAAI/aaai07.php">(AAAI-07)</a> Vancouver, British Columbia, Canada
<BR>[ <A href="/pubs"/2007/johns_mw_AAAI07.pdf">pdf</A> ]

<p><li>Mahadevan, S. (2007)
<BR><b>New Frontiers in Representation Discovery</b>
<BR>Tutorial given at the Twenty-second National Conference on Artificial Intelligence <a href="http://www.aaai.org/Conferences/AAAI/aaai07.php">(AAAI-07)</a>, July 23, 2007,  Vancouver, British Columbia, Canada
<BR>[ <A HREF="http://www.cs.umass.edu/~mahadeva/aaai07-tutorial/tutorial-overview.html">tutorial website</a> ]

<p><li>Johns, J., Osentoski, S., and Mahadevan, S. (2007)
<BR><b>Representation Discovery in Planning using Harmonic Analysis</b>
<BR><a href="http://www.aaai.org">AAAI</a> Fall Symposium on Computational Approaches to Representation Change during Learning and Development, Nov. 8-11, 2007, Washington, D.C.
<BR>[ <A href="/pubs"/2007/johns_om_AAAIfallsymp07.pdf">pdf</A> ]

<p><li>Mahadevan, S. (2007)
<BR><b>Adaptive Mesh Compression in 3D Computer Graphics using Multiresolution Manifold Learning</b>
<BR>Proceedings of the International Conference on Machine Learning (<a href="http://oregonstate.edu/conferences/icml2007/">ICML-07</a>), Corvallis, OR June 2007
<BR>[ <A href="/pubs"/2007/mahadevan_ICML07.pdf">pdf</A> ]

<p><li>Johns, J., and  Mahadevan, S. (2007)
<BR><b>Constructing Basis Functions from Directed Graphs for Value Function Approximation</b>
<BR>Proceedings of the International Conference on Machine Learning (<a href="http://oregonstate.edu/conferences/icml2007/">ICML-07</a>), Corvallis, OR June 2007
<BR>[ <A href="/pubs"/2007/johns_m_ICML07.pdf">pdf</A> ]

<p><li>Osentoski, S., and Mahadevan, S. (2007)
<BR><b>Learning State-Action Basis Functions for Hierarchical MDPs</b>
<BR>Proceedings of the International Conference on Machine Learning (<a href="http://oregonstate.edu/conferences/icml2007/">ICML-07</a>), Corvallis, OR June 2007
<BR>[ <A href="/pubs"/2007/osentoski_m_ICML07.pdf">pdf</A> ]

<p><li>Mahadevan, S., Osentoski, S., Johns, J., Ferfuson, K., and Wang, C. (2007)
<BR><b>Learning to Plan using Harmonic Analysis of Diffusion Models</b>
<BR>Proceedings of the International Conference on Automated Planning and Scheduling (<a href="http://icaps07.icaps-conference.org/">ICAPS-07</a>), Providence, RI, September.
<BR>[ <A href="/pubs"/2007/mahadevan_ojfw_ICAPS07.pdf">pdf</A> ]

<p><li>Arroyo, I., Ferguson, K., Johns, J., Dragon, T., Meheranian, H., Fisher, D., Barto, A.G., Mahadevan, S., and Woolf, B. (2007)
<BR><b>Repairing Disengagement with Non-Invasive Interventions</b>
<BR>Proceedings of the 13th International Conference of Artificial Intelligence in Education (<a href="http://www.isi.edu/AIED2007/">AIED-07</a>)
<BR>[ <A href="/pubs"/2007/arroyo_fjdmfbmw_AIED2007.pdf">pdf</A> ]

<p><li>Vigorito, C.  (2007)
<BR><b>Distributed Path Planning for Mobile Robots using a Swarm of Interacting Reinforcement Learners</b>
<BR>Proceedings of the Sixth Annual International Conference on Autonomous Agents and Multiagent Systems (<a href="http://www.aamas2007.org/">AAMAS-07</a>), Honolulu, HI.
<BR>[ <A href="/pubs"/2007/vigorito_AAMAS07.pdf">pdf</A> ]

<p><li>Vigorito, C., Ganesan, D., and Barto, A.G. (2007)
<BR><b>Adaptive Control of Duty-Cycling in Energy-Harvesting Wireless Sensor Networks</b>
<BR>Proceedings of the Fourth Annual IEEE Communications Society Conference on Sensor, Mesh, and Ad Hoc Communications and Networks (<a href="http://www.ieee-secon.org/2007/">SECON-07</a>), San Diego, CA.
<BR>[ <A href="/pubs"/2007/vigorito_gb_SECON07.pdf">pdf</A> ] (Note: this recieved the best paper award)

<p><li>&#350;im&#351;ek, &#214. and Barto, A.G. (2007)
<BR><b>Betweenness Centrality as a Basis for Forming Skills</b>
<BR>University of Massachusetts, Department of Computer Science Technical Report TR-2007-26, 2007
<BR>[ <a href="/pubs"/2007/simsek_b_TR07-26.pdf">pdf</a> ]

<p><li>Barringer, C.W. and  Barto, A.G. (2007)
<BR><b>Discrete Submovements Using Predictive Models</b><BR>
poster presented at the <a href="http://ncm-society.org/">Neural Control of Movement Conference</a>,
March 25-30, Seville, Spain
<BR>[ <A href="/pubs"/2007/barringer_b_NCM07.pdf">pdf</A> ]

<p><li>Mahadevan, S. (2007)
<BR><b>Learning Representations for Markov Decision Processes and Reinforcement Learning</b>
<BR>A <a href="http://www.ijcai-07.org/?q=tutorialdesc.html#t14">tutorial</a> given at the Twentieth International Joint Conference on Artificial Intelligence (<a href="http://www.ijcai.org/">IJCAI</a>-07), Hyderabad, India, January 6-12, 2007.
<BR>[ <a href="/pubs"/2007/mahadevan_IJCAI07tutslides.pdf">pdf slides</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2007)<br>
<b> Building Portable Options: Skill Transfer in Reinforcement Learning</b><br>
Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (<a href="http://www.ijcai.org/">IJCAI</a>-07), Hyderabad, India, January 6-12, 2007.<br>
[ <a href="/pubs"/2007/konidaris_b_IJCAI07.pdf">pdf</a> ]
<ul>
<p><b>NOTE:</b> an earlier version appeared as a 2006 tech report: Konidaris, G.D. and Barto, A.G. (2006),
<b>Building Portable Options: Skill Transfer in Reinforcement Learning</b>,
University of Massachusetts Department of Computer Science Technical Report UM-CS-2006-17, March, 2006
[ <a href="/pubs"/2006/konidaris_b_TECH06.pdf">pdf</a> ]
</ul>
</ul>


<hr>
<A name="2006"></A>
<h3>2006</h3>
<ul>
<p><li>Jonsson, A. and Barto, A.G. (2006)<br>
<b>Causal Graph Based Decomposition of Factored MDPs</b><br>
<a href="http://www.jmlr.org">Journal of Machine Learning Research</a>, vol 7, pages 2259--2301, Nov., 2006.<br>
[ <a href="/pubs"/2006/jonsson_b_JMLR06.pdf">pdf</a> ]

<p><li>Rohanimanesh, K. (2006)<br>
<b>Concurrent Decision Making in Markov Decision Processes</b><br>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.<br>
[ <a href="/pubs"/2006/rohanimanesh_thesis06.pdf">pdf</a> ]

<p><li>Mahadevan, S. and Maggiono, M. (2006)
<BR><b>Proto-Value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes</b>
<BR>University of Massachusetts, Department of Computer Science Technical Report TR-2006-35, 2006
<BR>[ <a href="/pubs"/2006/mahadevan_m_TECH06-35.pdf">pdf</a> ]

<p><li>Maggiono, M. and Mahadevan, S. (2006)
<BR><b>A Multiscale Framework For Markov Decision Processes using Diffusion Wavelets</b>
<BR>University of Massachusetts, Department of Computer Science Technical Report TR-2006-36, 2006
<BR>[ <a href="/pubs"/2006/maggioni_m_TECH06-36.pdf">pdf</a> ]

<p><li>Mahadevan, S. and Maggiono, M. (2006)
<BR><b>Learning Representation And Behavior: Manifold and Spectral Methods for Markov Decision Processes and Reinforcement Learning</b>
<BR>A <a href="http://www.cs.umass.edu/~mahadeva/icml06-tutorial/tutorial-overview.html">tutorial</a> given at <a href="http://www.autonlab.org/icml2006/home.html">ICML-06</a>, 
Carnegie Mellon University, June 25, 2006
<BR>[ <a href="/pubs"/2006/mahadevan_m_ICML06tutslides.pdf">pdf slides</a> ]

<p><li>Ghavamzadeh, M., Mahadevan, S., and Makar, R. (2006)
<BR><b>Hierarchical Multiagent Reinforcement Learning</b>
<BR><a href="http://www.springerlink.com/openurl.asp?genre=journal&eissn=1573-7454">Journal of Autonomous Agents and Multiagent Systems</a>, vol. 13(2), pages 197-229, September
<BR>[ <a href="/pubs"/2006/ghavamzadeh_mm_JAAMAS06.pdf">pdf</a> ]

<p><li>Mahadevan, S. and Maggioni, M. (2006)
<BR><b>Value Function Approximation using Diffusion Wavelets and Laplacian Eigenfunctions</b>
<BR>Neural Information Processing Systems (<a href="http://www.nips.cc">NIPS</a>), MIT Press, 2006.
<BR>[ <a href="/pubs"/2006/mahadevan_m_NIPS06.pdf">pdf</a> ]

<p><li>Maggioni, M. and Mahadevan, S. (2006)
<BR><b>Fast Direct Policy Evaluation using Multiscale Analysis of Markov Diffusion Processes</b>
<BR>Proceedings of the Twenty Third International Conference on Machine Learning (<a href="http://www.autonlab.org/icml2006/home.html">ICML 2006</a>), Pittsburgh, PA, June 2006
<BR>[ <a href="/pubs"/2006/maggioni_m_ICML06.pdf">pdf</a> ]

<p><li>Polewan, R.J., Vigorito, C.M., Nason, C.D., Block, R.A., and Moore, J.W. (2006)
<BR><b>A Cartesian Reflex Assessment of Face Processing</b>
<BR><a href="http://bcn.sagepub.com/">Behavioral and Cognitive Neuroscience Reviews</a>, vol. 5(1), pages 3-23
<BR>[ <a href="/pubs"/2006/polewan_vnbm_BCNR06.pdf">pdf</a> ] NOTE: This paper is part of the <a href="http://www-unix.oit.umass.edu/~jwmoore/crp/">UMass Cartesian Reflex Project</a>

<p><li>Mahadevan, S., Maggioni, M., Ferguson, K., and Osentoski., S. (2006)
<BR><b>Learning Representation and Control In Continuous Markov Decision Processes</b>
<BR>Proceedings of The 21st National Conference on Artificial Intelligence <a href="http://www.aaai.org/Conferences/AAAI/aaai06.php">(AAAI-06)</a>, Boston, MA, July 16-20, 2006
<BR>[ <a href="/pubs"/2006/mahadevan_mfo_AAAI06.pdf">pdf</a> ]

<p><li> Ferguson, K. and Mahadevan, S.(2006)
<BR><b> Proto-transfer Learning in Markov Decision Processes Using Spectral Methods</b>
<BR>Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning, Pittsburgh, PA, June 2006
<BR>[ <a href="/pubs"/2006/ferguson_m_ICMLws06.pdf">pdf</a> ]

<p><li>Ferguson, K., Arroyo, A., Mahadevan, S., Woolf, B., and Barto, A.G. (2006)
<BR><b>Improving Intelligent Tutoring Systems: Using Expectation Maximization To Learn Student Skill Levels</b>
<BR>Proceedings of the Eighth International Conference on Intelligent Tutoring Systems <a href="http://www.its2006.org/">(ITS-06)</a>, Jhongli, Taiwan, June 26 - 30, 2006 
<BR>[ <a href="/pubs"/2006/ferguson_amwb_ITS06.pdf">pdf</a> ]

<p><li>Johns, J. and Woolf, B. (2006)
<BR><b>A Dynamic Mixture Model to Detect Student Motivation and Proficiency</b>
<BR>Proceedings of The 21st National Conference on Artificial Intelligence <a href="http://www.aaai.org/Conferences/AAAI/aaai06.php">(AAAI-06)</a>, Boston, MA, July 16-20, 2006
<BR>[ <a href="/pubs"/2006/johns_w_AAAI06.pdf">pdf</a> | <a href="/pubs"/2006/johns_w_AAAI06.ppt">ppt slides</a>]

<p><li>Johns, J., Mahadevan, S., and Woolf, B.(2006)
<BR><b>Estimating Student Proficiency Using an Item Response Theory Model</b>
<BR>Proceedings of the Eighth International Conference on Intelligent Tutoring Systems <a href="http://www.its2006.org/">(ITS-06)</a>, Jhongli, Taiwan, June 26 - 30, 2006
<BR>[ <a href="/pubs"/2006/johns_mw_ITS06.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2006)
<BR><b>An Adaptive Robot Motivational System</b>
<BR>Animals to Animats 9: Proceedings of the 9th International Conference on Simulation of Adaptive Behavior (<a href="http://www.sab06.org/">SAB-06</a>), CNR, Roma, Italy, September 25 - 29, 2006.
<BR>[ <a href="/pubs"/2006/konidaris_b_SAB06.pdf">pdf</a> ]

<p><li>Konidaris, G.D. (2006)
<BR><b>A Framework for Transfer in Reinforcement Learning</b>
<BR>Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning, Pittsburgh, PA, June 2006
<BR>[ <a href="/pubs"/2006/konidaris_ICMLws06.pdf">pdf</a> ]

<p><li>Konidaris, G.D. and Barto, A.G. (2006)
<BR><b>Autonomous Shaping: Knowledge Transfer in Reinforcement Learning</b>
<BR>Proceedings of the Twenty Third International Conference on Machine Learning (<a href="http://www.autonlab.org/icml2006/home.html">ICML 2006</a>), Pittsburgh, PA, June 2006
<BR>[ <a href="/pubs"/2006/konidaris_b_ICML06.pdf">pdf</a> ]
<ul>
<p><b>NOTE:</b> an earlier version appeared as a 2005 tech report: Konidaris, G.D. and Barto, A.G. (2005), 
<b> Autoshaping: Learning to Predict Reward for Novel States</b>, 
University of Masschusetts Department of Computer Science Technical Report UM-CS-2005-58, September, 2005 
[ <a href="/pubs"/2005/konidaris_b_TECH05.ps.gz">ps.gz</a> ] 
</ul>

<p><li>Konidaris, G.D. and Barto, A.G. (2006)
<BR><b>Building Portable Options: Skill Transfer in Reinforcement Learning</b>
<BR>University of Massachusetts Department of Computer Science Technical Report UM-CS-2006-17, March, 2006
<BR>[ <a href="/pubs"/2006/konidaris_b_TECH06.pdf">pdf</a> ]

<p><li>Wolfe, A.P. and Barto, A.G. (2006)
<BR><b>Decision Tree Methods for Finding Reusable MDP Homomorphisms</b>
<BR>Proceedings of The 21st National Conference on Artificial Intelligence <a href="http://www.aaai.org/Conferences/AAAI/aaai06.php">(AAAI-06)</a>, Boston, MA, July 16 - 20, 2006
<BR>[ <A href="/pubs"/2006/wolfe_b_AAAI06.pdf">pdf</A> ]
<ul>
<p><b>NOTE:</b> parts of this work were later presented as a poster [ <a href="/pubs"/2006/wolfe_b_WMLws06.pdf">pdf</a> ] at the Women in Machine Learning Workshop, San Diego, CA 2006
</ul>

<p><li>Wolfe, A.P. and Barto, A.G. (2006)
<BR><b>Defining Object Types and Options Using MDP Homomorphisms</b>
<BR>Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning, Pittsburgh, PA, June, 2006
<BR>[ <A href="/pubs"/2006/wolfe_b_ICMLws06.pdf">pdf paper</A> | <A href="/pubs"/2006/wolfe_b_slidesICMLws06.pdf">pdf slides</A> ]

<p><li>Shah, A., Barto, A.G., and Fagg, A.H. (2006)
<BR><b>Biologically-Based Functional Mechanisms of Coarticulation</b><BR>
poster presented at the
<a href="http://ncm-society.org/">Neural Control of Movement
Conference</a>,
May 2-7, 2006, Key Biscayne, FL
<BR>[ <A href="/pubs"/2006/shah_bf_NCM06.pdf">pdf</A> ]

<p><li>
&#350;im&#351;ek, &#214. and Barto, A.G. (2006)<br>
<b>An Intrinsic Reward Mechanism for Efficient Exploration</b> <br>
Proceedings of the Twenty-Third International Conference on Machine
Learning (<a href="http://www.autonlab.org/icml2006/home.html">ICML 06<a/>), Pittsburgh, PA, June, 2006
<br>[ <a href="/pubs"/2006/simsek_b_icml06.pdf">pdf</a> ] 


<p><li>
Ferguson, K. (2006)<br>
<b> Improving Intelligent Tutoring Systems: Using Expectation Maximization To
Learn About Student Skill Levels</b> <br>
University of Masschusetts Department of Computer Science Technical Report
UM-CS-2006-09, February, 2006<br>
[ <a href="/pubs"/2006/ferguson_TR06.pdf">pdf</a> ]
</ul>


<hr>
<A name="2005"></A>
<h3>2005</h3>
<ul>
<p><li>
Barto, A.G. and &#350;im&#351;ek, &#214. (2005)<br>
<b>Intrinsic Motivation for reinforcement learning systems.</b> <br>
Proceedings of the Thirteenth Yale Workshop on Adaptive and Learning Systems<br>
[ <a href="/pubs"/2005/barto_s_yale05.pdf">pdf</a> ] 

<p><li>Ghavamzadeh, M. (2005)<br>
<b>Hierarchical Reinforcement Learning in Continuous State and Multi-Agent Environments</b><br>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.<br>
[ <a href="/pubs"/2005/ghavamzadeh_thesis05.pdf">pdf</a> ]

<p><li>Jonsson, A. (2005)<br>
<b>A Causal Approach to Hierarchical Decomposition in Reinforcement Learning</b><br>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.<br>
[ <a href="/pubs"/2005/jonsson_thesis05.pdf">pdf</a> ]

<A name="Konidaris_Barto_TECH_UM-CS-2005-58"></A>
<p><li>
Konidaris, G.D. and Barto, A.G. (2005)<br>
<b> Autoshaping: Learning to Predict Reward for Novel States</b> <br>
University of Masschusetts Department of Computer Science Technical Report UM-CS-2005-58, September, 2005<br>
[ <a href="/pubs"/2005/konidaris_b_TECH05.ps.gz">ps.gz</a> ] 
<ul>
<p><b>NOTE:</b> a later version appeared in ICML-06: Konidaris, G.D. (2006)
<b>Autonomous Shaping: Knowledge Transfer in Reinforcement Learning</b>
Proceedings of the Twenty Third International Conference on Machine Learning (<a href="http://icml2006.org">ICML 2006</a>), Pittsburgh, PA, June 2006
[ <a href="/pubs"/2006/konidaris_b_ICML06.pdf">pdf</a> ]
</ul>

<p><li>
Stout, A., Konidaris, G.D., and Barto, A.G. (2005)<br>
<b>Intrinsically Motivated Reinforcement Learning: A Promising Framework For Developmental Robot Learning</b> <br>
Proceedings of the AAAI <a href="http://mainline.brynmawr.edu/DevRob05/">Spring Symposium on Developmental Robotics</a>, Stanford University, Stanford, CA, March 21-23, 2005.<br>
[ <a href="/pubs"/2005/stout_kb_AAAIssdr05.pdf">pdf</a> ] 

<p><li>
Jonsson, A. and Barto, A.G. (2005)<br>
<b>A Causal Approach to Hierarchical Decomposition of Factored MDPs</b> <br>
Proceedings of the Twenty-Second International Conference on Machine Learning <a href="http://icml2005.kdnet.org/icml.php">ICML 05</a>, Bonn, Germany, August 7-13<br>
[ <a href="/pubs"/2005/jonsson_b_ICML05.pdf">pdf</a> | <a href="/pubs"/2005/jonsson_b_ICML05.ps">ps</a> ] 

<p><li>
Mahadevan, S. (2005)<br>
<b>Representation Policy Iteration: A Unified Framework for Learning Representation and Behavior</b> <br>
Invited talk given at National Conference on Artificial Intelligence <a href="http://www.aaai.org/">AAAI05</a>, Pittsburgh, PA, July 9-13, 2005<br>
[ <a href="/pubs"/2005/mahadevan_talkAAAI05.pdf">pdf slides</a> ] 

<p><li>
Rohanimanesh, K. and Mahadevan, S. (2005)<br>
<b>Coarticulation: An Approach for Generating Concurrent Plans in Markov Decision Processes</b> <br>
Proceedings of the Twenty-Second International Conference on Machine Learning <a href="http://icml2005.kdnet.org/icml.php">ICML 05</a>, Bonn, Germany, August 7-13<br>
[ <a href="/pubs"/2005/rohanimanesh_m_ICML05.pdf">pdf</a> | <a href="/pubs"/2005/rohanimanesh_m_ICML05.ps">ps</a> ] 

<p><li>
Mahadevan, S. and Maggioni, M.(2005)<br>
<b>Value Function Approximation using Diffusion Wavelets and Laplacian Eigenfunctions</b> <br>
University of Massachusetts, Department of Computer Science Technical Report TR-2005-38, 2005 <br>
[ <a href="/pubs"/2005/mahadevan_m_TECH05.pdf">pdf</a> ] 

<p><li>
Maggioni, M. and Mahadevan, S.(2005)<br>
<b>Fast Direct Policy Evaluation Using Multiscale Markov Diffusion Processes</b> <br>
University of Massachusetts, Department of Computer Science Technical Report TR-2005-39, 2005 <br>
[ <a href="/pubs"/2005/maggioni_m_TECH05.pdf">pdf</a> ] 

<p><li>
Theocharous, G., Mahadevan, S., and Kaelbling, L (2005)<br>
<b>Spatial and Temporal Abstraction in POMDPs for Robot Navigation</b> <br>
submitted (soon to appear as MIT CSAIL TR) <br>
[ <a href="/pubs"/2005/theocharous_mk_mitTECH05.ps.gz">ps.gz</a> ] 

<p><li>
Johns, J.  and Mahadevan, S. (2005)<br>
<b>A Variational Learning Algorithm for the Abstract Hidden Markov Model</b> <br>
Proceedings of the National Conference on Artificial Intelligence <a href="http://www.aaai.org/">AAAI05</a>, Pittsburgh, PA, July 9-13, 2005<br>
[ <a href="/pubs"/2005/johns_m_AAAI05.pdf">pdf</a> ] 

<p><li>
Mahadevan, S. (2005)<br>
<b>Samuel Meets Amarel: Automating Value Function Approximation using Global State Space Analysis</b> <br>
Proceedings of the National Conference on Artificial Intelligence <a href="http://www.aaai.org/">AAAI05</a>, Pittsburgh, PA, July 9-13, 2005<br>
[ <a href="/pubs"/2005/mahadevan_AAAI05.pdf">pdf</a> ] 

<p><li>
Mahadevan, S. (2005)<br>
<b>Representation Policy Iteration</b> <br>
Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence <a href="http://www.cs.toronto.edu/uai2005/">UAI05</a>, Edinburgh, Scotland, July 26-29, 2005<br>
[ <a href="/pubs"/2005/mahadevan_UAI05.pdf">pdf</a> ] 

<p><li>
Mahadevan, S. (2005)<br>
<b>Proto-Value Functions: Developmental Reinforcement Learning</b> <br>
Proceedings of the International Conference on Machine Learning <a href="http://icml2005.kdnet.org/icml.php">ICML05</a>, Bonn, Germany, August 7-13, 2005<br>
[ <a href="/pubs"/2005/mahadevan_ICML05.pdf">pdf</a> ] 

<p><li>
Manfredi, V. and Mahadevan, S. (2005)<br>
<b>Hierarchical Reinforcement Learning using Graphical Models</b> <br>
ICML Workshop on Rich Representation for Reinforcement Learning, Bonn, August 7th, 2005.<br>
[ <a href="/pubs"/2005/manfredi_m_ICMLws05.pdf">pdf</a> ] 

<p><li>
Manfredi, V. and Mahadevan, S. (2005)<br>
<b>Dynamic Abstraction Networks</b> <br>
University of Massachusetts, Amherst, Technical Report TR 2005-33, 2005 <br>
[ <a href="/pubs"/2005/manfredi_m_TECH05.ps">ps</a> ] 

<p><li>
Manfredi, V. and Mahadevan, S. (2005)<br>
<b>Kalman Filters for Prediction and Tracking in an Adaptive Sensor Network</b> <br>
University of Massachusetts, Amherst, Technical Report 2005-7, 2005 <br>
[ <a href="/pubs"/2005/manfredi_m_TECH05b.ps">ps</a> ] 

<p><li>
Jonsson, A.,  Johns, J., Mehranian, H., Arroyo, I.,  Woolf, B.,  Barto, A.G., Fisher, D., and  Mahadevan, S.(2005)<br>
<b>Evaluating the Feasibility of Learning Student Models from Data</b> <br>
AAAI Workshop on Educational Data Mining, Pittsburgh, PA, July 9, 2005<br>
[ <a href="/pubs"/2005/jonsson_jmawbfm_AAAIws05.ps">ps</a> ] 

<p><li>
&#350;im&#351;ek, &#214., Wolfe, A.P., and Barto, A.G. (2005)<br>
<b>Identifying useful subgoals in reinforcement learning by local graph partitioning.</b> <br>
Proceedings of the Twenty-Second International Conference on Machine Learning <a href="http://icml2005.kdnet.org/icml.php">ICML 05</a>, Bonn, Germany, August 7-13<br>
[ <a href="/pubs"/2005/simsek_wb_ICML05.pdf">pdf</a> | <a href="/pubs"/2005/simsek_wb_ICML05bibtex.txt">bibtex</a> ] 

<p><li>
Berthier, N. E., Rosenstein, M. T., and Barto, A. G. (2005)<br>
<b>Approximate Optimal Control as a Model for Motor Learning</b><br>
<a href="http://www.apa.org/journals/rev/">Psychological Review</a>  vol. 112, pages 329 - 346

</ul>


<hr>
<A name="2004"></A>
<h3>2004</h3>
<ul>
<p><li>
Ghavamzadeh, M. and Mahadevan, S. (2004)<BR>
<b>Hierarchical Multiagent Reinforcement Learning</b><BR>
Technical Report UM-CS-2004-02, Department of Computer Science, University of Massachusetts, Amherst, MA<BR>
[ <a href="/pubs"/2004/ghavamzadeh_m_TECH04.ps">ps</a> | <a href="/pubs"/2004/ghavamzadeh_m_TECH04.pdf">pdf</a> ]

<p><li>
Singh, S., Barto, A.G., and Chentanez, N. (2004)<BR>
<b>Intrinsically Motivated Reinforcement Learning</b><BR>
18th Annual Conference on Neural Information Processing Systems (<a href="http://www.nips.cc/">NIPS</a>), Vancouver, B.C., Canada, December 2004<BR>
[ <a href="/pubs"/2004/singh_bc_NIPS04.pdf">pdf</a> ]

<p><li>
Barto, A.G., Singh, S., and Chentanez, N. (2004)<BR>
<b>Intrinsically Motivated Learning of Hierarchical Collections of Skills</b><BR>
International Conference on Developmental Learning (ICDL), LaJolla, CA, USA <BR>
[ <a href="/pubs"/2004/barto_sc_ICDL04.pdf">pdf</a> ]

<p><li>
&#350;im&#351;ek, &#214;., Wolfe, A.P., and Barto, A.G. (2004)<BR>
<b>Local Graph Partitioning as a Basis for Generating Temporally-Extended Actions in Reinforcement Learning</b><BR>
In  Proceedings of the AAAI-04 Workshop on Learning and Planning in Markov Processes - Advances and Challenges 2004.<BR>
[ <a href="/pubs"/2004/simsek_wb_AAAI04.ps">ps</a> | <a href="/pubs"/2004/simsek_wb_AAAI04.pdf">pdf</a> | <a href="/pubs"/2004/simsek_wb_AAAI04bibtex.txt">bibtex</a> ] 

<p><li>
Osentoski, S., Manfredi, V., Mahadevan, S. (2004)<BR>
<b>Learning Hierarchical Models of Activity</b><BR>
<a href="http://www.informatik.uni-trier.de/~ley/db/conf/iros/iros2004.html">IEEE/RSJ International Conference on Robots and Systems</a> (IROS 2004)<BR>
[ <a href="/pubs"/2004/osentoski_mm_IROS04.pdf">pdf</a> ]

<A name="2"></A>
<p><li>Si. J., Barto, A. G., Powell, W. B., Wunch D., editors. (2004)<br>
<b>Handbook of Learning and Approximate Dynamic Programming</b><BR>
<a href="http://www.wiley.com/WileyCDA/">Wiley</a>-<a href="http://www.ieee.org/organizations/pubs/press/">IEEE Press</a>, Piscataway, NJ.<BR>
[ <a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-047166054X.html">publishers website for this book</a> ]


<p><li>
Barto, A.G. and Dietterich, T.G. (2004)<BR>
<b>Reinforcement Learning and Its Relationship to Supervised Learning</b><BR>
In Si, J., Barto, A.G., Powell, W.B., and Wunsch, D., editors, 
<a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-047166054X.html">Handbook of Learning and Approximate Dynamic Programming</a>, 
Chapter 2, pages 47 - 64. 
<a href="http://www.wiley.com/WileyCDA/">Wiley</a>-<a href="http://www.ieee.org/organizations/pubs/press/">IEEE Press</a>, Piscataway, NJ.
<BR>[ <a href="/pubs"/2004/barto_d_04.pdf">pdf</a> ]

<p><li>
Mahadevan, S.,  Ghavamzadeh, M.,  Rohanimanesh, K., and Theocharous G. (2004)<BR>
<b>Hierarchical Approaches to Concurrency, Multiagency, and Partial Observability</b><BR>
In Si, J., Barto, A.G., Powell, W.B., and Wunsch, D., editors, 
<a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-047166054X.html">Handbook of Learning and Approximate Dynamic Programming</a>, 
Chapter 11, pages 285 - 310. 
<a href="http://www.wiley.com/WileyCDA/">Wiley</a>-<a href="http://www.ieee.org/organizations/pubs/press/">IEEE Press</a>, Piscataway, NJ.

<p><li>
Rosenstein, M.T. and Barto, A.G.(2004)<BR>
<b>Supervised Actor-Critic Reinforcement Learning</b><BR>
In Si, J., Barto, A.G., Powell, W.B., and Wunsch, D., editors, 
<a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-047166054X.html">Handbook of Learning and Approximate Dynamic Programming</a>,
Chapter 14, pages 359 - 380. 
<a href="http://www.wiley.com/WileyCDA/">Wiley</a>-<a href="http://www.ieee.org/organizations/pubs/press/">IEEE Press</a>, Piscataway, NJ.
<BR>[ <a href="/pubs"/2004/rosenstein_b_ADP04.pdf">pdf</a> ]

<p><li> Rosenstein, M.T. and Barto, A.G. (2004)
<BR><b>Reinforcement learning with supervision by a stable controller</b>
<BR>Proceedings of the 2004 American Control Conference, pages 4517-4522
<BR>NOTE: for an expanded version of this work, see the book chaper just above (Supervised Actor-Critic Reinforcement Learning).


<p><li>
Rohanimanesh, K., Platt, R., Mahadevan, S., and Grupen, R (2004)<BR>
<b>Coarticulation in Markov Decision Processes</b><BR>
18th Annual Conference on Neural Information Processing Systems (<a href="http://www.nips.cc/">NIPS</a>), Vancouver, B.C., Canada, December 2004<BR>
[ <a href="/pubs"/2004/rohanimanesh_pmg_NIPS04.ps">ps</a> ]

<p><li>
Rohanimanesh, K., Platt, R., Mahadevan, S., and Grupen, R (2004)<BR>
<b>A Framework for Coarticulation in Markov Decision Processes</b><BR>
Technical Report 04-33, Department of Computer Science, University of Massachusetts, Amherst, Massachusetts<BR>
[ <a href="/pubs"/2004/rohanimanesh_pmg_TECH04.ps">ps</a> | <a href="/pubs"/2004/rohanimanesh_pmg_TECH04.pdf">pdf</a> ]

<p><li>
&#350;im&#351;ek, &#214;. and 
Barto, A.G. (2004)
<BR><b>Using Relative Novelty to Identify Useful Temporal Abstractions
in Reinforcement Learning</b><BR>
Proceedings of the <a href="http://www.informatik.uni-trier.de/~ley/db/conf/icml/icml2004.html">Twenty-First International
Conference on Machine Learning</a> (ICML 2004).<BR>
[ <a href="/pubs"/2004/simsek_b_ICML04.ps">ps</a> | <a href="/pubs"/2004/simsek_b_ICML04.pdf">pdf</a> | <a href="/pubs"/2004/simsek_b_ICML04bibtex.txt">bibtex</a>]

<p><li>
Ghavamzadeh, M. and
Mahadevan, S. (2004)
<BR><b>Learning to Act and Communicate in Cooperative Multiagent Systems using Hierarchical Reinforcement Learning</b><BR>
<a href="http://www.aamas-conference.org/">Autonomous Agents and
Multiagent Systems</a> (AAMAS 2004).<BR>
[ <a href="/pubs"/2004/ghavamzadeh_m_AAMAS04.pdf">pdf</a> ]

<p><li>
Saria, S. and 
Mahadevan, S. (2004)
<BR><b>Probabilistic Plan Recognition in Multiagent Systems</b><BR>
International Conference on AI and Planning Systems (ICAPS 2004).<BR>
[ <a href="/pubs"/2004/saria_m_ICAPS04.pdf">pdf</a> ]

<p><li>
Shah, A., Fagg, A. H., and Barto, A. G. (2004)
<BR><b>Cortical Involvement in the Recruitment of Wrist Muscles</b><BR>
<a href="http://jn.physiology.org/">Journal of Neurophysiology</a>  vol. 91, pages 2445 - 2456<BR>
[ <a href="/pubs"/2004/shah_fb_JNP04.pdf">pdf</a> ]

<p><li>Ravindran, B. and Barto, A.G. (2004)
<BR><b>Approximate Homomorphisms: A Framework for Non-exact Minimization in Markov Decision Processes</b>
<BR>
Proceedings of the Fifth International Conference on Knowledge Based Computer Systems (KBCS 04), Hyderabad, India, December 19--22
<BR>[ <a href="/pubs"/2004/ravindran_b_KBCS04.pdf">pdf</a> ]

<p><li>Ravindran, B. (2004) <BR>
<b>An Algebraic Approach to Abstraction in Reinforcement Learning</b><BR>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.
<br>[ <a href="/pubs"/2004/ravindran_thesis04.pdf">pdf</a> ]
</ul>


<hr>
<A name="2003"></A>
<h3>2003</h3>
<ul>
<p><li>
Ghavamzadeh, M., Mahadevan, S., and Makar, R. (2003)<BR>
<b>Extending Hierarchical Reinforcement Learning to Continuous-Time, Average-Reward, and Multi-Agent Models</b><BR>
Technical Report UM-CS-2003-23, Department of Computer Science, University of Massachusetts, Amherst, MA<BR>
[ <a href="/pubs"/2003/ghavamzadeh_mm_TECH03.ps">ps</a> | <a href="/pubs"/2003/ghavamzadeh_mm_TECH03.pdf">pdf</a> ]

<p><li>
Ghavamzadeh, M. and Mahadevan, S. (2003)<BR>
<b>Hierarchical Average Reward Reinforcement Learning</b><BR>
Technical Report UM-CS-2003-19, Department of Computer Science, University of Massachusetts, Amherst, MA<BR>
[ <a href="/pubs"/2003/ghavamzadeh_m_TECH03.ps">ps</a> | <a href="/pubs"/2003/ghavamzadeh_m_TECH03.pdf">pdf</a> ]

<p><li>
Barto, A. G. and 
Mahadevan, S. (2003)
<BR><b>Recent Advances in Hierarchical Reinforcement Learning</b><BR>
Discrete Event Dynamic Systems vol. 13(4), pages 341 - 379<BR>
[ <a href="/pubs"/2003/barto_m_DEDS03.pdf">pdf</a> ]

<p><li>Rosenstein, M.T. (2003) 
<BR><b>Learning To Exploit Dynamics For Robot Motor Coordination</b><BR>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.
<br>[ <a href="/pubs"/2003/rosenstein_thesis03.html">abstract</a> | <a href="/pubs"/2003/rosenstein_thesis03.pdf">pdf</a> ]


<p><li>Ghavamzadeh, M., Mahadevan, S. (2003) 
<BR><b>Hierarchical Policy Gradient Algorithms</b><BR>Proceedings of 
the <a href="http://www.hpl.hp.com/conferences/icml03/">Twentieth
International Conference on Machine Learning</a> 
(ICML 2003).
<br>[ <a href="/pubs"/2003/ghavamzadeh_m_ICML03.pdf">pdf</a> ]

<p><li>Ravindran, B. and Barto, A. G. (2003) 
<BR><b>Relativized Options: Choosing the Right
Transformation</b><BR> 
Proceedings of the <a href="http://www.hpl.hp.com/conferences/icml03/">Twentieth
International Conference on Machine Learning</a> (ICML 2003)
<br>[ <a href="/pubs"/2003/ravindran_b_ICML03.pdf">pdf</a> ]

<p><li> Ravindran, B. and Barto, A.G. (2003) 
<BR><b>SMDP Homomorphisms: An Algebraic Approach to
Abstraction in Semi Markov Decision Processes</b><BR> 
The Proceedings of the Eighteenth
International Joint Conference on
Artificial Intelligence (<a href="http://www.ijcai-03.org/">IJCAI-03</a>).
<br>[ <a href="/pubs"/2003/ravindran_b_IJCAI03.pdf">pdf</a> ]

<p><li> Ravindran, B. and Barto, A. G. (2003) <BR><b>An Algebraic Approach to
Abstraction in Reinforcement Learning</b><BR> In the
Proceedings of the Twelfth Yale Workshop on Adaptive and Learning Systems, pp. 109-114, Yale University.
<br>[ <a href="/pubs"/2003/ravindran_b_WALS03.pdf">pdf</a> ]
</ul>


<hr>
<A name="2002"></A>
<h3>2002</h3>
<ul>
<p><li>Barto, A. G. (2002)
<br><b>Reinforcement learning</b><br>
In <a href="http://mitpress.mit.edu/catalog/item/default.asp?sid=8037ABEE-1C53-48D3-80B1-37AFFA766876&ttype=2&tid=9184">Handbook of Brain Theory and Neural Networks, Second Edition</a> M.A. Arbib (Ed.), pages 963-968.
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>Barto, A. G. (2002)
<br><b>Reinforcement learning in motor control</b><br>
In <a href="http://mitpress.mit.edu/catalog/item/default.asp?sid=8037ABEE-1C53-48D3-80B1-37AFFA766876&ttype=2&tid=9184">Handbook of Brain Theory and Neural Networks, Second Edition</a> M.A. Arbib (Ed.), pages 968-972.
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>McGovern, Amy </a>, 
Moss, Eliot, and 
Andrew G. Barto (2002) 
<BR><b>Building a Basic Block Instruction Scheduler using Reinforcement Learning and Rollouts</b><BR> 
Machine Learning, Special Issue on Reinforcement Learning.  
Volume 49, Numbers 2/3, Pages 141-160.
<BR>[ <a href="/pubs"/2002/mcgovern_mb_MLJ02.ps">ps</a> (200K) |
 <a href="/pubs"/2002/mcgovern_mb_MLJ02.ps.gz">gzipped ps</a> (60K) |
 <a href="/pubs"/2002/mcgovern_mb_MLJ02.pdf">pdf</a> (160K)]

<p><li>Fagg, A. H., Shah, A., and Barto, A. G. (2002)
<BR><b>A Computational Model of Muscle Recruitment for Wrist Movements</b><BR>
<a href="http://jn.physiology.org/">Journal of Neurophysiology</a>, 88:3348 - 3358
<BR>[ <a href="/pubs"/2002/fagg_sb_JNP02.pdf">pdf</a> ]

<p><li>Perkins, T.J. (2002)
<BR><b>Lyapunov Methods for Safe Intelligent Agent Design</b><BR>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2002/perkins_thesis02.ps">ps</a> |
 <a href="/pubs"/2002/perkins_thesis02.pdf">pdf</a> ]

<p><li>Perkins, T.J. and Barto, A.G. (2002)
<BR><b>Lyapunov Design for Safe Reinforcement Learning</b>
<BR>Journal of Machine Learning Research <a href="http://jmlr.csail.mit.edu/">(JMLR)</a>, vol. 3, pg 803--832, 2002.
<BR>[ <A href="/pubs"/2002/perkins_b_JMRL02.pdf">pdf</A> ]


<p><li>Rohanimanesh, K., and Mahadevan, S. (2002)<BR>
<b>Learning to Take Concurrent Actions</b><BR>
16th Annual Conference on Neural Information Processing Systems (<a href="http://www.nips.cc/">NIPS</a>), Vancouver, Canada, December 2002<BR>
[ <a href="/pubs"/2002/rohanimanesh_m_NIPS02.ps">ps</a> ]

<p><li>McGovern, Amy (2002)
<BR><b>Autonomous Discovery of Temporal Abstractions from Interaction with an Environment</b><BR>
PhD Dissertation, Department of Computer Science, University of Massachusetts Amherst.
<BR>[ <a href="/pubs"/2002/mcgovern_thesis02.ps">ps</a> |
 <a href="/pubs"/2002/mcgovern_thesis02.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2002/mcgovern_thesis02.pdf">pdf</a> ]

<p><li>Pickett, M., and
 Barto, A. G (2002)
<BR><b>PolicyBlocks: An Algortithm for Creating Useful Macro-Actions in Reinforcement Learning</b><BR>
In Proceedings of the <a href="http://www.cse.unsw.edu.au/~icml2002/">Nineteenth International Conference of Machine Learning</a>
<br>[ <a href="/pubs"/2002/pickett_b_ICML02.ps">ps</a> ]

<p><li>Perkins, T.J., and
Pendrith, M.D. (2002)
<BR><b>On the Existence of Fixed Points for Q-Learning and Sarsa in Partially Observable Domains</b><BR>
In Proceedings of the <a href="http://www.cse.unsw.edu.au/~icml2002/">Nineteenth International Conference of Machine Learning</a>,
pp. 490--497.
<BR>[ <a href="/pubs"/2002/perkins_p_ICML02.ps">ps</a> |
 <a href="/pubs"/2002/perkins_p_ICML02.pdf">pdf</a> ]

<p><li>Perkins, T.J. (2002)
<BR><b>Reinforcement Learning for POMDPs based on Action Values and Stochastic Optimization</b><BR>
In Proceedings of the 
<a href="http://www.aaai.org/Conferences/AAAI/aaai02.php">
Eighteenth National Conference on Artificial Intelligence</a>,
pp. 199--204.
<BR>[ <a href="/pubs"/2002/perkins_AAAI02.ps">ps</a> |
 <a href="/pubs"/2002/perkins_AAAI02.pdf">pdf</a> ]

<p><li> Ravindran, B. and Barto, A. G. (2002) 
<BR><b>Model Minimization in Hierarchical Reinforcement
Learning</b><BR> In the Proceedings of the <a
href="http://www.cs.ualberta.ca/~holte/SARA2002/">Fifth
Symposium on Abstraction, Reformulation and Approximation</a>
(SARA 2002), pp.196-211, <a
href="http://www.springer.de/comp/lncs/index.html">LNCS</a>, Springer
Verlag.
<BR>[ <a href="/pubs"/2002/ravindran_b_SARA02.pdf.gz">gzipped pdf</a> ]

<p><li>Bernstein, D.S.,
Perkins, T.J.,
Zilberstein, S., and
Finkelstein, L. (2002)
<BR><b>Scheduling Contract Algorithms on Multiple Processors</b><BR>
In Proceedings of the 
<a href="http://www.aaai.org/Conferences/AAAI/aaai02.php">
Eighteenth National Conference on Artificial Intelligence</a>,
pp. 702--706.
<BR>[ <a href="/pubs"/2002/bernstein_pzf_AAAI02.ps">ps</a> |
 <a href="/pubs"/2002/bernstein_pzf_AAAI02.pdf">pdf</a> ]

<p><li>Shah, A.,
Fagg, A. H., and
Barto, A. G. (2002)
<BR><b>Cortical Involvement in the Recruitment of Wrist Muscles</b><BR>
poster presented at the 
<a href="http://ncm-society.org/">Neural Control of Movement Conference</a>,
April 14-21, 2002, Naples, FL
<BR>[ <a href="/pubs"/2002/shah_fb_NCM02.html">abstract</a> | <A href="/pubs"/2002/shah_fb_NCM02.pdf">pdf</A> ]

<p><li>Kositsky, M. and Barto, A.G. (2002)
<BR><b>The emergence of movement units through learning with noisy efferent signals and delayed sensory feedback</b><BR>
<A HREF="http://ees.elsevier.com/neucom/">Neurocomputing</A>, 44-46, pp. 889-895, 2002.
<BR>[ <A href="/pubs"/2002/kositsky_b_NC02.pdf">pdf</a> ]

<p><li>Kositsky, M. and Barto, A.G. (2002)
<BR><b>Emergence of Multiple Movement Units in the Presence of Noise and Feedback Delay</b><BR>
in Dietterich, T.G., Becker, S., and Ghahramani, Z. (eds.) Advances in Neural Information Processing Systems 14 (<A HREF="http://www.nips.cc">NIPS</a>) 2002.
<BR>[ <A href="/pubs"/2002/kositsky_b_NIPS02.pdf">pdf</a> ]

<p><li>Rosenstein, M.T. and Grupen, R.A. (2002)
<BR><b><a href="/pubs"/2002/rosenstein_g_IEEE02.html">Velocity-dependentdynamic manipulability</a></b><BR> 
In Proceedings of the IEEE International
Conference on Robotics and Automation, vol 3, 2424-2429.
XGGG 
<BR>[ <a href="/pubs"/2002/rosenstein_g_IEEE02.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2002/rosenstein_g_IEEE02.pdf">pdf</a> ]

<p><li>Ghavamzadeh, M., Mahadevan, S. (2002) 
<BR><b>Hierarchically Optimal Average Reward Reinforcement
Learning</b><BR>Proceedings of the Nineteenth International
Conference on Machine Learning (ICML-2002).
<BR>[ <A href="/pubs"/2002/ghavamzadeh_m_ICML02.ps">ps</a> ]

<p><li>Ghavamzadeh, M., Mahadevan, S. (2002) 
<BR><b>A Multiagent Reinforcement Learning Algorithm by Dynamically Merging
Markov Decision Processes</b><BR>Proceedings of the First
International Joint Conference on Autonomous Agents & Multiagent
Systems (AAMAS-2002)
<BR>[ <A href="/pubs"/2002/ghavamzadeh_m_AAMAS02.ps">ps</a> ]

<p><li>Arbib, M. A., Fagg, A. H., and Grafton, S. T. (2002) 
<BR><b>Synthetic PET Imaging for Grasping: From Primate Neurophysiology to Human Behavior</b><BR> in Explorative analysis and data modelling in functional neuroimaging,(F. Sommer and A. Wichert, Eds.), Cambridge MA: The MIT Press, pp. 231-250.
<BR>[ <A href="/pubs"/2002/arbib_fg_PET02.pdf">pdf</a> ]

<p><li>Houk, J. C., Fagg, A. H., Barto, A. G.  (2002) 
<BR><b>Fractional Power Damping Model of Joint Motion</b><BR> in Progress in Motor Control: Structure-Function Relations in Voluntary Movements,(M. Latash, Ed.), vol II, pages 147-178
<BR>[ <A href="/pubs"/2002/houk_bf_FPD02.ps">ps</a> ]

<p><li>Fagg, A. H. and Weitzenfeld, A. (2002) 
<BR><b> A Model of Primate Visual-Motor Conditional Learning</b><BR> in NSL - Neural Simulation Language: Systems and Applications ,(A. Weitzenfeld, M. A. Arbib, and A. Alexander, Eds.), MIT Press 
<BR>[ <A href="/pubs"/2002/fagg_w_NSL02.ps">ps</a> | 
<A href="/pubs"/2002/fagg_w_NSL02.pdf">pdf</a> ]
</ul>


<hr>
<A name="2001"></A>
<h3>2001</h3>
<ul>
<p><li>Perkins, T.J., and
Barto, A.G. (2001)
<BR><b>Lyapunov-Constrained Action Sets for Reinforcement Learning</b><BR>
In Proceedings of the Eighteenth International Conference on Machine Learning,
pp. 409--416.
<BR>[ <a href="/pubs"/2001/perkins_b_ICML01.ps">ps</a> ]

<p><li>Perkins, T.J., and
Barto, A.G. (2001)
<BR><b>Heuristic Search in Infinite State Spaces Guided by Lyapunov Analysis</b><BR>
In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence,
pp. 242--247.
<BR>[ <a href=pubs/2001/perkins_b_IJCAI01.ps>ps</a> | <a href=pubs/2001/perkins_b_IJCAI01.pdf>pdf</a>]

<p><li>Rosenstein, M.T. and
Barto, A.G. (2001)
<BR><b><a href="/pubs"/2001/rosenstein_b_IJCAI01.html">Robot weightlifting by direct policy search</a></b><BR>
In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence,
vol. 2, 839-844.
<BR>[ <a href="/pubs"/2001/rosenstein_b_IJCAI01.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2001/rosenstein_b_IJCAI01.pdf">pdf</a> ]

<p><li>Rosenstein, M.T. and
Barto, A.G. (2001)
<BR><b>A robotic weightlifter that learns to exploit dynamics</b><BR>
In Studies in Perception and Action VI: Eleventh International Conference on Perception and Action
, 25-28.

<p><li>Rosenstein, M.T. and
Barto, A.G. (2001)
<BR><b>From elementary movements to coordination for a robotic weightlifter</b><BR>
In Abstracts of the Third International Symposium on Progress in Motor Control: From Basic Science to Applications, p. 40.

<p><li>Rohanimanesh, K. and Mahadevan, S. (2001)<BR>
<b>Decision-Theoretic Planning with Concurrent Temporally Extended Actions</b><BR>
17th Conference on Uncertainty in Artificial Intelligence (<a href="http://www.informatik.uni-trier.de/~ley/db/conf/uai/uai2001.html">UAI '01</a>), August 3-5, 2001, University of Washington, Seattle, WA, USA<BR>
[ <a href="/pubs"/2001/rohanimanesh_m_UAI01.ps">ps</a> ]

 <p><li>Ravindran, B. and
Barto, A. G. (2001)
<BR><b>Symmetries and Model Minimization of Markov Decision Processes</b><BR>
Computer Science Technical Report 01-43, University of Massachusetts, Amherst, MA.
<BR>[ <a href="/pubs"/2001/ravindran_b_TECH01.ps.gz">gzipped ps</a> ]

<p><li>McGovern, Amy , and
Andrew G. Barto (2001)
<BR><b>Automatic Discovery of Subgoals in Reinforcement Learning using Diverse Density</b><BR>
In <a href="http://www.ecn.purdue.edu/ICML2001/">2001 International Conference on Machine Learning</a>
<BR>[ <a href="/pubs"/2001/mcgovern_b_ICML01.ps">ps</a> (252K) |
 <a href="/pubs"/2001/mcgovern_b_ICML01.ps.gz">gzipped ps</a> (160K) ]

<p><li>Kositsky, M. and
Barto, A. G. (2001)
<BR><b><a href="/pubs"/2001/kositsky_b_TECH01.html">Nonlinear Damping Dynamics and the Variability of Rapid Aimed Movements</a></b><BR>
Technical Report 01-15, Department of Computer Science, University of Massachusetts, Amherst.
<BR>[ <a href="/pubs"/2001/kositsky_b_TECH01.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2001/kositsky_b_TECH01.pdf.gz">gzipped pdf</a> ]

<p><li>Kositsky, M. and
Barto, A. G. (2001)
<BR><b><a href="/pubs"/2001/kositsky_b_NCM01.html">Nonlinear Damping Dynamics and the Variability of Rapid Aimed Movements</a></b><BR>
Poster presented at the 2001 Conference on
<a href="http://ncm-society.org/">Neural Control of Movement</a>,
Seville, Spain.
<BR>one-page poster: [ <a href="/pubs"/2001/kositsky_b_NCM01.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2001/kositsky_b_NCM01.pdf.gz">gzipped pdf</a> ] 

<p><li>Kositsky, M. and Barto, A. G. (2001)
<BR><b>The emergence of multiple movement through learning with noisy efferent signals and delayed sensory feedback</b><BR>
Tenth Annual <A HREF="http://www.cnsorg.org/">Computational Neuroscience Meeting</A>, San Francisco and Pacific Grove, California, 2001.
<BR>[ <A href="/pubs"/2001/kositsky_b_CNS01.pdf">pdf</a> ]

<p><li>Kositsky, M. and Barto, A. G. (2001)
<BR><b>Reinforcement learning model for noisy environment and delayed feedback: natural emergence of movement units</b><BR>
Fifth International <A HREF="http://cns-web.bu.edu/cns-meeting/conference.html">Conference on Cognitive and Neural Systems</A>, Boston, Massachusetts, 2001.

<p><li>Shah, A., Fagg, A. H., and Barto, A. G. (2001)
<BR><b>A Computational Model of Muscle Recruitment for Wrist Movements</b><BR>
poster presented at
<a href="http://ncm-society.org/">Neural Control of Movement Conference</a>,
March 25-30, 2001, Seville, Spain
<BR>[ <a href="/pubs"/2001/shah_fb_NCM01.html">abstract</a> | <A href="/pubs"/2001/shah_fb_NCM01.pdf">pdf</A> ]

<p><li>Jonsson, A. and
Barto, A. G. (2001)
<BR><b>Automated State Abstraction for Options using the U-Tree Algorithm</b><BR>
In Advances in Neural Processing Information Systems 13, Cambridge, MA: MIT Press.
<BR>[ <a href="/pubs"/2001/jonsson_b_NIPS01.ps.gz">gzipped ps</a> ]

<p><li>Schlesinger, M., and
Parisi, D. (2001)
<BR><b>The agent-based approach:  A new direction for computational models of development</b><BR>
Developmental Review, 21, pp 121--146.
<BR>[ <a href="/pubs"/2001/schlesinger_p_DEVREV01.ps.gz">gzipped ps</a> ]

<p><li>Engelbrecht, S.E. (2001)
<BR><b>Minimum Principles in Motor Control</b><BR>
<a href="http://www.elsevier.com/wps/find/journaldescription.cws_home/622887/description#description">Journal of Mathematical Psychology</a>, 45:497-542.
<BR>[ <a href="/pubs"/2001/engelbrecht_JMPsych01.pdf">pdf</a> | <a href="/pubs"/2001/engelbrecht_JMPsych01.ps">ps</a> ]

<p><li>Ghavamzadeh, M., Mahadevan, S. (2001) <BR><b>
Continuous-Time Hierarchical Reinforcement
Learning</b><BR>Proceedings of the Eighteenth International
Conference on Machine Learning (ICML-2001)
<BR>[ <a href="/pubs"/2001/ghavamzadeh_m_ICML01.ps">ps</a> ]

<p><li>Makar, R., Mahadevan, S., 
Ghavamzadeh, M. (2001) 
<BR><b>Hierarchical Multi-Agent Reinforcement Learning</b><BR>
Proceedings of the Fifth International Conference on
Autonomous Agents 2001.
<BR>[ <a href="/pubs"/2001/makar_mg_ICAA01.ps">ps</a> ]
 
<p><li>Davis, J.A., Fagg, A.H., and
Levine, B.N. (2001) 
<BR><b>Wearable Computers as Packet Transport Mechanisms in Highly-Partitioned Ad-Hoc Networks</b><BR>
Proceedings of the International Symposium on Wearable Computing, Zurich, Switzerland, October 2001, pp. 141-148.
<BR>[ <a href="/pubs"/2001/davis_fl_ISWC01.ps">ps</a> ]
</ul>

<hr>
<A name="2000"></A>
<h3>2000</h3>
<ul>
<p><li>J. Randl&oslash;v,
A.G. Barto, and
M.T. Rosenstein (2000)
<BR><b><a href="/pubs"/2000/randlov_br_ICML00.html">Combining reinforcement learning with a local control algorithm</a></b><BR>
In Proceedings of the Seventeenth International Conference on Machine Learning, 775-782.
<BR>[ <a href="/pubs"/2000/randlov_br_ICML00.ps.gz">gzipped ps</a> |
 <a href="/pubs"/2000/randlov_br_ICML00.pdf">pdf</a> ]

<p><li>Precup, D. (2000)
<BR><b>Temporal Abstraction in Reinforcement Learning</b><BR>
Ph.D. Dissertation, Department of Computer Science, University of Massachusetts, Amherst.
<BR>[ <a href="/pubs"/2000/precup_thesis00.ps.gz">gzipped ps</a> ]

<p><li>R. Moll,
T. Perkins, and
A. Barto (2000)
<BR><b>Machine Learning for Subproblem Selection</b><BR>
Proceedings of the Seventeenth International Conference on Machine Learning
(ICML-2000), P. Langley (Ed.),Morgan Kaufmann, San Francisco,CA, pp. 615-622.
<BR>[ <a href="/pubs"/2000/moll_pb_ICML00.ps">ps</a> ]

<p><li>Precup, D.,
Sutton, R. S. and
Singh, S. (2000)
<BR><b>Eligibility Traces for Off-Policy Policy Evaluation</b><BR>
In Proceedings of the Seventeenth Conference on Machine Learning 
(<A HREF="http://www.informatik.uni-trier.de/~ley/db/conf/icml/icml2000.html">ICML 2000</a>), pp. 759--766. Morgan Kaufman.
<BR>[ <a href="/pubs"/2000/precup_ss_ICML00.ps">ps</a> ]

<p><li>Schlesinger, M., 
Parisi, D., and
Langer, J. (2000)
<BR><b>Learning to reach by constraining the movement search space</b><BR>
Developmental Science, 3, 67-80.
<BR>[ <a href="/pubs"/2000/schlesinger_p_DEVSCI00.ps.gz">gzipped ps</a> ]

<p><li>Berthier, N.E., Barto, A.G., and Schlesinger, M. (2000)
<BR><b>Learning and dynamics</b><BR>
Proceedings of the NSF DARPA Conference on Learning and Development
<BR>[ <a href="/pubs"/2000/berthier_bs_NSFDARPA00.pdf">pdf</a> ]

<p><li>Fagg, A.H. (2000)
<BR><b>A Model of Muscle Geometry for a Two Degree-Of-Freedom Planar Arm</b><BR>Technical Report #00-03, Department of Computer Science, University of Massachusetts, Amherst
<BR>[ <a href="/pubs"/2000/fagg_MSC00.ps">ps</a> ]
</ul>


<hr>
<A name="1999"></A>
<h3>1999</h3>
<ul>
<p><li>R. Moll,
A. Barto,
T. Perkins, and
R. Sutton (1999)
<BR><b>Learning Instance-Independent Value Functions to Enhance Local Search</b><BR>
Advances in Neural Information Processing Systems 11
(NIPS11), M. S. Kearns, S. A. Solla, and D. A. Cohn (Eds.), Cambridge,
MA: MIT Press, 1999, pp. 1017-1023.
<BR>[ <a href="/pubs"/1999/moll_bps_NIPS99.ps">ps</a> ]

<p><li>Sutton, R. S.,
Precup, D., and
Singh, S. (1999)
<BR><b>Between MDPs and semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning</b><BR>
In Artificial Intelligence, vol. 112, pp.181-211.
<BR>[ <a href="/pubs"/1999/sutton_ps_AI99.pdf">pdf</a> | <a href="/pubs"/1999/sutton_ps_AI99.ps.gz">gzipped ps</a> ]
<BR>An earlier version appeared as Technical Report UM-CS-1998-74,
Department of Computer Science, University of Massachusetts,
Amherst, MA 01003-4610.
<BR>[ <a href="/pubs"/1999/sutton_ps_TECH98.ps">ps</a> ]

<p><li>Schlesinger, M., and
Langer, J. (1999)
<BR><b>Infants' developing expectations of possible and impossible tool-use events between ages 8 and 12 months</b><BR>
Developmental Science, 2, 195-205.  
<BR>[ <a href="/pubs"/1999/schlesinger_l_DEVSCI99.ps.gz">gzipped ps</a> ]

<p><li>Schlesinger, M., and
Barto, A. (1999)
<BR><b>Optimal control methods for simulating the perception of causality in young infants</b><BR>
Proceedings of the Twenty First Annual Conference of the Cognitive Science Society,
pp. 625-630. New Jersey: Lawrence Erlbaum.
<BR>[ <a href="/pubs"/1999/schlesinger_b_COGSCI99.ps.gz">gzipped ps</a> ]

<p><li>McGovern, Amy,
Moss, Eliot, and
Barto, Andrew G. (1999)
<BR><b>Basic-block Instruction Scheduling Using Reinforcement Learning and Rollouts</b><BR>
Proceedings of the 1999 <a href="http://ijcai.org/past/ijcai-99/">IJCAI</a> workshop on learning and optimization.  
<BR>[ <a href="/pubs"/1999/mcgovern_mb_IJCAI99.ps">ps</a> ]

<p><li>Sutton, R. S.,
Singh, S.,
Precup, D., and
Ravindran, B. (1999)
<BR><b>Improved Switching among Temporally Abstract Actions</b><BR>
In Advances in Neural Information Processing Systems 11 (Proceedings of <A HREF="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html">NIPS'98</a>),
pp.1066-1072. MIT Press.
<BR>[ <a href="/pubs"/1999/sutton_spr_NIPS99.ps">ps</a> ]

<p><li>McGovern, Amy, and
Moss, Eliot (1999)
<BR><b><a href="/~amy/pubs/mcgovern_moss_nips98.ps">Scheduling Straight-Line Code Using Reinforcement Learning and Rollouts</a></b><BR>
Proceedings of the 11th <a href="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html"> Neural Information Processing Systems Conference (NIPS '98)</a>, pages 903-909.
<BR>[ <a href="/pubs"/1999/mcgovern_m_NIPS98.ps">ps</a> ]


<p><li>Barto, A. G,
Fagg, A. H., Sitkoff, N., and 
Houk, J. C. (1999)
<BR><b>A Cerebellar Model of Timing and Prediction in the Control of Reaching</b><BR>
<a href="http://neco.mitpress.org/">Neural Computation</a>, vol. 11, pp. 565-594.
<BR>[ <a href="/pubs"/1999/barto_fsh_NC99.ps">ps</a> |
 <a href="/pubs"/1999/barto_fsh_NC99.pdf">pdf</a> ]
</ul>


<hr>
<A name="1998"></A>
<h3>1998</h3>
<ul>
<A name="1"></A>
<p><li>Sutton, Richard S., and Barto, Andrew G. (1998)
<BR><b>Reinforcement Learning: An Introduction</b><BR> 
<a href="http://mitpress.mit.edu">MIT Press.</a>
<BR>[ <a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html">HTML Version</a> |
 <a href="http://mitpress.mit.edu/catalog/item/default.asp?sid=E0DAF208-661D-4741-B405-26B2B9C213AD&ttype=2&tid=7548">MIT Press Site</a> for this book ]

<p><li>McGovern, Amy (1998)
<BR><b>acQuire-macros: An Algorithm for Automatically Learning Macro-actions</b><BR>
In the <a href="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html">Neural Information Processing Systems Conference (NIPS '98)</a> workshop on Abstraction and Hierarchy in Reinforcement Learning
<BR>[ <a href="/pubs"/1998/mcgovern_wrkshp_NIPS98.ps">ps</a> ]
     
<p><li>Crites, R.  H., and
Barto, A. G (1998)
<BR><b>Elevator Group Control Using Multiple Reinforcement Learning Agents</b><BR>
Machine Learning 33: 235-262. 
<BR>[ <a href="/pubs"/1998/crites_b_ML98.ps.gz">gzipped ps</a> ]


<p><li>McGovern, Amy, and
Sutton, Richard S. (1998)
<BR><b>Macro-Actions in Reinforcement Learning: An Empirical Analysis</b><BR>
Master's thesis and University of Massachusetts, Amherst Technical Report 98-70
<BR>[ <a href="/pubs"/1998/mcgovern_s_TECH98.ps">ps</a> ]

<p><li>Fagg, A. H., Zelevinsky, L., 
Barto, A. G., and 
Houk, J. C. (1998)
<BR><b><a href="/pubs"/1998/fagg_zbh_NCM98.html">A Pulse-Step Model of Control for Arm Reaching Movements</a></b><BR>
Proceedings of the Spring Meeting on the 
<a href="http://ncm-society.org/">Neural Control of Movement</a>.

<p><li>Fagg, A. H., 
Barto, A. G., and 
Houk, J. C.(1998)
<BR><b>Learning to Reach Via Corrective Movements</b><BR>
Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems,
New Haven, CT.
<BR>[ <a href="http://www.cs.ou.edu/~fagg/papers/1998/yale/yale.ps">ps</a> |
 <a href="http://www.cs.ou.edu/~fagg/papers/1998/yale/html/index.html">html</a> ]

<p><li>McGovern, Amy,
Precup, Doina,
Ravindran, B.,
Singh, Satinder, and
Sutton, Richard S. (1998)
<BR><b>Hierarchical Optimal Control of MDPs</b><BR>
Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems, pp.186-191.
<BR>[ <a href="/pubs"/1998/mcgovern_prs_YALE98.ps">ps</a> ]

<p><li>Sutton, R. S.,
Precup, D., and
 Singh, S. (1998)
<BR><b>Intra-Option Learning about Temporally Abstract Actions</b><BR>
In Proceedings of the Fifteenth International Conference on Machine Learning (<A HREF="http://www.informatik.uni-trier.de/~ley/db/conf/icml/icml1998.html">ICML'98</a>), pp.556-564.
Morgan Kaufman.
<BR>[ <a href="/pubs"/1998/sutton_ps_ICML98.ps">ps</a> ]

<p><li>Precup, D., Sutton, R. S., and Singh, S. (1998)
<BR><b>Theoretical Results  on  Reinforcement  Learning with Temporally Abstract Behaviors</b><BR>
In Machine Learning: ECML-98. <A HREF="http://www.tu-chemnitz.de/informatik/ecml98/">10th European Conference on Machine Learning, Chemnitz, Germany, April 1998</a>. Proceedings,
pp. 382-393. Springer Verlag.
<BR>[ <a href="/pubs"/1998/precup_ss_ECML98.ps">ps</a> ]

<p><li>Precup, D., and Sutton, R. S. (1998)
<BR><b>Multi-Time Models for Temporally Abstract Planning</b><BR> 
In Advances in Neural Information Processing Systems 10 (Proceedings of <A HREF="http://www.cs.cmu.edu/Groups/NIPS/NIPS97/nips97.html">NIPS'97</a>),
pp. 1050-1056. MIT Press.
<BR>[ <a href="/pubs"/1998/precup_s_NIPS97.ps">ps</a> ]

<p><li>Fagg, A. H., Lotspeich, D. L., Hoff, J. Bekey, G. A. (1998)
<BR><b>Rapid Reinforcement Learning for Reactive Control Policy Design for Autonomous Robots</b><BR> in Artificial Life in Robotics , (T. Shibata and T. Fukuda, Eds.)
<BR>[ <a href="/pubs"/1998/fagg_lhb_ALR98.ps">ps</a> | <a href="/pubs"/1998/fagg_lhb_ALR98.pdf">pdf</a>]
</ul>


<hr>
<A name="1997"></A>
<h3>1997</h3>
<ul>
<p><li>McGovern, Amy, Sutton, Richard S., and Fagg, Andrew H. (1997)
<BR><b>Roles of Macro-Actions in Accelerating Reinforcement Learning</b><BR>
1997 Grace Hopper Celebration of Women in Computing.
<BR>[ <a href="/pubs"/1997/mcgovern_sf_GHC97.ps">ps</a> ]

<p><li>Precup, D., Sutton, R. S., and Singh, S. (1997)
<BR><b>Planning with Closed-Loop Macro Actions</b><BR>
In Working Notes of the AAAI Fall Symposium '97 on Model-directed Autonomous Systems, pp. 70-76.
<BR>[ <a href="/pubs"/1997/precup_ss_AAAI97.ps">ps</a> ]

<p><li>Precup, D., and Sutton, R. S. (1997)
<BR><b>Multi-Time Models for Reinforcement Learning</b><BR>
Proceedings of the <A HREF="http://www.cs.cmu.edu/~ggordon/ml97ws/">ICML'97 Workshop on Modelling in Reinforcement Learning</a>.
<BR>[ <a href="/pubs"/1997/precup_s_ICML97ws.ps">ps</a> ]

<p><li>Barto, A.G. and Sutton, R.S. (1997)
<br><b>Reinforcement Learning in Artificial Intelligence</b>
<br>in Neural-Network Models of Cognition, Volume 121: Biobehavioral Foundations (Advances in Psychology) (eds. Donahoe, J.W. and Dorsel, V.P.), Elsevier, North-Holland, The Netherlands.
<BR>[ <a href="/pubs"/1997/barto_s_97.pdf">pdf</a> ] 

<p><li>Precup, D., and Sutton, R. S. (1997)
<BR><b>Exponentiated Gradient Methods for Reinforcement Learning</b><BR>
Proceedings of the 14th International Conference on Machine Learning, ICML'97,
Morgan Kaufmann, pp.272-277.
<BR>[ <a href="/pubs"/1997/precup_s_ICML97.ps">ps</a> ]

<p><li>R. E. Kettner, S. Mahamud, H. -C. Leung, N. Sitkoff, Houk, J. C., B. W. Peterson, and Barto, A. G. (1997)
<BR><b>Prediction of Complex Two-Dimensional Trajectories by the Eye and by a Cerebellar Model of Smooth Eye Movements</b><BR>
<A href="http://jn.physiology.org/">Journal of Neurophysiology</a>, 77:2115-2130
<BR>[ <a href="/pubs"/1997/kettner_mlshpb_JNP97.ps">ps</a> |
 <a href="/pubs"/1997/kettner_mlshpb_JNP97.pdf">pdf</a> ]

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997)
<BR><b>Cerebellar Learning for Control of a Two-Link Arm in Muscle Space</b><BR>
Proceedings of the IEEE Conference on Robotics and Automation, May, pp. 2638-2644.
<BR>[ <a href="/pubs"/1997/fagg_sbh_IEEE97.ps.gz">gzipped ps</a> ]

<p><li>Fagg, A. H., Zelevinsky, L., Barto, A. G., and Houk, J. C. (1997)
<BR><b>Using Crude Movements to Learn Accurate Motor Programs for Reaching</b><BR> Presented at the <a href="http://www.nips.cc">NIPS</a> workshop: Can Artificial Cerebellar Models Compete to Control Robots? Dec. 5, Breckenridge, CO.
<BR>[ <a href="/pubs"/1997/fagg_zbh_NIPS97.ps">ps</a> ]

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997)
<BR><b><A HREF="http://www.cs.ou.edu/~fagg/papers/1997/ncm.97.html">A Computational Model of Cerebellar Learning for Limb Control</A></b><BR>
Proceedings of the Spring 1997 Meeting of the <a href="http://ncm-society.org/">Neural Control of Movement</a>.
<BR>[ <a href="/pubs"/1997/fagg_sbh_NCM97.ps.gz">gzipped ps poster text</a> ]

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997)
<BR><b>A Model of Cerebellar Learning for Control of Arm Movements Using Muscle Synergies</b><BR>
Proceedings of the IEEE International Symposium on Computational Intelligence in Robotics and Automation, July 10-11, pp. 6-12.<BR>[ <a href="/pubs"/1997/fagg_sbh_IEEE97b.ps.gz">gzipped ps</a> ]

<p><li>A. H. Fagg, N. Sitkoff, A. G. Barto, and Houk, J. C. (1997)
<BR><b>Cerebellar Learning for Control of a Two-Link Arm in Muscle Space</b><BR> Proceedings of the IEEE Conference on Robotics and Automation (ICRA), May, pages 2638-2644.
<BR>[ <a href="/pubs"/1997/fagg_sbh_ICRA97.ps.gz">gzipped ps</a> ]
</ul>


<hr>
<A name="1996"></A>
<h3>1996</h3>
<ul>
<p><li>Bradke, S.J. and Barto, A.G.  (1996)
<BR><b>Linear Least-Squares Algorithms for Temporal DIfference Learning</b><BR>
Machine Learning 22(1-3):33--57, 1996
<BR>[ <a href="/pubs"/1995_96/bradtke_b_ML96.pdf">pdf</a> ]

<p><li>Singh, S.P. and Sutton, R.S. (1996)<br>
<b>Reinforcement Learning with Replacing Eligibility Traces</b><br>
Machine Learning 22(1-3):123--158, 1996
<BR>[ <a href="/pubs"/1995_96/singh_s_ML96.pdf">pdf</a> ]

<p><li>Precup, D., and Sutton, R. S. (1996)
<BR><b>Empirical Comparison of Gradient Descent and Exponentiated Gradient Descent in Supervised and Reinforcement Learning</b><BR>
Technical Report UM-CS-1996-070, Department of Computer Science,
University of Massachusetts, Amherst, MA 01003.
<BR>[ <a href="/pubs"/1995_96/precup_s_TECH96.ps">ps</a> ]

<p><li>Houk, J.C., Buckingham,  J.T., and Barto, A.G. (1996)
<BR><b>Models of the Cerebellum and Motor Learning</b><BR>
<a href="http://www.bbsonline.org/bbsprints.html">Behavioral and Brain Sciences<a> vol. 19, pages 368-383.
<BR>[ <a href="/pubs"/1995_96/houk_bb_BBS96.pdf">pdf</a> | 
<a href="/pubs"/1995_96/houk_bb_BBS96.ps">ps</a> ] (<B>NOTE</B>: These are pdf/ps copies of an unofficial online version that does not include figures. They were provided to give you an idea of the paper, but please go through the journal for the official version. Thanks.)

<p><li>Hansen, E.A., Barto, A.G., and Zilberstein, S. (1996)
<BR><b>Reinforcement Learning for Mixed Open-Loop and Closed-Loop Control</b><BR>
Proceedings from the Ninth Annual Neural Information Processing Systems Conference (<a href="http://nips.cc/">NIPS</a>), Denver, Colorado, USA
<BR>[ <a href="/pubs"/1995_96/hansen_bz_NIPS96.pdf">pdf</a> ]
</ul>

<hr>
<A name="1995"></A>
<h3>1995</h3>
<ul>
<p><li>A. G. Barto, J. T. Buckingham, and Houk, J. C. (1995)
<BR><b>A Predictive Switiching Model of Cerebellar Movement Control</b><BR>
Neural Information Processing Systems 8, MIT Press, 1995, pp. 138-144.
<BR>[ <a href="/pubs"/1995_96/barto_bh_NIPS95.ps.gz">gzipped ps</a> ]

<p><li>R. H. Crites, and A. G. Barto (1995)
<BR><b>Improving Elevator Performance Using Reinforcement Learning</b><BR>
Neural Information Processing Systems 8, MIT Press, 1995, pp. 1017-1023.
<BR>[ <a href="/pubs"/1995_96/crites_b_NIPS95.ps.Z">zipped ps</a> ]

<p><li>Houk, J. C., J. L. Adams, and Barto, A. G. (1995)
<BR><b>A model of how the basal ganglia generates and uses neural signals that predict reinforcement</b><BR>
In <a href="http://mitpress.mit.edu/catalog/item/default.asp?sid=01D398C6-F7C5-47FD-A518-E241F26DF9EA&ttype=2&tid=8362">Models of Information Processing in the Basal Ganglia</a>,
J. C. Houk, J. Davis, and D. Beiser (Eds.), Cambridge, MA: <a href="http://mitpress.mit.edu/">MIT Press</a>, 1995,
pp. 249-270.

<p><li>A. G. Barto (1995)
<BR><b>Adaptive critics and the basal ganglia</b><BR>
In <a href="http://mitpress.mit.edu/catalog/item/default.asp?sid=01D398C6-F7C5-47FD-A518-E241F26DF9EA&ttype=2&tid=8362">Models of Information Processing in the Basal Ganglia</a>,
J. C. Houk, J. Davis, and D. Beiser (Eds.), Cambridge, MA: <a href="http://mitpress.mit.edu/">MIT Press</a>, 1995,
pp. 215-232.
<BR>[ <a href="/pubs"/1995_96/barto_BGbook95.ps">ps</a> |
 <a href="/pubs"/1995_96/barto_BGbook95.pdf">pdf</a> ] (note: this version is missing one figure) 

<p><li>J. T. Buckingham, Barto, A. G., and Houk, J. C. (1995)
<BR><b>Adaptive Predictive Control with a Cerebellar Model</b><BR>
In Proceedings of the 1995 World Congress on Neural Networks, Volume 1,
Lawrence Erlbaum Associates, Inc: Mahwah, NJ, 1995,  pp. 373-380

<p><li>M. Duff (1995)
<BR><b>Q-Learning for bandit problems</b><BR>
In A. Prieditis and S. Russell, editors,
Machine Learning:  Proceedings of the Twelfth International Conference on Machine Learning (ML95),
Morgan Kaufmann: Tahoe City, CA, 1995, pp. 209-217.

<p><li>Barto, A. G. (1995)
<BR><b>Reinforcement learning and dynamic programming</b><BR> 
Presented at IFAC'95, Conference on Man-Machine Systems,
Cambridge, MA, June 1995.

<p><li>A. G. Barto, S. J. Bradtke, and S. P. Singh (1995)
<BR><b>Learning to act using real-time dynamic programming</b><BR>
Artificial Intelligence,
Special Volume on Computational Research on Interaction and Agency,
<BR>72(1): 81-138, 1995.
<BR>[ <a href="/pubs"/1995_96/barto_bs_AI95.ps.gz">gzipped ps</a> ]
<ul><li>(Reprinted in Computational Theories of Interaction and Agency,
P. E. Agre & S. J. Rosenschein (Eds.), Cambridge, MA: MIT Press, 1996.)
<li>(Also appeared as CMPSCI Technical Report 93-02, University of
Massachusetts, January 1993.  (Supercedes TR 91-57.))
</ul>

<p><li>Crites RH, and Barto, A. G. (1995)
<BR><b>An Actor/Critic Algorithm that is Equivalent to Q-Learning</b><BR>
NIPS 7.
<BR>[ <a href="/pubs"/1995_96/crites_b_95.pdf">pdf</a> ]

<p><li>Bradtke, Steven J. and Duff, Michael O. (1995)
<BR><b>Reinforcement Learning Methods for Continuous-Time Markov Decision Problems</b><BR>
NIPS 7.
<BR>
</ul>

<hr>
<A name="1994"></A>
<h3>1994</h3>
<ul>
<p><li>Singh, S. P. (1994)
<BR><b>Learning to Solve Markovian Decision Processes</b><BR>
Ph.D Thesis
<BR>[ <a href="/pubs"/1994/singh_THESIS94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P., Jaakkola, T., and Jordan, M. (1994)
<BR><b>Reinforcement Learning With Soft State Aggregation</b><BR>
NIPS-7 
<BR>[ <a href="/pubs"/1994/singh_jj_NIPS94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P. (1994)
<BR><b>Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes</b><BR>
AAAI-94
<BR>[ <a href="/pubs"/1994/singh_AAAI94.ps.Z">zipped ps</a> ]

<p><li>Singh, S. P., Jaakkola, T., and Jordan, M. (1994)
<BR><b>Learning Without State-Estimation in Partially Observable Markovian Decision Processes</b><BR>
ML-94
<BR>[ <a href="/pubs"/1994/singh_jj_ML94.ps.Z">zipped ps</a> ]

<p><li>Sutton, R. S., and Singh, S. P. (1994)
<BR><b>On Step-Size and Bias in Temporal-Difference Learning</b><BR>
Eighth Yale Workshop
<BR>[ <a href="/pubs"/1994/sutton_s_YALE94.ps.Z">zipped ps</a> ]

<p><li>Jaakkola, T., Jordan, M., and Singh, S. P. (1994)
<BR><b>On the Convergence of Stochastic Iterative Dynamic Programming Algorithms</b><BR>
Neural Computation
<BR>[ <a href="/pubs"/1994/jaakkola_js_NC94.ps.Z">zipped ps</a> ]

<p><li>J. T. Buckingham, J. C. Houk, and A. G. Barto (1994)
<BR><b>Controlling a nonlinear spring-mass system with a cerebellar model</b><BR>
8th Yale Workshop on Adaptive and Learning Systems,
Yale University, June 1994.  pp. 1-6.

<p><li>S. J. Bradtke, A. G. Barto, and B. E. Ydstie (1994)
<BR><b>A reinforcement learning method for direct adaptive linear quadratic control</b><BR>
8th Yale Workshop on Adaptive and Learning Systems,
Yale University, June 1994.  pp. 85-96.

<p><li>V. Gullapalli and A. Barto (1994)
<BR><b>Convergence of indirect adaptive asynchronous value iteration algorithms</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 695-702.

<p><li>A. Barto and M. Duff (1994)
<BR><b>Monte Carlo matrix inversion and reinforcement learning</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 687-694.

<p><li>S. P. Singh, A. G. Barto, R. Grupen, and C. Connolly (1994)
<BR><b>Robust reinforcement learning in motion planning</b><BR>
In Advances in Neural Information Processing Systems 6,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994.  pp. 655-662.

<p><li>V. Gullapalli, A. G. Barto, and R. A. Grupen (1994)
<BR><b>Learning admittance mappings for force-guided assembly</b><BR>
Proceedings of the 1994 International Conference on Robotics and Automation,
1994, pp. 2633-2638.

<p><li>V. Gullapalli, J. A. Franklin, and H. Benbrahim (1994)
<BR><b>Acquiring robot skills via reinforcement learning</b><BR>
IEEE Control Systems Special Issue on Robotics: Capturing Natural Motion, 4(1): 13-24, Feb. 1994.

<p><li>Grupen RA, Coelho, J. A., Connolly, C. I., Gullapalli, V., Huber, M., and
Souccar, K. (1994)
<BR><b>Toward Physical Interaction and Manipulation: Screwing in a Light Bulb</b><BR>
AAAI 1994 Spring Symposium on Physical Interaction and Manipulation. 
<BR>[ <a href="/pubs"/1994/grupen_ccghs_AAAI94.ps.Z">zipped ps</a> ](large file)

<p><li>T. W. Sandholm and R. H. Crites (1994)
<BR><b>Multiagent Reinforcement Learning in the Iterated Prisoner's Dilemma</b><BR>
Submitted to Biosystems Journal, November 1994.

<p><li>S. J. Bradtke and A. G. Barto (1994)
<BR><b>New Algorithms for Temporal Difference Learning</b><BR>
Machine Learning, 108, Special Issue on Reinforcement Learning.

<p><li>Singh, S. P., and
Yee, R. C. (1994)
<BR><b>An Upper Bound on the Loss from Approximate Optimal-Value Functions</b><BR>
Machine Learning
<BR>[ <a href="/pubs"/1994/singh_y_ML94.ps.Z">zipped ps</a> ]

<p><li>Barto, A. G. (1994)
<BR><b>Reinforcement Learning Control</b><BR>
Current Opinion in Neurobiology, 4:888-893, 1994.

<p><li>V. Gullapalli (1994)
<BR><b>Skillful Control Under Uncertainty via Direct Reinforcement Learning</b><BR>
(Submitted to Robotics and Autonomous Systems.)

<p><li> N. Berthier, R. Clifton, V. Gullapalli, D. McCall, and D. Rubin (1994)
<BR><b>Visual information and object size in the control of reaching</b><BR>
(Submitted.)

<p><li>V. Gullapalli (1994)
<BR><b>Direct associative reinforcement learning methods for dynamic systems control</b><BR>
(Submitted to Neurocomputing.)

<p><li>S. J. Bradtke (1994)
<BR><b>Incremental Dynamic Programming for On-Line Adaptive Optimal Control</b><BR>
(Ph.D. Thesis) CMPSCI Technical Report 94-62, University of Massachusetts,
August 1994.

<p><li>Barto, A. G. (1994)
<BR><b>Learning as hillclimbing in weight space</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>Barto, A. G. (1994)
<BR><b>Reinforcement learning in motor control</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>Barto, A. G.(1994)
<BR><b>Reinforcement Learning</b><BR>
In Handbook of Brain Theory and Neural Networks, M.A. Arbib (Ed.),
Cambridge: <a href="http://mitpress.mit.edu">MIT Press.</a>.

<p><li>M. Duff (1994)
<BR><b>Solving Bellman's Equation by the method of continuity</b><BR>  
Proceedings of the 1994 American Control Conference, Baltimore, June 1994.

<p><li>S. J. Bradtke, B. E. Ydstie, and A. G. Barto (1994)
<BR><b>Adaptive linear quadratic control using policy iteration</b><BR>
CMPSCI Technical Report 94-49, University of Massachusetts, June 1994.
Submitted to IEEE Transactions on Automatic Control, April 1994.

<p><li>S. Bradtke and M. Duff (1994)
<BR><b>Reinforcement learning methods for continuous-time Markov decision problems</b><BR>
7th Annual Conference on Neural Information Processing Systems (NIPS 7),
November 1994.
</ul>

<hr>

<h3><a href="comp.html">before 1994</a></h3>

</div>
</div>
</div>

<HR>

<ul id="footer">
  <li>[ <a href="#top"><i>Top of page</i></a> ] &nbsp;</li>
  <li>[ <a href="../index.html"><i>ALL Home</i></a> ] &nbsp;</li>
  <li>[ <a href="http://www.cs.umass.edu/"><i>School of CS</i></a> ] &nbsp;</li>
  <li>[ <a href="http://www.umass.edu/"><i>UMass Amherst</i></a> ]</li>
</ul>

</div>

</BODY>
</HTML>

