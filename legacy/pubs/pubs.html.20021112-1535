<HTML>
<HEAD>
<TITLE>Publications Autonomous Learning Laboratory</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">

<TABLE WIDTH=100% BORDER=0>
<TR WIDTH=100% HEIGHT=80 VALIGN=TOP><TD COLSPAN=2>
<IMG SRC="../img/all_horiznamesm.gif" border=0>
</TD></TR>

<TR><TD WIDTH=100 ALIGN=LEFT VALIGN=TOP>
<a href="../index.html"><img src="../img/homebutt.gif" border=0></a><BR>
<a href="../about.html"><img src="../img/aboutbutt.gif" border=0></a><BR>
<a href="../people.html"><img src="../img/peoplebutt.gif" border=0></a><BR>
<a href="../research.html"><img src="../img/researchbutt.gif" border=0><BR>
<a href="pubs.html"><img src="../img/publicationsbutt.gif" border=0></a><BR>
<a href="http://www-all.cs.umass.edu/rlr/" target="_top"><img src="../img/rlrepbutt.gif" border=0></a><BR>
<a href="../links.html"><img src="../img/linksbutt.gif" border=0></a><BR>
<a href="http://www.cs.umass.edu"><img src="../img/csdeptbutt.gif" border=0></a><BR>
<a href="../contact.html"><img src="../img/contactbutt.gif" border=0></a><BR>
<a href="../restrict/"><img src="../img/resaccbutt.gif" border=0></a><BR>
</TD>

<TD WIDTH=500>

<!-- insert title of page here -->

<BR>
<H1><FONT SIZE=7><B>Publications</B></FONT></H1>

<!-- insert individual page content here -->


Following is a list of publications in reverse chronological order.  Some
of these items appear both as published papers and as technical
reports, but the title may have changed.  In such cases, to avoid
ambiguity, the citation shown <i>in this list</i> is the proper
citation.  We prefer that you cite the published version over the
technical report.
<p>
Clicking on a highlighted title will allow you to access that paper.
<p>
<a href="comp.html">Comprehensive publications list
(1981-1995)</a>

<ul>

<!--
<p><li><a href="/People/barto/barto.html">Barto AG</a>,1996,
<a href="ftp://ftp.cs.umass.edu/pub/anw/pub/barto/filename.ps">
name of publication</a>,where it appeared.
-->
<!--
<p><li> <a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a> and
 <A HREF="http://www.cs.umass.edu/~rich">Sutton, R. S.</a> (in
preparation), "Roles of Temporally Abstract Actions in
Reinforcement Learning ", <i>Technical Report 98-70</i>, University of
Massachusetts, Amherst.
-->


<BR><BR><HR>
<BR><B>2002</B><BR><BR>

<p><li> <a href="http://www-all.cs.umass.edu/~ravi">Ravindran, B.</a> and 
<a href="http://www-all.cs.umass.edu/People/barto/barto.html">Barto, A. G.</a> 
(2002) &quot;<a
href="http://www-all.cs.umass.edu/~ravi/SARA02.pdf.gz">Model Minimization 
in Hierarchical Reinforcement Learning</a>&quot;. In the
<i>Proceedings of the Fifth Symposium on Abstraction, Reformulation and
Approximation (SARA 2002)</i>, pp.196-211, <a
href="http://www.springer.de/comp/lncs/index.html">LNCS</a>, Springer
Verlag. 
<p><li><a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a> (2002)
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/PerkinsThesis02.ps">Lyapunov Methods for Safe Intelligent Agent Design</a>&quot;.
PhD Dissertation,
<a href="http://www.cs.umass.edu/">Department of Computer Science</a>,
University of Massachusetts Amherst.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a> (2002)
&quot;Autonomous Discovery of Temporal Abstractions from Interaction with an Environment&quot;.
PhD Dissertation,
<a href="http://www.cs.umass.edu/">Department of Computer Science</a>,
University of Massachusetts Amherst.
[<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_barto_mlj00.ps">postscript</a> (200K) |
<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_barto_mlj00.ps.gz">gzipped postscript</a> (60K) |
<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_barto_mlj00.pdf">pdf</a> (160K)]

<p><li><a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a>, and
Pendrith, M.D. (2002)
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/PerPenICML02.ps">On the Existence of Fixed Points for Q-Learning and Sarsa in Partially Observable Domains</a>&quot;.
In <em>Proceedings of the Nineteenth International Conference of Machine Learning</em>,
pp. 490--497.

<p><li><a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a> (2002)
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/PerAAAI02.ps">Reinforcement Learning for POMDPs based on Action Values and Stochastic Optimization</a>&quot;.
In <em>Proceedings of the Eighteenth National Conference on Artificial Intelligence</em>,
pp. 199--204.

<p><li><a href="http://www.cs.umass.edu/~bern">Bernstein, D.S.</a>,
<a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a>,
<a href="http://www.cs.umass.edu/~shlomo">Zilberstein, S.</a>, and
Finkelstein, L. (2002)
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/BPZFAAAI02.ps">Scheduling Contract Algorithms on Multiple Processors</a>&quot;.
In <em>Proceedings of the Eighteenth National Conference on Artificial Intelligence</em>,
pp. 702--706.

<p><li><a href="http://www-all.cs.umass.edu/~ash/">Shah, A.</a>,
<a href="http://www-all.cs.umass.edu/~fagg/">Fagg, A. H.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2002).
&quot;<a href="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM02.html">Cortical Involvement in the Recruitment of Wrist Muscles,</a>&quot;.
poster presented at
<a href="http://www-ncm.cs.umass.edu/"><em>Neural Control of Movement Conference</em></a>,
April 14-21, 2002, Naples, FL;
half-sized (26"x24") poster:
<A HREF="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM02.pdf">pdf</A> file;
<A HREF="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM02.ps">ps</A> file

<p><li><a href="http://www.cs.umass.edu/~mtr">Rosenstein, M.T.</a> and
<a href="http://www.cs.umass.edu/~grupen">Grupen, R.A.</a> (2002).
&quot;<a href="http://www.cs.umass.edu/~mtr/papers/RosensteinM02.html">Velocity-dependent dynamic manipulability</a>&quot;.
In <em>Proceedings of the IEEE International Conference on Robotics and Automation</em>, to appear.

<BR><BR><HR>
<BR><B>2001</B><BR><BR>

<p><li><a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A.G.</a> (2001).
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/PerBarICML01.ps">Lyapunov-Constrained Action Sets for Reinforcement Learning</a>&quot;.
In <em>Proceedings of the Eighteenth International Conference on Machine Learning</em>,
pp. 409--416.

<p><li><a href="http://www.mcb.mcgill.ca/~perkins">Perkins, T.J.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A.G.</a> (2001).
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/PerBarIJCAI01.ps">Heuristic Search in Infinite State Spaces Guided by Lyapunov Analysis</a>&quot;.
In <em> Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence</em>,
pp. 242--247.

<p><li><a href="http://www.cs.umass.edu/~mtr">Rosenstein, M.T.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A.G.</a> (2001).
&quot;<a href="http://www.cs.umass.edu/~mtr/papers/RosensteinM01.html">Robot weightlifting by direct policy search</a>&quot;.
In <em>Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence</em>,
vol. 2, 839-844.

<p><li><a href="http://www.cs.umass.edu/~mtr">Rosenstein, M.T.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A.G.</a> (2001).
&quot;A robotic weightlifter that learns to exploit dynamics&quot;.
In <em>Studies in Perception and Action VI: Eleventh International Conference on Perception and Action</em>
, 25-28.

<p><li><a href="http://www.cs.umass.edu/~mtr">Rosenstein, M.T.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A.G.</a> (2001).
&quot;From elementary movements to coordination for a robotic weightlifter&quot;.
In <em>Abstracts of the Third International Symposium on Progress in Motor Control: From Basic Science to Applications</em>, p. 40.

<p> <li><a href="http://www-all.cs.umass.edu/~ravi">Ravindran, B.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2001).
&quot;<A href="http://www-all.cs.umass.edu/~ravi/TR01-43.ps.gz">Symmetries and Model Minimization of Markov Decision Processes</a>&quot;.
Computer Science Technical Report 01-43, University of Massachusetts, Amherst, MA.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy </a>, and
<a href="http://www.cs.umass.edu/~barto">Andrew G. Barto</a> (2001).
&quot;Automatic Discovery of Subgoals in Reinforcement Learning using Diverse Density&quot;.
In <em><a href="http://www.ecn.purdue.edu/ICML2001/">2001 International Conference on Machine Learning</a></em>
[<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_barto_icml2001.ps">postscript</a> (252K) |
<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_barto_icml2001.ps.gz">gzipped postscript</a> (160K)]
</p>

<p><li><a href="http://www-all.cs.umass.edu/~kositsky/">Kositsky, M.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2001).
&quot;<a href="http://www-all.cs.umass.edu/~kositsky/TR-01-15/TR-01-15.html">Nonlinear Damping Dynamics and the Variability of Rapid Aimed Movements</a>&quot;.
Technical Report 01-15, Department of Computer Science, University of Massachusetts, Amherst.

<p><li><a href="http://www-all.cs.umass.edu/~kositsky/">Kositsky, M.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2001).
&quot;<a href="http://www-all.cs.umass.edu/~kositsky/NCM-01/NCM-01.html">Nonlinear Damping Dynamics and the Variability of Rapid Aimed Movements</a>&quot;.
Poster presented at the 2001 Conference on
<em><a href="http://www-ncm.cs.umass.edu/">Neural Control of Movement</a></em>,
Seville, Spain.

<!--
<p><li><a href="http://www-all.cs.umass.edu/~ash/">Shah, A.</a>,
<a href="http://www-all.cs.umass.edu/~fagg/">Fagg, A. H.</a>, and
<a href="http://www-all.cs.umass.edu/People/barto/barto.html">Barto,
A. G.</a> (2001)
" <a href="http://www-all.cs.umass.edu/~ash/pubs/NCM_01.html">A
Computational Model of Muscle Recruitment for Wrist Movements,</a>", 
poster to be presented at
<a href="http://www-ncm.cs.umass.edu/"><em>Neural Control of Movement
Conference</em></a>, March 25-30, 2001, Seville, Spain
-->

<p><li><a href="http://www-all.cs.umass.edu/~ash/">Shah, A.</a>,
<a href="http://www-all.cs.umass.edu/~fagg/">Fagg, A. H.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2001).
&quot;<a href="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM01.html">A Computational Model of Muscle Recruitment for Wrist Movements,</a>&quot;.
poster presented at
<a href="http://www-ncm.cs.umass.edu/"><em>Neural Control of Movement Conference</em></a>,
March 25-30, 2001, Seville, Spain;
half-sized (18"x31") poster:
<A HREF="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM01.pdf">pdf</A> file;
<A HREF="http://www-all.cs.umass.edu/~ash/pubs/sfbNCM01.ps">ps</A> file


<p><li><a href="http://www-all.cs.umass.edu/~ajonsson">Jonsson, A.</a> and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (2001).
&quot;<a href="http://www-all.cs.umass.edu/papers/2000/JonssonBartoUTree2001.ps.gz">Automated State Abstraction for Options using the U-Tree Algorithm</a>&quot;.
In <em>Advances in Neural Processing Information Systems 13</em>, Cambridge, MA: MIT Press.

<p><li><a href="http://www.siu.edu/~matthew">Schlesinger, M.</a>, and
<a href="http://gral.ip.rm.cnr.it/parisi">Parisi, D.</a> (2001).
&quot;<a href="http://www-all.cs.umass.edu/papers/2000/SchlesingerParisiAgentBased2000.ps.gz">The agent-based approach:  A new direction for computational models of development</a>&quot;.
<em>Developmental Review, 21,</em> pp 121--146.
 
<BR><BR><HR>
<BR><B>2000</B><BR><BR>
 
<p><li>J. Randl&oslash;v,
<a href="http://www.cs.umass.edu/~barto">A.G. Barto</a>, and
<a href="http://www.cs.umass.edu/~mtr">M.T. Rosenstein</a> (2000).
&quot;<a href="http://www.cs.umass.edu/~mtr/papers/RandlovJ00.html">Combining reinforcement learning with a local control algorithm</a>&quot;.
In <em>Proceedings of the Seventeenth International Conference on Machine Learning</em>, 775-782.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a> (2000).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Dissertation.ps.gz">Temporal Abstraction in Reinforcement Learning</a>&quot;.
Ph.D. Dissertation,
<A HREF="http://www.cs.umass.edu">Department of Computer Science</a>,
University of Massachusetts, Amherst.

<p><li><a href="http://www.cs.umass.edu/~moll/">R. Moll</a>,
<a href="http://www.mcb.mcgill.ca/~perkins/">T. Perkins</a>, and
<a href="http://www.cs.umass.edu/~barto">A. Barto</a> (2000).
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/MPBICML00.ps">Machine Learning for Subproblem Selection</a>&quot;.
<em>Proceedings of the Seventeenth International Conference on Machine Learning</em>
(ICML-2000), P. Langley (Ed.),
Morgan Kaufmann, San Francisco, CA, 2000, pp. 615-622.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>,
<A HREF="http://www.cs.umass.edu/~rich">Sutton, R. S.</a> and
<A HREF="http://www.eecs.umich.edu/~baveja/">Singh, S.</a> (2000).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-Singh-ICML00.ps">Eligibility Traces for Off-Policy Policy Evaluation</a>&quot;.
In <i>Proceedings of the Seventeenth Conference on Machine Learning (<A HREF="http://www-csli.stanford.edu/icml2k">ICML 2000</a>)</i>, pp. 759--766. Morgan Kaufman.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>,
<A HREF="http://www.cs.umass.edu/~moss">Moss, Eliot</a>, and
<a href="http://www.cs.umass.edu/~barto">Andrew G. Barto</a> (2000).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_barto_mlj00.ps">Building a Basic Block Instruction Scheduler using Reinforcement Learning and Rollouts</a>&quot;.
<em>Machine Learning, Special Issue on Reinforcement Learning</em>

<p><li><a href="http://www.siu.edu/~matthew/">Schlesinger, M.</a>, 
<a href="http://gral.ip.rm.cnr.it/parisi">Parisi, D.</a>, and
Langer, J. (2000).
&quot;<a href="http://www-all.cs.umass.edu/papers/2000/SchlesingerParisiLearning2000.ps.gz">Learning to reach by constraining the movement search space,</a>&quot;.
<em>Developmental Science, 3,</em> 67-80.

<BR><BR><HR>
<BR><B>1999</B><BR><BR>

<p><li><a href="http://www.cs.umass.edu/~moll/">R. Moll</a>,
<a href="http://www.cs.umass.edu/~barto">A. Barto</a>,
<a href="http://www.mcb.mcgill.ca/~perkins/">T. Perkins</a>, and
<a href="http://www-all.cs.umass.edu/~rich/sutton.html">R. Sutton</a> (1999).
&quot;<a href="http://www.mcb.mcgill.ca/~perkins/publications/MBPSNIPS98.ps">Learning Instance-Independent Value Functions to Enhance Local Search</a>&quot;.
<em>Advances in Neural Information Processing Systems 11</em>
(NIPS11), M. S. Kearns, S. A. Solla, and D. A. Cohn (Eds.), Cambridge,
MA: MIT Press, 1999, pp. 1017-1023.

<p><li><A HREF="http://www.cs.umass.edu/~rich">Sutton, R. S.</a>,
<A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www.eecs.umich.edu/~baveja/">Singh, S.</a> (1999).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Sutton-Precup-Singh-AIJ99.ps.gz">Between MDPs and semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning</a>&quot;.
In <i>Artificial Intelligence</i>, vol. 112, pp.181-211.<br>
An earlier version appeared as
<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/SPS-98.ps">Technical Report UM-CS-1998-74</a>,
Department of Computer Science, University of Massachusetts,
Amherst, MA 01003-4610.

<p><li><a href="http://www.siu.edu/~matthew/">Schlesinger, M.</a>, and
Langer, J. (1999).
&quot;<a href="http://www-all.cs.umass.edu/papers/1990/SchlesingerLangerInfants1999.ps.gz">Infants' developing expectations of possible and impossible tool-use events between ages 8 and 12 months</a>&quot;.
<em>Developmental Science, 2,</em> 195-205.  

<p><li><a href="http://www.siu.edu/~matthew/">Schlesinger, M.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A.</a> (1999).
&quot;<a href="http://www-all.cs.umass.edu/papers/1990/SchlesingerBartoOptimal1999.ps.gz">Optimal control methods for simulating the perception of causality in young infants</a>&quot;.
<em>Proceedings of the Twenty First Annual Conference of the Cognitive Science Society</em>,
pp. 625-630. New Jersey: Lawrence Erlbaum.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>,
<A HREF="http://www.cs.umass.edu/~moss">Moss, Eliot</a>, and
<A HREF="http://www.cs.umass.edu/~barto">Barto, Andrew G.</a> (1999).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_barto_ijcai99.ps">Basic-block Instruction Scheduling Using Reinforcement Learning and Rollouts</a>&quot;.
<em>Proceedings of the 1999 <a href="http://www.dsv.su.se/ijcai-99/">IJCAI</a> workshop on learning and optimization</em>.  

<p><li><A HREF="http://www.cs.umass.edu/~rich">Sutton, R. S.</a>,
<A HREF="http://www.eecs.umich.edu/~baveja/">Singh, S.</a>,
<A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www.cs.umass.edu/~ravi">Ravindran, B.</a> (1999).
&quot;<A HREF="http://www-all.cs.umass.edu/papers/1990/SuttonSinghImprovedSwitching1999.ps">Improved Switching among Temporally Abstract Actions</a>&quot;.
In <i>Advances in Neural Information Processing Systems 11 (Proceedings of <A HREF="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html">NIPS'98</a>)</i>,
pp.1066-1072. MIT Press.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>, and
<A HREF="http://www.cs.umass.edu/~moss">Moss, Eliot</a> (1999).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_moss_nips98.ps">Scheduling Straight-Line Code Using Reinforcement Learning and Rollouts</a>&quot;.
<em>Proceedings of the 11th <a href="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html"> Neural Information Processing Systems Conference (NIPS '98)</a></em>, pages 903-909.</p>

<BR><BR><HR>
<BR><B>1998</B><BR><BR>

<p><li><a href="http://www-all.cs.umass.edu/~rich">Sutton, Richard S.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, Andrew G.</a> (1998).
&quot;<a href="http://www-all.cs.umass.edu/~rich/book/the-book.html">Reinforcement Learning: An Introduction</a>&quot;, MIT Press.

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a> (1998).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_nips98_workshop.ps">acQuire-macros: An Algorithm for Automatically Learning Macro-actions</a>&quot;.
<em>In the <a href="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html">Neural Information Processing Systems Conference (NIPS '98)</a> workshop on Abstraction and Hierarchy in Reinforcement Learning</em>
     
<p><li><a href="http://www-all.cs.umass.edu/People/crites/crites.html">Crites, R.  H.</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a> (1998).
&quot;<a href="http://www-all.cs.umass.edu/papers/1990/CritesBartoElevator1998.ps.gz">Elevator Group Control Using Multiple Reinforcement Learning Agents</a>&quot;.
<i>Machine Learning</i> 33: 235-262. 


<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>, and
<A HREF="http://www.cs.umass.edu/~rich">Sutton, Richard S.</a> (1998).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern-techrpt-98-70.ps">Macro-Actions in Reinforcement Learning: An Empirical Analysis</a>&quot;.
<em>Master's thesis and University of Massachusetts, Amherst Technical Report 98-70</em>

<p><li>Barto, A. G., Fagg, A. H., Sitkoff, N., and Houk, J. C. (1998).
&quot;A Cerebellar Model of Timing and Prediction in the Control of Reaching&quot;.
submitted to <em>Neural Computation</em>.

<p><li>Fagg, A. H., Zelevinsky, L., Barto, A. G., and Houk, J. C. (1998).
&quot;A Pulse-Step Model of Control for Arm Reaching Movements&quot;.
   <em>Proceedings of the Spring Meeting on the Neural Control of
   Movement</em>.

<p><li>Fagg, A. H., Barto, A. G., and Houk, J. C. (1998).
&quot;Learning to Reach Via Corrective Movements&quot;.
<em>Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems</em>,
New Haven, CT (to appear).

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>,
<a href="http://www.cs.mcgill.ca/~dprecup/">Precup, Doina</a>,
<a href="http://www-all.cs.umass.edu/~ravi">Ravindran, B.</a>,
<a href="http://www.eecs.umich.edu/~baveja/">Singh, Satinder</a>, and
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, Richard S.</a> (1998).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/options-yale98.ps">Hierarchical Optimal Control of MDPs</a>&quot;.
<i>Proceedings of the <A HREF="http://koshy.eng.yale.edu/wals98/">Tenth Yale Workshop on Adaptive and Learning Systems</a></i>, pp.186-191.

<p><li><A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a>,
<A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www.eecs.umich.edu/~baveja/"> Singh, S.</a> (1998).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Sutton-Precup-Singh-ICML98.ps">Intra-Option Learning about Temporally Abstract Actions</a>&quot;.
In <i>Proceedings of the Fifteenth International Conference on Machine Learning (<A HREF="http://www.cs.wisc.edu/icml98/">ICML'98</a>)</i>, pp.556-564.
Morgan Kaufman.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>,
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a>, and
<A HREF="http://www.eecs.umich.edu/~baveja/">Singh, S.</a> (1998).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-Singh-ECML98.ps">Theoretical Results  on  Reinforcement  Learning with Temporally Abstract Behaviors</a>&quot;.
In <i>Machine Learning: ECML-98. <A HREF="http://www.tu-chemnitz.de/informatik/ecml98/">10th European Conference on Machine Learning, Chemnitz, Germany, April 1998</a>. Proceedings</i>,
pp. 382-393. Springer Verlag.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a> (1998).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-NIPS97.ps">Multi-Time Models for Temporally Abstract Planning</a>&quot;. 
In <i>Advances in Neural Information Processing Systems 10 (Proceedings of <A HREF="http://www.cs.cmu.edu/Groups/NIPS/NIPS97/nips97.html">NIPS'97</a>)</i>,
pp. 1050-1056. MIT Press.

<BR><BR><HR>
<BR><B>1997</B><BR><BR>

<p><li><a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy</a>,
<a HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, Richard S.</a>, and
<a HREF="http://www-all.cs.umass.edu/~fagg">Fagg, Andrew H.</a> (1997).
&quot;<a href="http://www-all.cs.umass.edu/~amy/pubs/mcgovern_ghc97.ps">Roles of Macro-Actions in Accelerating Reinforcement Learning</a>&quot;.
<a href="http://www.sdsc.edu/Hopper/">1997 Grace Hopper Celebration of Women in Computing.</a>

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>,
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a>, and
<A HREF="http://www.eecs.umich.edu/~baveja/">Singh, S.</a> (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-Singh-AAAI97.ps">Planning with Closed-Loop Macro Actions</a>&quot;.
In <i>Working Notes of the AAAI Fall Symposium '97 on Model-directed Autonomous Systems</i>, pp. 70-76.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a> (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-ICML97RL.ps">Multi-Time Models for Reinforcement Learning</a>&quot;.
<i>Proceedings of the <A HREF="http://www.cs.cmu.edu/~ggordon/ml97ws/">ICML'97 Workshop on Modelling in Reinforcement Learning</a></i>.

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a> (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/dprecup/Precup-Sutton-ICML97.ps">Exponentiated Gradient Methods for Reinforcement Learning</a>&quot;.
<i>Proceedings of the 14th International Conference on Machine Learning, ICML'97</i>,
Morgan Kaufmann, pp.272-277.

<p><li>R. E. Kettner, S. Mahamud, H. -C. Leung, N. Sitkoff,
J. C. Houk, B. W. Peterson, and A. G. Barto (1997).
&quot;Prediction of Complex Two-Dimensional Trajectories by the Eye and by a Cerebellar Model of Smooth Eye Movements&quot;.
<i>Journal of Neurophysiology,</i> 77: 2115-2130, 1997.

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/fagg/cerebellum/icra.97.ps.gz">Cerebellar Learning for Control of a Two-Link Arm in Muscle Space</A>&quot;.
<em>Proceedings of the IEEE Conference on Robotics and Automation</em>, May, pp. 2638-2644.

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997).
&quot;<A HREF="http://www-all.cs.umass.edu/~fagg/projects/cerebellum/papers/ncm.97.html">A Computational Model of Cerebellar Learning for Limb Control</A>&quot;.
<em>Proceedings of the Spring Meeting on the Neural Control of Movement</em>.

<p><li>Fagg, A. H., Sitkoff, N., Barto, A. G., and Houk, J. C. (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/fagg/cerebellum/cira.97.ps.gz">A Model of Cerebellar Learning for Control of Arm Movements Using Muscle Synergies</A>&quot;.
<em>Proceedings of the IEEE International Symposium on Computational Intelligence in Robotics and Automation</em>, July 10-11, pp. 6-12.

<p><li><a href="http://www-all.cs.umass.edu/~fagg">A. H. Fagg</a>,
N. Sitkoff,
<a href="http://www.cs.umass.edu/~barto">A. G. Barto</A>, and
J. C. Houk (1997).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/fagg/cerebellum/icra.97.ps.gz">Cerebellar Learning for Control of a Two-Link Arm in Muscle Space</A>&quot;. ICRA 97.

<BR><BR><HR>
<BR><B>1996</B><BR><BR>

<p><li><A HREF="http://www.cs.mcgill.ca/~dprecup/">Precup, D.</a>, and
<A HREF="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a> (1996).
&quot;<A HREF="ftp://ftp.cs.umass.edu/pub/techrept/techreport/1996/UM-CS-1996-070.ps">Empirical Comparison of Gradient Descent and Exponentiated Gradient Descent in Supervised and Reinforcement Learning</a>&quot;.
Technical Report UM-CS-1996-070, Department of Computer Science,
University of Massachusetts, Amherst, MA 01003.

<BR><BR><HR>
<BR><B>1995</B><BR><BR>

<p><li><a href="http://www.cs.umass.edu/~barto">A. G. Barto</a>,
J. T. Buckingham, and J. C. Houk (1995).
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/fagg/cerebellum/NIPS95.ps.gz">A Predictive Switiching Model of Cerebellar Movement Control</a>&quot;.
Neural Information Processing Systems 8, MIT Press, 1995, pp. 138-144.

<p><li><a href="http://www-all.cs.umass.edu/People/crites/crites.html">R. H. Crites</a>, and
<a href="http://www.cs.umass.edu/~barto">A. G. Barto</a>
<a name="nips8.ps.Z"> (1995)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/crites/nips8.ps.Z">Improving Elevator Performance Using Reinforcement Learning</a>&quot;.
Neural Information Processing Systems 8, MIT Press, 1995, pp. 1017-1023.

<P><LI>J. C. Houk, J. L. Adams, and A. G. Barto (1995).
&quot;A model of how the basal ganglia generates and uses neural signals that predict reinforcement&quot;.
In <i>Models of Information Processing in the Basal Ganglia,</i>
J. C. Houk, J. Davis, and D. Beiser (Eds.), Cambridge, MA: MIT Press, 1995,
pp. 249-270.

<P><li><a href="http://www.cs.umass.edu/~barto">A. G. Barto</a> (1995).
<!-- <a href="/cgi-bin/getfile/pub/anw/pub/barto/BasalGanglia.ps.Z"> -->
&quot;Adaptive critics and the basal ganglia&quot;.<!-- </a> -->
In <i>Models of Information Processing in the Basal Ganglia,</i>
J. C. Houk, J. Davis, and D. Beiser (Eds.), Cambridge, MA: MIT Press, 1995,
pp. 215-232. (BasalGanglia.ps.Z, 98659 bytes)

<P><LI>J. T. Buckingham, A. G. Barto, and J. C. Houk (1995).
&quot;Adaptive Predictive Control with a Cerebellar Model&quot;.
In <i>Proceedings of the 1995 World Congress on Neural Networks, Volume 1</i>,
Lawrence Erlbaum Associates, Inc: Mahwah, NJ, 1995,  pp. 373-380

<P><LI>M. Duff (1995).
&quot;Q-Learning for bandit problems&quot;.
In A. Prieditis and S. Russell, editors,
<i>Machine Learning:  Proceedings of the Twelfth International Conference on Machine Learning</i> (ML95),
Morgan Kaufmann: Tahoe City, CA, 1995, pp. 209-217.

<P><LI>A. G. Barto (1995).
&quot;Reinforcement learning and dynamic programming&quot;. 
Presented at <i>IFAC'95, Conference on Man-Machine Systems</i>,
Cambridge, MA, June 1995.

<P><LI>A. G. Barto, S. J. Bradtke, and S. P. Singh (1995).
&quot;<a href="http://www-all.cs.umass.edu/papers/1990/BartoBradtkeRealtime1995.ps.gz">Learning to act using real-time dynamic programming</a>&quot;.
<i>Artificial Intelligence</i>,
Special Volume on Computational Research on Interaction and Agency,
<b>72</b>(1): 81-138, 1995.
(Reprinted in Computational Theories of Interaction and Agency,
P. E. Agre & S. J. Rosenschein (Eds.), Cambridge, MA: MIT Press, 1996.)
[Also appeared as CMPSCI Technical Report 93-02, University of
Massachusetts, January 1993.  (Supercedes TR 91-57.)]

<P><LI><a href="http://www-all.cs.umass.edu/People/crites/crites.html">Crites RH</a>, and
<a href="http://www.cs.umass.edu/~barto">Barto, A. G.</a>
<a name="nips7.ps.Z"> (1995)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/crites/nips7.ps.Z">An Actor/Critic Algorithm that is Equivalent to Q-Learning</a>&quot;.
NIPS 7. (nips7.ps.Z: 64695 bytes)

<BR><BR><HR>
<BR><B>1994</B><BR><BR>

<P><li><a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>
<a name="MDPlearn.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/Thesis/MDPlearn.ps.Z">Learning to Solve Markovian Decision Processes</a>&quot;.
Ph.D Thesis, (MDPlearn.ps.Z:  676713 bytes)

<P><LI><a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>,
Jaakkola, T., and Jordan, M.
<a name="singh-nips7.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/singh-nips7.ps.Z">Reinforcement Learning With Soft State Aggregation</a>&quot;.
NIPS-7 (singh-nips7.ps.Z: 89381 bytes)

<p><li><a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>
<a name="singh-AAAI94.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/singh-AAAI94.ps.Z">Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes</a>&quot;.
AAAI-94, (singh-AAAI94.ps.Z: 84885 bytes)

<p><li><a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>,
Jaakkola, T., and Jordan, M.
<a name="singh-ML94.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/singh-ML94.ps.Z">Learning Without State-Estimation in Partially Observable Markovian Decision Processes</a>&quot;.
ML-94, (singh-ML94.ps.Z: 89381 bytes)

<p><li><a href="http://www-all.cs.umass.edu/~rich/sutton.html">Sutton, R. S.</a>, and
<a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>
<a name="Yale94.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/Yale94.ps.Z">On Step-Size and Bias in Temporal-Difference Learning</a>&quot;.
Eighth Yale Workshop, (Yale94.ps.Z: 100075 bytes)

<p><li>Jaakkola, T., Jordan, M., and
<a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>
<a name="Neural-Computation-94.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/Neural-Computation-94.ps.Z">On the Convergence of Stochastic Iterative Dynamic Programming Algorithms</a>&quot;.
Neural Computation, (Neural-Computation-94.ps.Z: 82015 bytes)

<P><LI>J. T. Buckingham, J. C. Houk, and A. G. Barto (1994).
&quot;Controlling a nonlinear spring-mass system with a cerebellar model&quot;.
<i>8th Yale Workshop on Adaptive and Learning Systems</i>,
Yale University, June 1994.  pp. 1-6.

<P><LI>S. J. Bradtke, A. G. Barto, and B. E. Ydstie (1994).
&quot;A reinforcement learning method for direct adaptive linear quadratic control&quot;.
<i>8th Yale Workshop on Adaptive and Learning Systems</i>,
Yale University, June 1994.  pp. 85-96.

<P><LI>V. Gullapalli and A. Barto (1994).
&quot;Convergence of indirect adaptive asynchronous value iteration algorithms&quot;.
In <i>Advances in Neural Information Processing Systems 6</i>,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 695-702.

<P><LI>A. Barto and M. Duff (1994).
&quot;Monte Carlo matrix inversion and reinforcement learning&quot;.
In <i>Advances in Neural Information Processing Systems 6</i>,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994. pp. 687-694.

<P><LI>S. P. Singh, A. G. Barto, R. Grupen, and C. Connolly (1994).
&quot;Robust reinforcement learning in motion planning&quot;.
In <i>Advances in Neural Information Processing Systems 6</i>,
J.D. Cowan, G. Tesauro and J. Alspector (Eds.),
San Francisco: Morgan Kauffmann, 1994.  pp. 655-662.

<P><LI>V. Gullapalli, A. G. Barto, and R. A. Grupen (1994).
&quot;Learning admittance mappings for force-guided assembly&quot;.
<i>Proceedings of the 1994 International Conference on Robotics and Automation</i>,
1994, pp. 2633-2638.

<P><LI>V. Gullapalli, J. A. Franklin, and H. Benbrahim (1994).
&quot;Acquiring robot skills via reinforcement learning&quot;.
<i>IEEE Control Systems</i> Special Issue on Robotics: Capturing Natural Motion,
<b>4</b>(1): 13-24, Feb. 1994.

<P><li><a href="http://www.cs.umass.edu/~grupen">Grupen RA</a>, 
<a href="http://www-robotics.cs.umass.edu/~coelho/home.html">Coelho, J. A.</a>, 
<a href="http://www.ai.sri.com/~connolly/">Connolly, C. I.</a>, 
<a href="http://www-all.cs.umass.edu/People/vijay/vijay.html">Gullapalli, V.</a>, 
<a href="http://ranger.uta.edu/~huber/">Huber, M.</a>, and
<a href="http://www-robotics.cs.umass.edu/~souccar/home.html">Souccar, K.</a>
<a name="aaai-94.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/vijay/aaai-94.ps.Z">Toward Physical Interaction and Manipulation: Screwing in a Light Bulb</a>&quot;.
AAAI 1994 Spring Symposium on Physical Interaction and Manipulation. 
<b>(aaai-94.ps.Z: 3528729 bytes -- warning: contains several images)</b>

<p><LI>T. W. Sandholm and R. H. Crites (1994).
&quot;Multiagent Reinforcement Learning in the Iterated Prisoner's Dilemma&quot;.
Submitted to <i>Biosystems Journal</i>, November 1994.

<P><LI>S. J. Bradtke and A. G. Barto (1994).
&quot;New Algorithms for Temporal Difference Learning&quot;.
<i>Machine Learning,</i> <b>108:</b>
Special Issue on Reinforcement Learning.

<P><li><a href="http://www.eecs.umich.edu/~baveja/">Singh, S. P.</a>, and
Yee, R. C.
<a name="approx-rl-loss.ps.Z"> (1994)</a>.
&quot;<a href="/cgi-bin/getfile/pub/anw/pub/singh/approx-rl-loss.ps.Z">An Upper Bound on the Loss from Approximate Optimal-Value Functions</a>&quot;.
Machine Learning, (approx-rl-loss.ps.Z: 54302 bytes)

<P><LI>A. G. Barto (1994).
&quot;Reinforcement learning control&quot;.
<i>Current Opinion in Neurobiology,</i> <b>4:</b> 888-893, 1994.

<P><LI>V. Gullapalli (1994).
&quot;Skillful Control Under Uncertainty via Direct Reinforcement Learning&quot;.
(Submitted to <em>Robotics and Autonomous Systems</em>.)

<P><LI> N. Berthier, R. Clifton, V. Gullapalli, D. McCall, and D. Rubin (1994).
&quot;Visual information and object size in the control of reaching&quot;.
(Submitted.)

<P><LI>V. Gullapalli (1994).
&quot;Direct associative reinforcement learning methods for dynamic systems control&quot;.
(Submitted to <em>Neurocomputing</em>.)

<P><LI>S. J. Bradtke (1994).
&quot;Incremental Dynamic Programming for On-Line Adaptive Optimal Control&quot;.
(Ph.D. Thesis) CMPSCI Technical Report 94-62, University of Massachusetts,
August 1994.

<P><LI>A. G. Barto (1994).
&quot;Learning as hillclimbing in weight space&quot;.
In <i>Handbook of Brain Theory and Neural Networks,</i> M.A. Arbib (Ed.),
Cambridge: MIT Press.

<P><LI>A. G. Barto (1994).
&quot;Reinforcement learning in motor control&quot;.
In <i>Handbook of Brain Theory and Neural Networks,</i> M.A. Arbib (Ed.),
Cambridge: MIT Press.

<P><LI>A. G. Barto (1994).
&quot;Reinforcement learning&quot;.
In <i>Handbook of Brain Theory and Neural Networks,</i> M.A. Arbib (Ed.),
Cambridge: MIT Press.

<P><LI>M. Duff (1994).
&quot;Solving Bellman's Equation by the method of continuity&quot;.  
<em>Proceedings of the 1994 American Control Conference</em>, Baltimore, June 1994.

<P><LI>S. J. Bradtke, B. E. Ydstie, and A. G. Barto (1994).
&quot;Adaptive linear quadratic control using policy iteration&quot;.
CMPSCI Technical Report 94-49, University of Massachusetts, June 1994.
Submitted to <i>IEEE Transactions on Automatic Control,</i> April 1994.

<P><LI>S. Bradtke and M. Duff (1994).
&quot;Reinforcement learning methods for continuous-time Markov decision problems&quot;.
7th Annual Conference on Neural Information Processing Systems (NIPS 7),
November 1994.
<P>
</ul>


<!-- end content -->

</TD></TR>
</TABLE>


</BODY>
</HTML>
