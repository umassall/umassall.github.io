<html>
<head>
<title>Reinforcement Learning Repository at Michigan State
University</title>
</head>
<body bgcolor="FFFFBB">
<h3>Reinforcement Learning Repository at MSU</h3>
<h2>Demos and Implementations (Domains)</h2>
<p>This section contains application demonstrations, many of which are 
<b>Real-World</b>
<ul>
<li>Interactive demonstration (Java) illustrating the improvement
gained by applying RL to the problem of <a
href=http://envy.cs.umass.edu/People/singh/Demo.html>Dynamic Channel
Allocation in Cellular Telephones</a> by Satinder Singh at the University
of Colorado
</ul>

<b>Toy</b>
<ul>
<li>
<b>Cart-Pole Problem</b>: <br>
<img align=right src=imgs/cartpole-sm.gif>

simulation of the cart and pole dynamic
system and 
 a procedure for learning to balance the pole.  Both are described in 
 Barto, Sutton, and Anderson, "<i>Neuronlike Adaptive Elements That Can
Solve
 Difficult Learning Control Problems," IEEE Trans. Syst., Man, Cybern.,
 Vol. SMC-13, pp. 834--846, Sept.--Oct. 1983</i>

<br>
<a href=http://www.cps.u.ed/rlr/distcode/pole.tar>pole.tar</a>
(16 K, requires C compiler)
<br><br>
<li><b>MDP Q-learning</b>: implements Q-learning on a given MDP, using
semi-uniform exploration.
<a href=http://www.cps.msu.edu/rlr/distcode/mdp-q.tar>mdp-q.tar</a>
(61 K, requires GNU C compiler) 
<li><b>Mountain-Car Problem</b>: <br>
<img align=right src=imgs/carhill-sm.gif>
Simulation of a car learning the proper acceleration to get up a mountain.
</ul>

