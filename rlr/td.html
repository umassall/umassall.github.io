<HTML>
<HEAD>
<META HTTP-EQUIV=REFRESH>
<TITLE>Publications on Temporal Difference Learning</TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<body bgcolor="#FFFFBB">
<CENTER>
<H1>Publications on Temporal Difference Learning</H1>
</CENTER>

<img align=right src="imgs/sower.gif">
<br><hr>

<!nextperson><B>Bandera, 
C.</B>
 , V. Francisco, B. Jose, M. Harmon, and L. Baird<blockquote><A HREF=http://www.leemon.com/papers/icml96/>Residual q-learning applied to visual attention.</A><BR>
<i>Proceedings of the Thirteenth International Conference on Machine Learning, pages 20-27.  Morgan Kaufmann, 1996</i>

( HTML)
<A HREF=http://web.cps.msu.edu/rlr/pub/Bandera1.html>Abstract</A>: 
<BR>Foveal vision features imagers with graded acuity coupled with context
sensitive sensor gaze contro...
</BLOCKQUOTE><HR>

<!nextperson><B>Borkar, 
Vivek</B>
 , Vijaymohan R. Konda( <A
	   HREF=mailto:borkar@csa.iisc.ernet.in>borkar@csa.iisc.ernet.in</A>)<BR>
<blockquote><A HREF=http://web.mit.edu/konda/www/sadhana97.ps>Actor-Critic algorithm as multi-time scale stochastic approximation algorithm</A><BR>
<i>'Sadhana', Indian Academy of Sciences</i>

(Postscript - 561 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Borkar1.html>Abstract</A>: 
<BR>The actor-critic algorithm of Barto et al for simulation-based optimization of Markov decision proce...
</BLOCKQUOTE><HR>
<!nextperson><B>Boyan, 
Justin</B>
 , A. Moore( <A
	   HREF=mailto:Justin.Boyan@cs.cmu.edu>Justin.Boyan@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/afs/cs/project/reinforcement/papers/boyan.acyclic.ps>Learning evaluation functions for large acyclic domains</A><BR>
<i>Proceedings of the Thirteenth International Conference on Machine Learning, pages 63-70.  Morgan Kaufmann, 1996.</i>

(Postscript - 147 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Boyan1.html>Abstract</A>: 
<BR>Some of the most successful recent applications of reinforcement 
learning have used neural network...
</BLOCKQUOTE><HR>

<!nextperson><B>Boyan, 
Justin</B>
 , Michael L. Littman( <A
	   HREF=mailto:jab+@cs.cmu.edu>jab+@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/routing-nips.ps>Packet Routing in Dynamically Changing Networks: A Reinforcement
	Learning Approach</A><BR>
<i>Advances in
 Neural Information Processing Systems</i>

(Postscript - 155KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Boyan3.html>Abstract</A>: 
<BR>This paper describes the Q-routing algorithm for packet routing, in
which a reinforcement learning ...
</BLOCKQUOTE><HR>
<!nextperson><B>Coulom, 
Rémi</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:Remi.Coulom@imag.fr>Remi.Coulom@imag.fr</A><BR>
<A HREF=http://remi.coulom.free.fr/Thesis/>Reinforcement Learning Using Neural Networks, with Applications to Motor Control
</A><BR>
<i>PhD thesis</i>

(html - 1Mb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Coulom1.html>Abstract</A>: 
<BR>This thesis is a study of practical methods to estimate value functions with feedforward neural netw...
</BLOCKQUOTE><HR>
<!nextperson><B>Coulom, 
Rémi</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:Remi.Coulom@free.fr>Remi.Coulom@free.fr</A><BR>
<A HREF=http://remi.coulom.free.fr/Publications/ALT2002.pdf>Feedforward Neural Networks in Reinforcement Learning Applied to High-dimensional Motor Control</A><BR>
<i>Proceedings of ALT2002</i>

(pdf - 139 Kb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Coulom2.html>Abstract</A>: 
<BR>Local linear function approximators are often preferred to feedforward neural networks to estimate v...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
 , W. Zhang<blockquote><B>E-mail:</B> <A
	   HREF=mailto:tgd@cs.orst.edu>tgd@cs.orst.edu</A><BR>
<A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/ijcai95-jss.ps.gz>A Reinforcement
Learning Approach to Job-shop Scheduling</A><BR>
<i>Proceedings of IJCAI95</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Dietterich1.html>Abstract</A>: 
<BR>We apply reinforcement learning methods to learn domain-specific
heuristics for job shop scheduling...
</BLOCKQUOTE><HR>

<!nextperson><B>Francois, 
Rivest</B>
 , Doina Precup<blockquote><B>E-mail:</B> <A
	   HREF=mailto:rivestfr@iro.umontreal.ca>rivestfr@iro.umontreal.ca</A><BR>
<A HREF=http://www-etud.iro.umontreal.ca/~rivestfr/Publications/ICML2003.pdf>Combining TD-learning with Cascade-correlation Networks</A><BR>
<i>ICML 2003</i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Francois1.html>Abstract</A>: 
<BR>Using neural networks to represent value
functions in reinforcement learning algorithms
often invo...
</BLOCKQUOTE><HR>
<!nextperson><B>Gadaleta, 
Sabino</B>
 , Gerhard Dangelmayr( <A
	   HREF=mailto:sabino@math.colostate.edu>sabino@math.colostate.edu</A>)<BR>
<blockquote><A HREF=http://www.math.colostate.edu/~sabino/publications.html>Optimal Chaos Control through reinforcement learning</A><BR>
<i>Chaos, 9, 775, 1999</i>

<A HREF=http://www.cse.msu.edu/rlr/pub/Gadaleta1.html>Abstract</A>: 
<BR>A general purpose chaos control algorithm based on reinforcement learning is 
introduced and applie...
</BLOCKQUOTE><HR>
<!nextperson><B>Garcia, 
Frédérick</B>
 , Florent Serre( <A
	   HREF=mailto:fgarcia@toulouse.inra.fr>fgarcia@toulouse.inra.fr</A>)<BR>
<blockquote><A HREF=http://www-bia.inra.fr/T/garcia/Doc/Papiers/ecai.ps.gz>Efficient Asymptotic Approximation in Temporal Difference Learning</A><BR>
<i>European Conference on Artificial Intelligence ECAI'2000</i>

( gzipped Postscript - 78383 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Garcia1.html>Abstract</A>: 
<BR>We propose in this paper an asymptotic approximation of 
online TD(lambda) with accumulating eligib...
</BLOCKQUOTE><HR>
<!nextperson><B>Ghory, 
Imran</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:imran@bits.bris.ac.uk>imran@bits.bris.ac.uk</A><BR>
<A HREF=http://www.cs.bris.ac.uk/Publications/Papers/2000100.pdf>Reinforcement Learning in Board Games</A><BR>
<i>Technical Report CSTR-04-004, Department of Computer Science, University of Bristol, May 2004.</i>

(pdf - 1097439 bytes)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ghory1.html>Abstract</A>: 
<BR>This project investigates the application of the TD(lambda) reinforcement learning algorithm and neu...
</BLOCKQUOTE><HR>
<!nextperson><B>Konda, 
Vijaymohan</B>
 , Vivek S. Borkar ( <A
	   HREF=mailto:konda@mit.edu >konda@mit.edu </A>)<BR>
<blockquote><A HREF=http://web.mit.edu/konda/www/siaml.ps>Learning Algorithms for Markov Decision Processes</A><BR>
<i>SIAM Journal on Control and Optimization</i>

(Postscript - 619 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Konda1.html>Abstract</A>: 
<BR>Algorithms learning the optimal policy of a Markov decision process based on simulated transitions a...
</BLOCKQUOTE><HR>
<!nextperson><B>Leslie, 
David</B>
 , E. J. Collins( <A
	   HREF=mailto:dleslie@stats.ox.ac.uk>dleslie@stats.ox.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.stats.ox.ac.uk/~dleslie/papers/LeslieCollinsSICON04.pdf>Individual Q-learning in normal form games</A><BR>
<i>unpublished</i>

(PDF - 210K)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Leslie1.html>Abstract</A>: 
<BR>The single-agent multi-armed bandit problem can be solved by an
  agent that learns the values of e...
</BLOCKQUOTE><HR>
<!nextperson><B>Littman, 
Michael</B>
( <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/ml94-final.ps>Markov games as a framework for multi-agent reinforcement learning</A><BR>
<i>Proceedings of the Eleventh International 
Conference on Machine Learning</i>

(Postscript - 83KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Littman6.html>Abstract</A>: 
<BR>In the Markov decision process (MDP) formalization of reinforcement
learning, a single adaptive age...
</BLOCKQUOTE><HR>
<!nextperson><B>Preux, 
Philippe</B>
( <A
	   HREF=mailto:ppreux@grappa.univ-lille3.fr>ppreux@grappa.univ-lille3.fr</A>)<BR>
<blockquote><A HREF=http://www.grappa.univ-lille3.fr/~ppreux/papiers/ecml2002.ps.gz>Propagation of Q-values in Tabular TD(lambda)</A><BR>
<i>proceedings of the ECML, 2002</i>

( gzipped Postscript - 75 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Preux1.html>Abstract</A>: 
<BR>In this paper, we propose a new idea for tabular TD(lambda) algorithm.
  In TD learning, rewards ar...
</BLOCKQUOTE><HR>
<!nextperson><B>Reynolds, 
Stuart</B>
( <A
	   HREF=mailto:sir@cs.bham.ac.uk>sir@cs.bham.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.cs.bham.ac.uk/~sir/pub/UKCI-01.ps.gz>Optimistic Initial Q-values and the max Operator</A><BR>
<i>UKCI'01</i>

( gzipped Postscript - 80)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Reynolds2.html>Abstract</A>: 
<BR>This paper provides a surprising new insight into the role of the max operator used by reinforcement...
</BLOCKQUOTE><HR>
<!nextperson><B>Reynolds, 
Stuart</B>
( <A
	   HREF=mailto:sir@cs.bham.ac.uk>sir@cs.bham.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.cs.bham.ac.uk/~sir/pub/EScolour-CSRP-02-1.ps.gz>Experience Stack Reinforcement Learning for Off-Policy Control</A><BR>
<i>Cognitive Science Technical Report number CSRP-02-1, School of Computer Science, The University of Birmingham, Birmingham, B15 2TT, UK. January 2002</i>

( gzipped Postscript - 235)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Reynolds3.html>Abstract</A>: 
<BR>This paper introduces a novel method for allowing backwards replay to be applied as an online learni...
</BLOCKQUOTE><HR>
<!nextperson><B>Singh, 
Satinder</B>
 , Richard Sutton( <A
	   HREF=mailto:baveja@cs.colorado.edu>baveja@cs.colorado.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.colorado.edu/users/baveja/Papers/Replace.ps.gz>Reinforcement Learning with Replacing Eligibility Traces</A><BR>
<i>Machine Learning</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Singh6.html>Abstract</A>: 
<BR>...
</BLOCKQUOTE><HR>
<!nextperson><B>Singh, 
Satinder</B>
 , Peter Dayan( <A
	   HREF=mailto:baveja@cs.colorado.edu>baveja@cs.colorado.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.colorado.edu/users/baveja/Papers/MLjournal4.ps.gz>Analytical Mean Squared Error Curves for Temporal Difference Learning </A><BR>
<i>Machine Learning</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Singh7.html>Abstract</A>: 
<BR>...
</BLOCKQUOTE><HR>
<!nextperson><B>Sutton, 
Richard</B>
( <A
	   HREF=mailto:rich@cs.umass.edu>rich@cs.umass.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/sutton-88.ps.gz>Learning to predict by the method of temporal differences</A><BR>
<i>Machine Learning, 3:9-44, 1988</i>

( gzipped Postscript - 121 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Sutton1.html>Abstract</A>: 
<BR>This article introduces a class of incremental learning procedures
specialized for prediction - tha...
</BLOCKQUOTE><HR>
<!nextperson><B>Tesauro, 
Gerald</B>
( <A
	   HREF=mailto:tesauro@watson.ibm.com>tesauro@watson.ibm.com</A>)<BR>
<blockquote><A HREF=http://www.research.ibm.com/massdist/tdl.html>Temporal Difference Learning and TD-Gammon</A><BR>
<i>unpublished</i>

(HTML - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Tesauro1.html>Abstract</A>: 
<BR>Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-l...
</BLOCKQUOTE><HR>
<!nextperson><B>Tesauro, 
Gerald</B>
( <A
	   HREF=mailto:tesauro@watson.ibm.com>tesauro@watson.ibm.com</A>)<BR>
<blockquote><A
HREF=ftp://archive.cis.ohio-state.edu/pub/neuroprose/tesauro.tdgammon.ps.Z>TD-Gammon,
a self-teaching backgammon program, achieves master-level play</A><BR>
<i>unpublished</i>

(compressed Postscript - 120 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Tesauro2.html>Abstract</A>: 
<BR>TD Gammon is a neural network that is able to teach itself to play
backgammon soley by playing agai...
</BLOCKQUOTE><HR>
<!nextperson><B>Thrun, 
Sebastian</B>
( <A
	   HREF=mailto:thrun+@heaven.learning.cs.cmu.edu>thrun+@heaven.learning.cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/People/thrun/papers/thrun.nips7.neuro-chess.ps.gz>Learning to Play the Game of Chess </A><BR>
<i>Advances in Neural Information
 Processing Systems (NIPS) 7, 1995. </i>

<A HREF=http://web.cps.msu.edu/rlr/pub/Thrun2.html>Abstract</A>: 
<BR>This paper presents NeuroChess, a program which learns to play chess from the final
outcome of game...
</BLOCKQUOTE><HR>
<!nextperson><B>Tsitsiklis, 
John</B>
 , Ben Van Roy( <A
	   HREF=mailto:jnt@mit.edu>jnt@mit.edu</A>)<BR>
<blockquote><A HREF=http://lids.mit.edu/~jnt/td.ps>An Analysis of Temporal-Difference Learning with Function Approximation</A><BR>
<i>IEEE Transactions on Automatic Control,
 Vol. 42, No. 5, May 1997, pp. 674-690. </i>

(Postscript - 2 MB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Tsitsiklis1.html>Abstract</A>: 
<BR>We discuss the temporal-difference learning algorithm, as applied to
approximating cost-to-go funct...
</BLOCKQUOTE><HR>
<!nextperson><B>Wilson, 
Stewart</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:wilson@smith.rowland.org>wilson@smith.rowland.org</A><BR>
<A HREF=http://www.genetic-programming.org/#anchor10052121>Generalization in the XCS classifier system</A><BR>
<i>Genetic Programming 1998: Proceedings of the Third Annual Conference.  San Francisco, CA: Morgan Kaufmann.</i>

( HTML)
<A HREF=http://web.cps.msu.edu/rlr/pub/Wilson1.html>Abstract</A>: 
<BR>This paper studies two changes to XCS, a classifier system in which 
fitness is based on prediction...
</BLOCKQUOTE><HR>
<!nextperson><B>Xu, 
Xin</B>
 , Han-gen He and Dewen Hu<blockquote><B>E-mail:</B> <A
	   HREF=mailto:xuxin_mail@263.net>xuxin_mail@263.net</A><BR>
<A HREF=http://www.jair.org>Efficient Reinforcement Learning Using Recursive Least-Squares Methods</A><BR>
<i>Journal of Artificial Intelligence Research, Vol.16,2002, pp:259-292</i>

( gzipped Postscript - 700)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Xu1.html>Abstract</A>: 
<BR>The recursive least-squares (RLS) algorithm is one of the most well-known algorithms used in adaptiv...
</BLOCKQUOTE><HR>
<!nextperson><B>Yin, 
ChangMing</B>
( <A
	   HREF=mailto:cmyin@cs167.net>cmyin@cs167.net</A>)<BR>
<blockquote><A HREF=http://></A><BR>
<i>unpublished</i>

(Postscript - )
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Yin1.html>Abstract</A>: 
<BR>...
</BLOCKQUOTE><HR>
<!nextperson><B>ZHAO, 
Gang</B>
 , Shoji TATSUMI,Ruoying SUN( <A
	   HREF=mailto:zhaogang@ieee.org>zhaogang@ieee.org</A>)<BR>
<blockquote><A HREF=http://search.ieice.org/1999/files/e000a10.htm#e82-a,10,2266>RTP-Q: A Reinforcement Learning System with Time Constraints Exploration Planning for Accelerating the Learning Rate</A><BR>
<i>IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences</i>

(pdf - 171kb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/ZHAO1.html>Abstract</A>: 
<BR>This paper proposes a RTP-Q reinforcement learning system which varies an efficient method for explo...
</BLOCKQUOTE><HR>
<!nextperson><B>ZHAO, 
Gang</B>
 , Shoji TATSUMI,Ruoying SUN( <A
	   HREF=mailto:zhaogang@ieee.org>zhaogang@ieee.org</A>)<BR>
<blockquote><A HREF=http://search.ieice.org/2000/files/e000a09.htm#e83-a,9,1786>Convergence of the Q-ae Learning on Deterministic MDPs and Its Efficiency on the Stochastic Environment</A><BR>
<i>IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences</i>

(pdf - 172kb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/ZHAO2.html>Abstract</A>: 
<BR>In this paper, based on discussing different exploration methods, replacing the pre-action-selector ...
</BLOCKQUOTE><HR>
<!nextperson><B>Zhuang, 
Xiaodong</B>
( <A
	   HREF=mailto:windok@21cn.com>windok@21cn.com</A>)<BR>
<blockquote><A HREF=http://www.anycities.com/user1/aiouc/ICMLC02_z.zip>MULTI-SCALE REINFORCEMENT LEARNING WITH FUZZY STATE</A><BR>
<i>conference proceedings</i>

(Compressed PDF - 207KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Zhuang2.html>Abstract</A>: 
<BR>In this paper, multi-scale reinforcement learning is presented based on fuzzy state. The concept of ...
</BLOCKQUOTE><HR>
