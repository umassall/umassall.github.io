<HTML>
<HEAD>
<META HTTP-EQUIV=REFRESH>
<TITLE>Publications on Partially Observable Problems</TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<body bgcolor="#FFFFBB">
<CENTER>
<H1>Publications on Partially Observable Problems</H1>
</CENTER>

<img align=right src="imgs/sower.gif">

<br><hr>

<!nextperson><B>Mitchell, Matthew</B>
(<A HREF=mailto:MMitchell@groupwise.swin.edu.au>MMitchell@groupwise.swin.edu.au</A>)<BR>
<blockquote>
<A HREF=pub/mitchell-thesis.pdf>An Architecture for Situated-learning Agents</A><BR>
<i>Ph.D. Thesis, Monash University, Australia 2004.</i>

(PDF - 1.9 MB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Mitchell1.html>Abstract</A>: 
<BR>This thesis looks at the problem of situated learning agents operating in real-world environments ...
</BLOCKQUOTE><HR>
<!nextperson><B>Bhulai, 
Sandjai</B>
( <A
	   HREF=mailto:sbhulai@cs.vu.nl>sbhulai@cs.vu.nl</A>)<BR>
<blockquote><A HREF=http://www.cs.vu.nl/~sbhulai/papers/thesis.html>Markov Decision Processes: the control of high-dimensional systems.</A><BR>
<i>Ph.D. Thesis, Vrije Universiteit Amsterdam, 2002</i>

(PDF - 1.1 MB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Bhulai2.html>Abstract</A>: 
<BR>We develop algorithms for the computation of (nearly) optimal decision rules in high-dimensional sys...
</BLOCKQUOTE><HR>
<!nextperson><B>Cassandra, 
Anthony</B>
 , Michael L. Littman and Nevin L.
 Zhang( <A
	   HREF=mailto:arc@cs.brown.edu>arc@cs.brown.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/uai97-pomdp.ps>Incremental pruning: A simple, fast, exact algorithm
       for partially observable Markov decision processes.</A><BR>
<i>Proceedings of the Thirteenth Annual Conference
       on Uncertainty in Artificial Intelligence (UAI--97), 1997</i>

(Postscript - 120 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Cassandra1.html>Abstract</A>: 
<BR>Most exact algorithms for general partially observable Markov
decision processes (POMDPs) use a for...
</BLOCKQUOTE><HR>
<!nextperson><B>Kaelbling, 
Leslie Pack</B>
 , Anthony R. Cassandra and Michael L. Littman( <A
	   HREF=mailto:lpk@cs.brown.edu>lpk@cs.brown.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.brown.edu/research/ai/pomdp/papers/aaai94.ps.gz>Acting Optimally in Partially Observable Stochastic Domains</A><BR>
<i>Proceedings of the
              Twelfth National Conference on Artificial Intelligence, 1994</i>

(gzipped Postscript - 104 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Kaelbling2.html>Abstract</A>: 
<BR>In this paper, we describe the partially observable Markov decision
process (POMDP) approach to fin...
</BLOCKQUOTE><HR>
<!nextperson><B>Kalmar, 
Zsolt</B>
 , Cs. Szepesvari and A. Lorincz<blockquote><B>E-mail:</B> <A
	   HREF=mailto:kalmar@mindmaker.kfkipark.hu>kalmar@mindmaker.kfkipark.hu</A><BR>
<A HREF=http://link.springer.de/link/service/series/0558/papers/1545/15450029.pdf>Module-Based Reinforcement Learning for a Real Robot 

</A><BR>
<i>Proceedings of the 6th European Workshop on Learning Robots, Lecture Notes in AI, to appear. 1998</i>

( PDF - 845 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Kalmar1.html>Abstract</A>: 
<BR>The behaviour of reinforcement learning (RL) algorithms is best understood in completely observable,...
</BLOCKQUOTE><HR>
<!nextperson><B>Kalmar, 
Zsolt</B>
 , Cs. Szepesvári and A. Lorincz<blockquote><B>E-mail:</B> <A
	   HREF=mailto:kalmar@mindmaker.kfkipark.hu>kalmar@mindmaker.kfkipark.hu</A><BR>
<A HREF=http://link.springer.de/link/service/series/0558/papers/1545/15450029.pdf>Module Based Reinforcement Learning for a Real Robot </A><BR>
<i>Proceedings of the 6th European Workshop on Learning Robots, 22-32, 1997</i>

( PDF - 845 Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Kalmar2.html>Abstract</A>: 
<BR>This is the shortest version of our Module-Based RL paper.

The behaviour of reinforcement learnin...
</BLOCKQUOTE><HR>
<!nextperson><B>Littman, 
Michael</B>
 , Anthony Cassandra and Leslie Pack Kaelbling( <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/witness-or.ps>Efficient dynamic-programming updates in partially observable
Markov decision processes</A><BR>
<i>Brown University Technical Report CS-95-19</i>

(Postscript - 1.2 MB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Littman1.html>Abstract</A>: 
<BR>We examine the problem of performing exact dynamic-programming updates
in partially observable Mark...
</BLOCKQUOTE><HR>
<!nextperson><B>Littman, 
Michael</B>
 , Anthony Cassandra and Leslie Kaelbling<blockquote><B>E-mail:</B> <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A><BR>
<A HREF=http://www.cs.duke.edu/~mlittman/docs/ml95.ps>Learning
policies for partially observable environments: Scaling up</A><BR>
<i>Proceedings of the Twelfth
International Conference on Machine Learning</i>

(Postscript - 315K)
<A HREF=http://web.cps.msu.edu/rlr/pub/Littman5.html>Abstract</A>: 
<BR>Partially observable Markov decision processes (POMDPs) model decision
problems in which an agent t...
</BLOCKQUOTE><HR>
<!nextperson><B>Littman, 
Michael</B>
( <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/sab94.ps>Memoryless policies: Theoretical limitations and practical results</A><BR>
<i>From Animals to Animats 3: Proceedings
 of the Third International Conference on Simulation of Adaptive
 Behavior</i>

(Postscript - 416KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Littman7.html>Abstract</A>: 
<BR>One form of adaptive behavior is "goal-seeking" in which an agent acts
so as to minimize the time i...
</BLOCKQUOTE><HR>
<!nextperson><B>Littman, 
Michael</B>
( <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/sab92.giveout.ps>An optimization-based categorization of reinforcement learning environments</A><BR>
<i></i>

<A HREF=http://web.cps.msu.edu/rlr/pub/Littman8.html>Abstract</A>: 
<BR>This paper proposes a categorization of reinforcement learning
environments based on the optimizati...
</BLOCKQUOTE><HR>
<!nextperson><B>Mahadevan, 
Sridhar</B>
 , Nikfar Khaleeli
<B>E-mail:</B> (<A
	   HREF=mailto:mahadeva@cps.msu.edu>mahadeva@cps.msu.edu</A>)<BR>
<blockquote>
<A HREF=http://www.cps.msu.edu/~papers/jair-submit.ps.gz></A>

<b>Robot Navigation using Discrete-Event Markov Decision Process Models</b><BR>
<i>unpublished</i>

( gzipped Postscript - 200 kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Mahadevan1.html>Abstract</A>: 
<BR>This paper describes a novel architecture for robot navigation
based on semi-Markov decision proces...
</BLOCKQUOTE><HR>

<!nextperson><B>Parr, Ronald</B>, Stuart Russell
<blockquote><B>E-mail:</B> <A

HREF=mailto:russell@cs.berkeley.edu>russell@cs.berkeley.edu</A><BR>
<A
HREF=http://http.cs.berkeley.edu/~russell/papers/ijcai95-porl.ps>
Approximating 
optimal policies for partially observable stochastic
domains 
</A><BR>
<i>Proceedings of the IJCAI, 1995</i>
 
(Postscript - 157 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Russell1.html>Abstract</A>:
<BR>The problem of making optimal decisions in uncertain conditions is
central to Artificial Intelligen...
</BLOCKQUOTE><HR>

<!nextperson><B>Schmidhuber, 
Juergen</B>
( <A
	   HREF=mailto:juergen@idsia.ch>juergen@idsia.ch</A>)<BR>
<blockquote><A HREF=http://www.idsia.ch/~juergen/rl.html>REINFORCEMENT LEARNING AND POMDPs (dozens of papers on RL in partially observable environments since 1989)
</A><BR>
<i>Journal papers and conference papers</i>

(HTML - 100KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Schmidhuber3.html>Abstract</A>: 
<BR>Realistic environments are not fully observable. General learning agents need an internal state to m...
</BLOCKQUOTE><HR>
<!nextperson><B>Singh, 
Satinder</B>
 , Tommi Jaakkola, Michael Jordan( <A
	   HREF=mailto:baevja@cs.colorado.edu>baevja@cs.colorado.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.colorado.edu/users/baveja/Papers/ML94.ps.gz>Learning Without State-Estimation in Partially Observable Markovian Decision Processes</A><BR>
<i>Proceedings of the Eleventh International Machine Learning Conference</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Singh8.html>Abstract</A>: 
<BR>...
</BLOCKQUOTE><HR>

