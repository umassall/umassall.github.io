<HTML><HEAD>
<TITLE>Exploiting structure in policy construction</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Exploiting structure in policy construction</H2>
<!nextperson><B>Boutilier, Craig</B>, R. Dearden, and M. Goldszmidt
<blockquote><A HREF=
http://www.cs.ubc.ca/spider/cebly/Papers/spi.ps>Exploiting structure in policy construction</A><BR>

<I> Proceedings of the Fourteenth IJCAI, 1995 </I>

(Postscript - 195 KB )

<BR><B>Abstract</B>: Markov decision processes (MDPs) have recently been applied to the
problem of modeling decision-theoretic planning.  While such traditional
methods for solving MDPs are often practical for small states spaces,
their effectiveness for large AI planning problems is questionable.
We present an algorithm, called <i>structured policy iteration</i>(SPI),
that constructs optimal policies without explicit enumeration of the state
space.  The algorithm retains the fundamental computational steps of the 
commonly used modified policy iteration alogrithm, but exploits the
variable and propositional independencies in reflected in a temporal Bayesian
network representation of MDPs.  The principles behind SPI can be 
applied to any structured representation of stochastic actions, and the
algorithm itself can be used in conjunction with recent approximation
methods.
</BLOCKQUOTE>
