<HTML><HEAD>
<TITLE>Neural Reinforcement Learning for Behaviour
Synthesis</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Neural Reinforcement Learning for Behaviour
Synthesis</H2>
<!nextperson><B>Touzet, Claude F. </B><blockquote><A HREF= http://avalon.epm.ornl.gov/~touzetc/Publi/Jars_97.zip>Neural Reinforcement Learning for Behaviour
Synthesis</A><BR>

<I> Robotics and Autonomous Systems, Special issue on Learning Robot: the New Wave, N. SharkeyGuest Editor, 1997. </I>

( gzipped Postscript - 260 K )

<BR><BR><B>Abstract</B>: We present the results of a research aimed at improving the
Q-learning method through the use of artificial neural
networks. Neural implementations are interesting due to their
generalisation ability. Two implementations are proposed: one
with a competitive multilayer perceptron and the other with a
self-organising map. Results obtained on a task of learning an
obstacle avoidance behaviour for the mobile miniature robot
Khepera show that this last implementation is very effective,
learning more than 40 times faster than the basic Q-learning
implementation. These neural implementations are also
compared with several Q-learning enhancements, like the
Q-learning with Hamming distance, Q-learning with statistical
clustering and Dyna-Q. 

Key Words: 

Neural Q-learning, reinforcement learning, obstacle avoidance
behaviour, self-organising map, autonomous robotics. 
</BLOCKQUOTE>
