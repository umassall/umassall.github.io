<HTML><HEAD>
<TITLE>Efficient hierarchical MCMC for policy search</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Efficient hierarchical MCMC for policy search</H2>
<!nextperson><B>Strens, Malcolm</B><blockquote><A HREF= http://www.aicml.cs.ualberta.ca/banff04/icml/pages/papers/177.pdf>Efficient hierarchical MCMC for policy search</A><BR>

<I> International Conference on Machine Learning, 2004 </I>

(pdf - 318KB)

<BR><BR><B>Abstract</B>: Many inference and optimization tasks in machine learning can be solved by sampling approaches such as Markov Chain Monte Carlo (MCMC) and simulated annealing. These methods can be slow if a single target density query requires many runs of a simulation (or a complete sweep of a training dataset). We introduce a hierarchy of MCMC samplers that allow most steps to be taken in the solution space using only a small sample of simulation runs (or training examples). This is shown to accelerate learning in a policy search optimization task.
</BLOCKQUOTE>
