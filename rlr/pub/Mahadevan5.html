<HTML><HEAD>
<TITLE>Automatic Programming of Behavior-based Robots using Reinforcement
Learning</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Designing Agent Controllers using Discrete-Event Markov Models</H2>
<!nextperson><B>Mahadevan, Sridhar</B> , Nikfar Khaleeli and
Nicholas Marchalleck<blockquote><A
HREF=
http://www.cps.msu.edu/~mahadeva/papers/aaai-fs-97.ps.gz>
Designing Agent Controllers using Discrete-Event Markov Models
</A><BR>
<I> AAAI Fall Symposium on Model-Directed Autonomous
       Systems</I>, Nov. 5-7, Cambridge, MA (gzipped Postscript
       - 200 kb) 

<BR><BR><B>Abstract</B>: 
This paper describes the use of <i>discrete-event</i> Markov decision
process models to design robust agent controllers in complex stochastic
domains.  Unlike discrete-time models, where actions are assumed to take
unit time, discrete-event models allow state transitions to take random
time.  Discrete-event models also provide a convenient form of temporal
abstraction: the agent observes and controls the system only at decision
epochs.  The paper summarizes case studies using discrete-event models in
two challenging application domains: mobile robot navigation and
manufacturing.  The two domains also serve to highlight the difference
between probabilistic models, where dynamic programming can be applied,
and simulation models, where reinforcement learning methods are more
appropriate.


</BLOCKQUOTE>
