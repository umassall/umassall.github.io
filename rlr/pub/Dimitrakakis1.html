<HTML><HEAD>
<TITLE>Reinforcement Learning With Continuous Action Values</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Reinforcement Learning With Continuous Action Values</H2>
<!nextperson><B>Dimitrakakis, Christos</B><blockquote><A HREF= http://members.xoom.com/cdimita/research/rl/ml99.ps.gz>Reinforcement Learning With Continuous Action Values</A><BR>

<I> unpublished </I>

( gzipped Postscript - 120KB )

<BR><BR><B>Abstract</B>: The problem of reinforcement learning in the case of a continuous action set
remains largely unsolved. This paper offers a possible solution by attempting to model
softmax action selection in the continuous case through the use of a distribution whose
moments are modified using the TD-error update. Appropriate updates for all moments of
the distribution are derived and an actor-critic implementation of the method is described.
The effectiveness of this approach is demonstrated by a set of experiments. 
</BLOCKQUOTE>
