<HTML><HEAD>
<TITLE>Nearly optimal exploration-exploitation decision thresholds</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Nearly optimal exploration-exploitation decision thresholds</H2>
<!nextperson><B>Dimitrakakis, Christos</B><blockquote><A HREF= ftp://ftp.idiap.ch/pub/reports/2006/dimitrakakis-idiap-rr-06-12.ps.gz>Nearly optimal exploration-exploitation decision thresholds</A><BR>

<I> ICANN 2006 </I>

( gzipped Postscript - 170Kb )

<BR><BR><B>Abstract</B>: While in general trading off exploration and exploitation in
reinforcement learning is hard, under some formulations relatively
simple solutions exist.  Optimal decision thresholds for the
multi-armed bandit problem, one for the infinite horizon discounted
reward case and one for the finite horizon undiscounted reward case
are derived, which make the link between the reward horizon,
uncertainty and the need for exploration explicit.  From this result
follow two practical approximate algorithms, which are illustrated
experimentally.
</BLOCKQUOTE>
