<HTML><HEAD>
<TITLE>Acting Optimally in Partially Observable Stochastic Domains</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Acting Optimally in Partially Observable Stochastic Domains</H2>
<!nextperson><B>Kaelbling, Leslie Pack</B> , Anthony R. Cassandra and Michael L. Littman<blockquote><A HREF= http://www.cs.brown.edu/people/lpk/aaai94.ps>Acting Optimally in Partially Observable Stochastic Domains</A><BR>

<I> Proceedings of the
              Twelfth National Conference on Artificial Intelligence, 1994 </I>

(Postscript - 320 KB )

<BR><BR><B>Abstract</B>: In this paper, we describe the partially observable Markov decision
process (POMDP) approach to finding optimal or near-optimal control
strategies for partially observalbe stochastic environments, given
a complete model of the environment.  The POMDP approach was originally
developed in the operations research community and provides a formal
basis for planning problems that have been of interest to the AI
community.  We found the existing algorithms for computing optimal
control strategies to be highly computationally inefficient and have
developed a new algorithm that is empirically more efficient.  We
sketch this algorithm and present preliminary results on several small
problems that illustrate important properties of the POMDP approach. 
</BLOCKQUOTE>
