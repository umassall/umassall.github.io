<HTML><HEAD>
<TITLE>Hierarchical Optimal Control of MDP's</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Hierarchical Optimal Control of MDP's</H2>
<!nextperson><B>McGovern, Amy</B> , Doina Precup, Balaraman Ravindran, Satinder Singh, Richard S Sutton<blockquote><A HREF= http://www-anw.cs.umass.edu/~amy/pubs/options-yale98.ps.gz>Hierarchical Optimal Control of MDP's</A><BR>

<I>  Proceedings of the 10th Yale Workshop on Adaptive and Learning systems. </I>

( gzipped Postscript - 600 KB )

<BR><BR><B>Abstract</B>: In this paper we survey a new approach to reinforcement learning 
in which high and low-level decisions are treated uniformly.  Each low-level
action and high-level couse of action is represented as an "option,"
 a (sub)controller
and termination condition.  The theory of options is based on the 
theories of of Markov and semi-Markov decision processes, but extends
these in significant ways.

</BLOCKQUOTE>
