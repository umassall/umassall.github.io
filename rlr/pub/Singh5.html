<HTML><HEAD>
<TITLE>Reinforcement Learning With Soft State Aggregation</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Reinforcement Learning With Soft State Aggregation</H2>
<!nextperson><B>Singh, Satinder</B><blockquote>
<A HREF= ftp://ftp.cs.colorado.edu/users/baveja/Papers/Nips94.ps.gz>
Reinforcement Learning With Soft State Aggregation</A><BR>
<I> NIPS 7 </I>
( gzipped Postscript -  )

<BR><BR><B>Abstract</B>: It is widely accepted that the use of more
compact representations than lookup tables is crucial to scaling
reinforcement learning (RL) algorithms to real-world problems.
Unfortunately almost all of the theory of reinforcement learning assumes
lookup table representations.  In this paper we address the pressing
issue of combining function approximation and RL, and present 1) a
function approximator based on a simple extension to state aggregation (a
commonly used form of compact representation), namely <i>soft</i> state
aggregation, 2) a theory of convergence for RL with arbitrary, but fixed,
soft state aggregation, 3) a novel intuitive understanding of the effect
of state aggregation on online RL, and 4) a new heuristic <i>adaptive</i>
state aggregation algorithm that finds improved compact representations by
exploiting the non-discrete nature of soft state aggregation.  Preliminay
empirical results are also presented.


</BLOCKQUOTE>
