<HTML><HEAD>
<TITLE>Finding Structure in Reinforcement Learning</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Finding Structure in Reinforcement Learning</H2>
<!nextperson><B>Thrun, Sebastian</B> , Anton Schwartz<blockquote><A HREF= http://www.cs.cmu.edu/People/thrun/papers/thrun.nips7.reinforcement-learning.ps.gz>Finding Structure in Reinforcement Learning</A><BR>

<I> Advances in Neural Information
 Processing Systems (NIPS) 7, 1995.  </I>

( gzipped Postscript - 149 KB )

<BR><BR><B>Abstract</B>: Reinforcement learning addresses the problem of learning to select actions in order to
maximize one's performance in unknown environments. To scale reinforcement learning to
complex real-world tasks, such as typically studied in AI, one must ultimately be able to
discover the structure in the world, in order to abstract away the myriad of details and to
operate in more tractable problem spaces.
<p>
This paper presents the SKILLS algorithm. SKILLS discovers skills, which are partially
defined action policies that arise in the context of multiple, related tasks. Skills collapse whole
action sequences into single operators. They are learned by minimizing the compactness of
action policies, using a description length argument on their representation. Empirical results
in simple grid navigation tasks illustrate the successful discovery of structure in reinforcement
learning. 
</BLOCKQUOTE>
