<HTML><HEAD>
<TITLE>Residual q-learning applied to visual attention.</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Residual q-learning applied to visual attention.</H2>
<!nextperson><B>Bandera, C.</B> , V. Francisco, B. Jose, M. Harmon, and L. Baird<blockquote><A HREF= http://www.cs.cmu.edu/~baird/papers/icm96/ICML96.ps>Residual q-learning applied to visual attention.</A><BR>

<I> Proceedings of the Thirteenth International Conference on Machine Learning, pages 20-27.  Morgan Kaufmann, 1996 </I>

(Postscript - 445 KB )

<BR><B>Abstract</B>: Foveal vision features imagers with graded acuity coupled with context
sensitive sensor gaze control, analogous to that prevalent throughout
vertebrate vision.  Foveal vision operates more efficiently than uniform
acuity because resolution is treated as a dynamically allocatable
resource, but requires a more refined visual attention mechanism.  We
demonstrate that reinforcement learning (RL) significantly improves the
performance of foveal visual attention, and of the overall vision system,
for the task of model based target recognition.  A simulated foveal vision
system is shown to classify targets with fewer fixations by learning
strategies for the acquisition of visual information relevant to the task,
and learning how to generalize these strategies in ambiguous and
unexpected scenario conditions. </BLOCKQUOTE>
