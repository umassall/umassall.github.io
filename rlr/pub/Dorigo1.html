<HTML><HEAD>
<TITLE>Robot shaping: Developing autonomous agents through learning</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Robot shaping: Developing autonomous agents through learning</H2>
<!nextperson><B>Dorigo, Marco</B> , M. Colombetti<blockquote><A HREF= ftp://iridia.ulb.ac.be/pub/dorigo/journals/IJ.05-AIJ94.ps.gz>Robot shaping: Developing autonomous agents through learning</A><BR>

<I> Artificial Intelligence, 71:321-370, 1994 </I>

( gzipped Postscript - 574 KB )

<BR><B>Abstract</B>: Learning plays a vital role in the development of situated agents.  In
this paper, we explore the use of reinforcement learning to "shape" a
robot to perform a predefined target behavior.  We connect both
simulated and real robots to ALECSYS, a parallel implementation of a
learning classifier system with an extended genetic algorithm.  After
classifying different kinds of Animat-like behaviors, we explore the
effects on learning of different types of agent's architecture
(monolithic, flat and hierarchical) and of training strategies.  In
particular, hierarchical architecture requires the agent to learn how
to coordinate basic learned responses.  We show that the best results
are achieved when both the agent's architecture and the training
strategy match the structure of the behavior pattern to be learned.
We report the results of a number of experiments carried out both in
simulated and in real environments, and show that the results of 
simulations carry smoothly to real robots.  While most of our
experiments deal with simple reactive behavior, in one of them we
demonstrate the use of a simple and general memory mechanism.  As a 
whole, our experimental activity demonstrates that classifier systems
with genetic algorithms can be practically employed to develop 
autonomous agents.
</BLOCKQUOTE>
