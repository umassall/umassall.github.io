<HTML><HEAD>
<TITLE>Auto-exploratory average reward reinforcement learning</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Auto-exploratory average reward reinforcement learning</H2>
<!nextperson><B>Ok, DoKyeong</B> , Prasad Tadepalli<blockquote><A HREF=
http://www.cs.orst.edu/~tadepall/research/papers/auto-exploratory.ps>Auto-exploratory average reward reinforcement learning</A><BR>

<I> Proceedings of AAAI-96 </I>

(Postscript - 130 KB )

<BR><BR><B>Abstract</B>: We introduce a model-based average-reward Reinforcement Learning
method called H-learning and compare it with its discounted 
counterpart, Adaptive Real-Time Dynamic Programming, in a simulated
robot scheduling task.  We also introduce an extension to H-learning,
which automatically explores the unexplored parts of the state space,
while always choosing greedy actions with respect to the current
value function.  We show that this "Auto-exploratory H-learning"
performs better than the original H-learning under previously studied
exploration methods such as randon, recency-based, or counter-based 
explanations.
</BLOCKQUOTE>
