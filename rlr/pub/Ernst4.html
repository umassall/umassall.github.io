<HTML><HEAD>
<TITLE>Approximate value iteration in the reinforcement learning context. Application to electrical power system control</TITLE></HEAD>
<BODY bgcolor="FFFFBB">
<H2>Approximate value iteration in the reinforcement learning context. Application to electrical power system control</H2>
<!nextperson><B>Ernst, Damien</B> , Pierre Geurts, Mevludin Glavic, Louis Wehenkel<blockquote><A HREF= http://www.montefiore.ulg.ac.be/~ernst>Approximate value iteration in the reinforcement learning context. Application to electrical power system control</A><BR>

<I> International Journal of Emerging Electric Power Systems </I>

(.pdf - 780)

<BR><BR><B>Abstract</B>: In this paper we explain how to design intelligent agents able to process the information acquired from interaction with a system to learn a good control policy and show how the methodology can be applied to control some devices aimed to damp electrical power oscillations. The control problem is formalized as a discrete-time optimal control problem and the information acquired from interaction with the system is a set of samples, where each sample is composed
of four elements: a state, the action taken while being in this state, the instantaneous reward observed and the successor state of the system. To process this information we consider reinforcement learning algorithms that determine an approximation of the so-called Q-function by mimicking the behavior of the value iteration algorithm. Simulations are first carried on a benchmark power system modeled with two state variables. Then we present a more complex case study on a four-machine power system where the reinforcement learning algorithm controls a Thyristor Controlled Series Capacitor (TCSC) aimed to damp power system oscillations.
</BLOCKQUOTE>
