<HTML>
<HEAD>
<META HTTP-EQUIV=REFRESH>
<TITLE>Publications on Hierarchical Methods</TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<body bgcolor="#FFFFBB">
<CENTER>
<H1>Publications on Hierarchical Methods</H1>
</CENTER>

<img align=right src="imgs/sower.gif">

<BR><BR>
<hr>
<!nextperson><B>Asadi, 
Mehran</B>
( <A
	   HREF=mailto:asadi@cse.uta.edu>asadi@cse.uta.edu</A>)<BR>
<blockquote><A HREF=http://www.ijcai.org/papers07/Papers/IJCAI07-331.pdf>Effective Control Knowledge Transfer Through Learning Skill and Representation Hierarchies
</A><BR>
<i>International Joint Conference on Artificial Intelligence 2007</i>

(pdf - 192 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Asadi1.html>Abstract</A>: 
<BR>Learning capabilities of computer systems still lag far behind biological systems. One of the reason...
</BLOCKQUOTE><HR>
<!nextperson><B>Caironi, 
Pierguido</B>
( <A
	   HREF=mailto:caironi@elet.polimi.it>caironi@elet.polimi.it</A>)<BR>
<blockquote><A HREF=ftp://www.elet.polimi.it/pub/data/Pierguido.Caironi/tr97_50.ps.gz>Gradient-Based Reinforcement Learning: Learning Combinations of Control Policies</A><BR>
<i>Technical Report 97.50, Dip. Elettronica e Informazione, Politecnico di Milano</i>

( gzipped Postscript - 381 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Caironi1.html>Abstract</A>: 
<BR>This report presents two innovative model-based reinforcement
learning algorithms for continuous st...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
( <A
	   HREF=mailto:tgd@cs.orst.edu>tgd@cs.orst.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/ml98-maxq.ps.gz>The MAXQ Method for Hierarchical Reinforcement Learning</A><BR>
<i>Proceedings of the International Conference on Machine Learning, 1998</i>

( gzipped Postscript - 53Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Dietterich3.html>Abstract</A>: 
<BR>This paper presents a new approach to hierarchical reinforcement
learning based on the MAXQ decompo...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
( <A
	   HREF=mailto:tgd@cs.orst.edu>tgd@cs.orst.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/mlj-maxq.ps.gz>Hierarchical Reinforcement Learning with the MAXQ Value
Function Decomposition</A><BR>
<i>journal version; under review</i>

( gzipped Postscript - 192Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Dietterich4.html>Abstract</A>: 
<BR>This paper presents a new approach to hierarchical
reinforcement learning based on the MAXQ decompo...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:tgd@cs.orst.edu>tgd@cs.orst.edu</A><BR>
<A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/tr-maxq-abstraction.ps.gz>State abstraction in MAXQ hierarchical reinforcement learning</A><BR>
<i>unpublished</i>

( gzipped Postscript - 102Kb)
<A HREF=http://www.cse.msu.edu/rlr/pub/Dietterich5.html>Abstract</A>: 
<BR>Many researchers have explored methods for hierarchical reinforcement
learning (RL) with tempora...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
( <A
	   HREF=mailto:tg@cs.orst.edu>tg@cs.orst.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/tr-big-maxq.ps.gz>Hierarchical reinforcement learning with the MAXQ value function decomposition.</A><BR>
<i>unpublished</i>

( gzipped Postscript - 360Kb)
<A HREF=http://www.cse.msu.edu/rlr/pub/Dietterich6.html>Abstract</A>: 
<BR><b>Note: Supersedes previous version with same title.</b> This paper presents a new approach to hier...
</BLOCKQUOTE><HR>
<!nextperson><B>Diuk, 
Carlos</B>
 , Alexander Strehl, Michael Littman( <A
	   HREF=mailto:cdiuk@cs.rutgers.edu>cdiuk@cs.rutgers.edu</A>)<BR>
<blockquote><A HREF=http://paul.rutgers.edu/~cdiuk/papers/HRL_AAMAS.pdf>A Hierarchical Approach to Efficient Reinforcement Learning in Deterministic Domains</A><BR>
<i>AAMAS 2006</i>

(PDF - 140KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Diuk1.html>Abstract</A>: 
<BR>Factored representations, model-based learning, and hierar-
chies are well-studied techniques for i...
</BLOCKQUOTE><HR>
<!nextperson><B>Faihe, 
Yassine</B>
 , Jean-Pierre Muller( <A
	   HREF=mailto:yfaihe@acm.org>yfaihe@acm.org</A>)<BR>
<blockquote><A HREF=http://iiun.unine.ch/People/yfaihe/Public/sab98.ps.gz>Behaviors Coordination Using Restless Bandits Allocation Indexes</A><BR>
<i>Proceedings of the Fifth International Conference on Simulation of Adaptive Behavior (SAB98)</i>

( gzipped Postscript - 166KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Faihe1.html>Abstract</A>: 
<BR>In order to remain viable and to reproduce an animal has to 
continuously deal with the problem of ...
</BLOCKQUOTE><HR>
<!nextperson><B>Hengst, 
Bernhard</B>
( <A
	   HREF=mailto:bernhardh@cse.unsw.edu.au>bernhardh@cse.unsw.edu.au</A>)<BR>
<blockquote><A HREF=http://www.users.bigpond.com/hengst/AIResearch.html>Generating Hierarchical Structure in Reinforcement Learning from State Variables</A><BR>
<i>Springer-Verlag (copyright) as a volume in their Lecture Notes in Artificial Intelligence series. (2000)</i>

( gzipped Postscript - 11 pages)
<A HREF=http://www.cse.msu.edu/rlr/pub/Hengst1.html>Abstract</A>: 
<BR>This paper presents the CQ algorithm which decomposes and solves a Markov Decision Process (MDP) by ...
</BLOCKQUOTE><HR>
<!nextperson><B>Kalmar, 
Zsolt</B>
 , Cs. Szepesvári and A. Lorincz( <A
	   HREF=mailto:kalmar@mindmaker.kfkipark.hu>kalmar@mindmaker.kfkipark.hu</A>)<BR>
<blockquote><A
HREF==ftp://iserv.iki.kfki.hu/pub/papers/new/modbase.ps.gz>Module Based Reinforcement Learning for a Real Robot </A><BR>
<i>Proceedings of the 6th European Workshop on Learning Robots, 22-32, 1997</i>

( gzipped Postscript - 755 Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Kalmar2.html>Abstract</A>: 
<BR>This is the shortest version of our Module-Based RL paper.

The behaviour of reinforcement learnin...
</BLOCKQUOTE><HR>
<!nextperson><B>Kalmar, 
Zsolt</B>
 , Cs. Szepesvari and A. Lorincz ( <A
	   HREF=mailto:kalmar@mindmaker.kfkipark.hu>kalmar@mindmaker.kfkipark.hu</A>)<BR>
<blockquote><A HREF=http://iserv.iki.kfki.hu/pub/papers/kalmar.gdcm.ps.Z>Generalized Dynamic Concept Model as a Route to Construct Adaptive Autonomous Agents </A><BR>
<i>Neural Network World 3:353-360, 1995</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Kalmar3.html>Abstract</A>: 
<BR>This is an early approach to introduce generalization in RL.

A model of adaptive autonomous agent...
</BLOCKQUOTE><HR>
<!nextperson><B>Kalmár, 
Zsolt</B>
 , Cs. Szepesvári and A. Lorincz( <A
	   HREF=mailto:kalmar@mindmaker.kfkipark.hu>kalmar@mindmaker.kfkipark.hu</A>)<BR>
<blockquote><A HREF=http://sneaker.mindmaker.kfkipark.hu/~szepes/papers/ml-98.ps.gz>Module-Based Reinforcement Learning: Experiments with a Real Robot </A><BR>
<i>Machine Learning</i>

( gzipped Postscript - 755)
<A HREF=http://web.cps.msu.edu/rlr/pub/Kalmár1.html>Abstract</A>: 
<BR>The behavior of reinforcement learning (RL) algorithms is best understood in completely observable, ...
</BLOCKQUOTE><HR>
<!nextperson><B>Laurent, 
Guillaume</B>
 , Emmanuel Piat( <A
	   HREF=mailto:mel@guillaume-laurent.levillage.org>mel@guillaume-laurent.levillage.org</A>)<BR>
<blockquote><A HREF=http://www.guillaume-laurent.levillage.org/Downloads/Laurent-IROS01.pdf>Parallel Q-Learning for a block-pushing problem</A><BR>
<i>Conference proceedings</i>

(pdf - 679KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Laurent1.html>Abstract</A>: 
<BR>Our approach is based on reinforcement learning algorithm (Q-Learning). We propose an original archi...
</BLOCKQUOTE><HR>
<!nextperson><B>McGovern, 
Amy</B>
 , Richard S. Sutton( <A
	   HREF=mailto:amy@cs.umass.edu>amy@cs.umass.edu</A>)<BR>
<blockquote><A HREF=http://www-anw.cs.umass.edu/~amy/pubs/mcgovern-techrpt-98-70.ps.gz>Macro-Actions in Reinforcement Learning: An Empirical Analysis</A><BR>
<i>technical report</i>

( gzipped Postscript - 440K)
<A HREF=http://web.cps.msu.edu/rlr/pub/McGovern1.html>Abstract</A>: 
<BR>   Several researchers have proposed reinforcement learning methods
   that obtain advantages in le...
</BLOCKQUOTE><HR>
<!nextperson><B>McGovern, 
Amy</B>
 , Doina Precup, Balaraman Ravindran, Satinder Singh, Richard S Sutton( <A
	   HREF=mailto:amy@cs.umass.edu>amy@cs.umass.edu</A>)<BR>
<blockquote><A HREF=http://www-anw.cs.umass.edu/~amy/pubs/options-yale98.ps.gz>Hierarchical Optimal Control of MDP's</A><BR>
<i> Proceedings of the 10th Yale Workshop on Adaptive and Learning systems.</i>

( gzipped Postscript - 600 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/McGovern2.html>Abstract</A>: 
<BR>In this paper we survey a new approach to reinforcement learning 
in which high and low-level decis...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A><BR>
<A HREF=http://www.cs.cmu.edu/~munos/papers/ecml97ps.zip>Finite-Element methods with local triangulation refinement for continuous Reinforcement Learning problems</A><BR>
<i>European Conference on
 Machine Learning, 1997</i>

(compressed Postscript - 283Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos5.html>Abstract</A>: 
<BR>
 This paper presents a reinforcement learning algorithm for generating an adaptive control for a
...
</BLOCKQUOTE><HR>
<!nextperson><B>Parr, 
Ron</B>
 , Stuart Russell( <A
	   HREF=mailto:parr@cs.berkeley.edu >parr@cs.berkeley.edu </A>)<BR>
<blockquote><A HREF=http://http.cs.berkeley.edu/~russell/papers/nips97-ham.ps.gz>Reinforcement Learning with Hierarchies of Machines</A><BR>
<i>NIPS'97</i>

( gzipped Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Parr1.html>Abstract</A>: 
<BR>We present a new approach to reinforcement learning in which the policies considered by the learning...
</BLOCKQUOTE><HR>
<!nextperson><B>Parr, 
Ronald</B>
( <A
	   HREF=mailto:parr@cs.stanford.edu>parr@cs.stanford.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~parr/thesis600.ps.gz>Hierarchical Control and Learning for Markov Decision Processes</A><BR>
<i>PhD Thesis</i>

( gzipped Postscript - 440 KB )
<A HREF=http://web.cps.msu.edu/rlr/pub/Parr2.html>Abstract</A>: 
<BR>

This dissertation investigates the use of hierarchy and problem decomposition as a means of solv...
</BLOCKQUOTE><HR>
<!nextperson><B>Schmidhuber, 
Juergen</B>
( <A
	   HREF=mailto:juergen@idsia.ch>juergen@idsia.ch</A>)<BR>
<blockquote><A HREF=http://www.idsia.ch/~juergen/subgoals.html>A whole bunch of papers on hierarchical reinforcement learning (since 1990)</A><BR>
<i>journal papers and conference papers</i>

(HTML - 100 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Schmidhuber2.html>Abstract</A>: 
<BR>There is no teacher providing useful intermediate subgoals for our hierarchical reinforcement learni...
</BLOCKQUOTE><HR>
<!nextperson><B>Strehl, 
Alexander</B>
 , Carlos Diuk, Michael Littman( <A
	   HREF=mailto:strehl@cs.rutgers.edu>strehl@cs.rutgers.edu</A>)<BR>
<blockquote><A HREF=http://paul.rutgers.edu/~cdiuk/papers/StructLearnAAAI07.pdf>Efficient Structure Learning in Factored-state MDPs</A><BR>
<i>AAAI 2007</i>

(PDF - 115KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Strehl1.html>Abstract</A>: 
<BR>We consider the problem of reinforcement learning in
factored-state MDPs in the setting in which le...
</BLOCKQUOTE><HR>
<!nextperson><B>Wang, 
Gang</B>
 , Sridhar Mahadevan( <A
	   HREF=mailto:wanggan1@cse.msu.edu>wanggan1@cse.msu.edu</A>)<BR>
<blockquote><A HREF=http://www.cse.msu.edu/~mahadeva/papers/icml99.ps.gz>Hierarchical Optimization of Policy-Coupled Semi-Markov Decision Processes</A><BR>
<i>International Conference on Machine Learning (ICML-99)</i>

( gzipped Postscript - 250 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Wang1.html>Abstract</A>: 
<BR>Manufacturing is a challenging real-world domain for applying
MDP-based reinforcement learning algo...
</BLOCKQUOTE><HR>
<!nextperson><B>Wiering, M. and Schmidhuber, Jurgen</B>
 , ( <A
	   HREF=mailto:juergen@isdia.ch>juergen@isdia.ch</A>)<BR>
<blockquote>
<a href=ftp://ftp.idsia.ch/pub/juergen/hq96.ps.gz>HQ-Learning: Discovering
Markovian subgoals for non-Markovian reinforcement learning</a><br>
<i>Technical Report IDSIA-95-96, October 1996</i>

( gzipped Postscript - 111 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Schmidhuber1-temp.html>Abstract</A>: 
<BR>To solve partially observable Markov decision problems, we introduce
HQ-learning, a hierarchical ex...
</BLOCKQUOTE><HR>
<!nextperson><B>Singh, 
Satinder</B>
( <A
	   HREF=mailto:baveja@cs.colorado.edu>baveja@cs.colorado.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.colorado.edu/users/baveja/Papers/AAAI92.ps.gz>Reinforcement Learning with a Hierarchy of Abstract Models</A><BR>
<i>Appears in Proceedings of the Tenth National Conference on Artificial Intelligence,
1992</i>

( gzipped Postscript - 105 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Singh3.html>Abstract</A>: 
<BR>Reinforcement learning (RL) algorithms have traditionally been thought
of as trial and error learni...
</BLOCKQUOTE><HR>

<!nextperson><B>Thrun, Sebastian</B>
 , Anton Schwartz( <A HREF=
mailto:thrun+@heaven.learning.cs.cmu.edu>thrun+@heaven.learning.cs.cmu.edu>
<blockquote>
<A HREF= 
http://www.cs.cmu.edu/People/thrun/papers/thrun.nips7.reinforcement-learning.ps.gz>
Finding Structure in Reinforcement Learning</A><BR>
<i>Advances in Neural Information Processing Systems (NIPS) 7, 1995. </i>
 
( gzipped Postscript - 149 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Thrun1.html>Abstract</A>:
<BR>Reinforcement learning addresses the problem of learning to select
actions$
maximize one...
</BLOCKQUOTE><HR>
