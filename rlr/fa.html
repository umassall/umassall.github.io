<HTML>
<HEAD>
<META HTTP-EQUIV=REFRESH>
<TITLE>Publications on Function Approximation (RL)</TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<body bgcolor="#FFFFBB">
<CENTER>
<H1>Publications on Function Approximation (RL)</H1>
</CENTER>

<img align=right src="imgs/sower.gif">
<br><hr>

<!nextperson><B>Abe, 
Naoki</B>
 , Alan Biermann and Philip M. Long( <A
	   HREF=mailto:nabe@us.ibm.com >nabe@us.ibm.com </A>)<BR>
<blockquote><A HREF=http://www.comp.nus.edu.sg/~plong/publications/reinforcement.ps>Reinforcement learning with immediate rewards and linear hypotheses</A><BR>
<i>Algorithmica</i>

(Postscript - 350KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Abe1.html>Abstract</A>: 
<BR>We perform theoretical analysis of algorithms for reinforcement
learning with immediate rewards usi...
</BLOCKQUOTE><HR>
<!nextperson><B>Ackley, 
David</B>
 , Michael L. Littman( <A
	   HREF=mailto:ackley@cs.unm.edu>ackley@cs.unm.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/nips-crbp.ps>Generalization and scaling in reinforcement learning</A><BR>
<i>D. S. Touretzky, editor, Advances in Neural Information Processing Systems, volume 2, pages 550--557, San Mateo, CA, 1990. Morgan Kaufmann</i>

(Postscript - 140KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Ackley1.html>Abstract</A>: 
<BR>In associative reinforcement learning, an environment generates input
vectors, a learning system ge...
</BLOCKQUOTE><HR>
<!nextperson><B>Baird,
Leemon</B>
 , H. Klopf( <A
           HREF=mailto:leemon@cs.cmu.edu>leemon@cs.cmu.edu</A>)<BR>
<blockquote>
<A HREF=
http://www.leemon.com/papers/wirefit/index.html>
Reinforcement Learning with high-dimensional continuous actions </A><BR>
<i>Technical Report WL-TR-93-1147, Wright Laboratory, Wright-Patterson
Air Force Base, 1993</I>
 
(HTML)
<A HREF=http://web.cps.msu.edu/rlr/pub/Baird1.html>Abstract</A>:
<BR>Many reinforcement learning systems, such as Q-learning, or advantage
updating, require that a func...
</BLOCKQUOTE><HR>


<!nextperson><B>Baird, 
Leemon</B>
( <A
	   HREF=mailto:leemon@cs.cmu.edu>leemon@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=
http://www.leemon.com/papers/residual/index.html>
Residual Algorithms: Reinforcement Learning with Function
       Approximation</A><BR>
<i>Armand Prieditis & Stuart Russell, eds. Machine Learning:
       Proceedings of the Twelfth International Conference, 9-12 July, Morgan Kaufman
 Publishers, San Francisco, CA</i>

(HTML)
<A HREF=http://web.cps.msu.edu/rlr/pub/Baird2.html>Abstract</A>: 
<BR>A number of reinforcement learning algorithms have been developed that
are guaranteed to converge t...
</BLOCKQUOTE><HR>
<!nextperson><B>Bhulai, 
Sandjai</B>
( <A
	   HREF=mailto:sbhulai@cs.vu.nl>sbhulai@cs.vu.nl</A>)<BR>
<blockquote><A HREF=http://www.cs.vu.nl/~sbhulai/papers/thesis.html>Markov Decision Processes: the control of high-dimensional systems</A><BR>
<i>Ph.D. Thesis, Vrije Universiteit, 2002</i>

(Postscript - )
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Bhulai1.html>Abstract</A>: 
<BR>We develop algorithms for the computation of (nearly) optimal decision rules in high-dimensional sys...
</BLOCKQUOTE><HR>
<!nextperson><B>Boyan, 
Justin</B>
 , Andrew Moore( <A
	   HREF=mailto:Justin.Boyan@cs.cmu.edu>Justin.Boyan@cs.cmu.edu</A>)<BR>
<blockquote><A
HREF=http://www.cs.cmu.edu/afs/cs.cmu.edu/project/reinforcement/papers/boyan.funapprox-dp.ps.Z>
Generalization in Reinforcement Learning: Safely
       Approximating the Value Function</A><BR>
<i>Proceedings of Neural Information Processings
       Systems 7, Morgan Kaufmann, January 1995 (8 pages) </i>

(compressed Postscript - 743 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Boyan2.html>Abstract</A>: 
<BR>A straightforward approach to the curse of dimensionality in
reinforcement learning and dynamic pro...
</BLOCKQUOTE><HR>

<!nextperson><B>Boyan, 
Justin</B>
 , Andrew W. Moore( <A
	   HREF=mailto:jab@cs.cmu.edu>jab@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~jab/pubs/boyan.acyclic.ps>Learning Evaluation Functions for Large Acyclic Domains</A><BR>
<i>ICML-96</i>

(Postscript - 147KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Boyan4.html>Abstract</A>: 
<BR>  Some of the most successful recent applications of reinforcement
  learning have used neural netw...
</BLOCKQUOTE><HR>

<!nextperson><B>Carreras, 
Marc</B>
( <A
	   HREF=mailto:marcc@eia.udg.es>marcc@eia.udg.es</A>)<BR>
<blockquote><A HREF=http://eia.udg.es/~marcc/research/tesi.pdf>A Proposal of a Behavior-based Control Architecture with Reinforcement Learning for an Autonomous Underwater Robot</A><BR>
<i></i>

(pdf - 4 MB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Carreras1.html>Abstract</A>: 
<BR>The achievement of a mission with an autonomous robot in an unknown and unstructured environment is ...
</BLOCKQUOTE><HR>
<!nextperson><B>Coulom, 
Rémi</B>
( <A
	   HREF=mailto:Remi.Coulom@imag.fr>Remi.Coulom@imag.fr</A>)<BR>
<blockquote><A HREF=http://remi.coulom.free.fr/Thesis/>Reinforcement Learning Using Neural Networks, with Applications to Motor Control
</A><BR>
<i>PhD thesis</i>

(html - 1Mb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Coulom1.html>Abstract</A>: 
<BR>This thesis is a study of practical methods to estimate value functions with feedforward neural netw...
</BLOCKQUOTE><HR>
<!nextperson><B>Coulom, 
Rémi</B>
( <A
	   HREF=mailto:Remi.Coulom@free.fr>Remi.Coulom@free.fr</A>)<BR>
<blockquote><A HREF=http://remi.coulom.free.fr/Publications/ALT2002.pdf>Feedforward Neural Networks in Reinforcement Learning Applied to High-dimensional Motor Control</A><BR>
<i>Proceedings of ALT2002</i>

(pdf - 139 Kb)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Coulom2.html>Abstract</A>: 
<BR>Local linear function approximators are often preferred to feedforward neural networks to estimate v...
</BLOCKQUOTE><HR>
<!nextperson><B>Dietterich, 
Thomas</B>
( <A
	   HREF=mailto:tgd@cs.orst.edu>tgd@cs.orst.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.orst.edu/pub/tgd/papers/nips99-maxq-abstraction.ps.gz>State abstraction in MAXQ hierarchical reinforcement learning</A><BR>
<i>unpublished</i>

( gzipped Postscript - 102Kb)
<A HREF=http://www.cse.msu.edu/rlr/pub/Dietterich5.html>Abstract</A>: 
<BR>Many researchers have explored methods for hierarchical reinforcement
learning (RL) with tempora...
</BLOCKQUOTE><HR>
<!nextperson><B>Dimitrakakis, 
Christos</B>
( <A
	   HREF=mailto:olethros@geocities.com>olethros@geocities.com</A>)<BR>
<blockquote><A HREF=http://olethros.50megs.com/research/rl/ml99.ps.gz>Reinforcement Learning With Continuous Action Values</A><BR>
<i>unpublished</i>

( gzipped Postscript - 120KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Dimitrakakis1.html>Abstract</A>: 
<BR>The problem of reinforcement learning in the case of a continuous action set
remains largely unsolv...
</BLOCKQUOTE><HR>
<!nextperson><B>Ernst, 
Damien</B>
 , Pierre Geurts and Louis Wehenkel( <A
	   HREF=mailto:dernst@ulg.ac.be>dernst@ulg.ac.be</A>)<BR>
<blockquote><A HREF=http://www.montefiore.ulg.ac.be/~ernst/>Iteratively extending time horizon reinforcement learning</A><BR>
<i>Proceedings of ECML 2003</i>

(Postscript - 6 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ernst2.html>Abstract</A>: 
<BR>Reinforcement learning  aims to  determine an (infinite  time horizon)
optimal  control policy  fro...
</BLOCKQUOTE><HR>
<!nextperson><B>Ernst, 
Damien</B>
 , Geurts Pierre, Louis Wehenkel( <A
	   HREF=mailto:ernst@montefiore.ulg.ac.be>ernst@montefiore.ulg.ac.be</A>)<BR>
<blockquote><A HREF=http://www.montefiore.ulg.ac.be/~ernst>Tree-based batch mode reinforcement learning</A><BR>
<i>Journal of Machine Learning Research, April 2005, Volume 6, pp 503-556</i>

(Pdf - 1290 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ernst3.html>Abstract</A>: 
<BR>Reinforcement learning aims to determine an optimal control policy from interaction with a system or...
</BLOCKQUOTE><HR>
<!nextperson><B>Ernst, 
Damien</B>
 , Pierre Geurts, Mevludin Glavic, Louis Wehenkel( <A
	   HREF=mailto:ernst@montefiore.ulg.ac.be>ernst@montefiore.ulg.ac.be</A>)<BR>
<blockquote><A HREF=http://www.montefiore.ulg.ac.be/~ernst>Approximate value iteration in the reinforcement learning context. Application to electrical power system control</A><BR>
<i>International Journal of Emerging Electric Power Systems</i>

(.pdf - 780)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ernst4.html>Abstract</A>: 
<BR>In this paper we explain how to design intelligent agents able to process the information acquired f...
</BLOCKQUOTE><HR>
<!nextperson><B>Ernst, 
Damien</B>
( <A
	   HREF=mailto:ernst@montefiore.ulg.ac.be>ernst@montefiore.ulg.ac.be</A>)<BR>
<blockquote><A HREF=http://www.montefiore.ulg.ac.be/~ernst/>Selecting concise sets of samples for a reinforcement learning agent</A><BR>
<i>Conference Proceedings of CIRAS 2005</i>

(pdf - 1036 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ernst5.html>Abstract</A>: 
<BR>We derive an  algorithm for selecting from the set of samples gathered by a reinforcement learning a...
</BLOCKQUOTE><HR>
<!nextperson><B>Ernst, 
Damien</B>
 , Raphael Marée, Louis Wehenkel( <A
	   HREF=mailto:ernst@montefiore.ulg.ac.be>ernst@montefiore.ulg.ac.be</A>)<BR>
<blockquote><A HREF=http://www.montefiore.ulg.ac.be/~ernst/>Reinforcement learning with raw image pixels as state input</A><BR>
<i>International Workshop on Intelligent Computing in Pattern Analysis/Synthesis (IWICPAS). Proceedings series: Lecture Notes in Computer Science, Volume 4153, page 446-454, August 2006</i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ernst7.html>Abstract</A>: 
<BR>We report in this paper some positive simulation results obtained when 
image pixels are directly u...
</BLOCKQUOTE><HR>

<!nextperson><B>Fernandes de Arruda, Edilson (<A HREF=mailto:efarruda@gmail.com>efarruda@gmail.com</A>)</B><BR>
<blockquote><A 
HREF=http://authors.elsevier.com/redirect/http://dx.doi.org/10.1016/j.ejor.2010.11.019>Approximate 
Dynamic Programming via Direct Search in the Space of Value Function 
Approximations</A>
<BR>
<I>European Journal of Operational Research, 2010</I>
<A HREF=pub/Fernandes1.html>Abstract</A>:
<BR>This paper deals with approximate value iteration (AVI) algorithms applied to discounted dynamic programming 
(DP) problems. For a fixed control policy, the span semi-norm of the so-called Bellman residual is shown to be 
...
</BLOCKQUOTE><HR>

<!nextperson><B>Fernandez, 
Fernando</B>
 , Daniel Borrajo( <A
	   HREF=mailto:ffernand@grial.uc3m.es>ffernand@grial.uc3m.es</A>)<BR>
<blockquote><A
HREF=http://grial.uc3m.es/~ffernand/publicaciones.html#ijcai99></A>
<b>Vector Quantization Applied to Reinforcement Learning</b>
<BR>
<i>Proceedings of the Fifth Workshop on RoboCup. Stockholm, Sweden. August, 1999. IJCAI'99 </i>

(Postscript - 202 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Fernandez1.html>Abstract</A>: 
<BR>Reinforcement learning has proven to be a set of successful techniques for finding optimal policies ...
</BLOCKQUOTE><HR>
<!nextperson><B>Fernandez, 
Fernando</B>
 , Daniel Borrajo( <A
	   HREF=mailto:ffernand@inf.uc3m.es>ffernand@inf.uc3m.es</A>)<BR>
<blockquote><A HREF=http://scalab.uc3m.es/~ffernand>On Determinism Handling while Learning Reduced State Space Representations</A><BR>
<i>European Conference on Artificial Intelligence</i>

(Postscript - )
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Fernandez2.html>Abstract</A>: 
<BR>When applying a Reinforcement Learning technique to problems with continuous or very large state spa...
</BLOCKQUOTE><HR>
<!nextperson><B>Francois, 
Rivest</B>
 , Doina Precup( <A
	   HREF=mailto:rivestfr@iro.umontreal.ca>rivestfr@iro.umontreal.ca</A>)<BR>
<blockquote><A HREF=http://www-etud.iro.umontreal.ca/~rivestfr/Publications/ICML2003.pdf>Combining TD-learning with Cascade-correlation Networks</A><BR>
<i>ICML 2003</i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Francois1.html>Abstract</A>: 
<BR>Using neural networks to represent value
functions in reinforcement learning algorithms
often invo...
</BLOCKQUOTE><HR>
<!nextperson><B>Ghory, 
Imran</B>
( <A
	   HREF=mailto:imran@bits.bris.ac.uk>imran@bits.bris.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.cs.bris.ac.uk/Publications/Papers/2000100.pdf>Reinforcement Learning in Board Games</A><BR>
<i>Technical Report CSTR-04-004, Department of Computer Science, University of Bristol, May 2004.</i>

(pdf - 1097439 bytes)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Ghory1.html>Abstract</A>: 
<BR>This project investigates the application of the TD(lambda) reinforcement learning algorithm and neu...
</BLOCKQUOTE><HR>

<!nextperson><B>Girgin, S.</B>, Ph. Preux<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#icmla2008>Incremental Basis Function Expansion in Reinforcement Learning using Cascade-Correlation Networks</A><BR>
<i>ICML-A 2008</i>
</blockquote><HR>

<!nextperson><B>Girgin, S.</B>, Ph. Preux<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#erlars2008>Incremental basis function expansion in reinforcement learning using cascade-correlation networks</A><BR>
<i>Proc. ECAI Workshop, ERLARS, 2008</i>
</blockquote><HR>

<!nextperson><B>Girgin, S.</B>, Ph. Preux<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#ewrl2008>Basis Expansion In Natural Actor Critic Methods</A><BR>
<i>Recent Advances in reinforcement Learning, Springer LNAI 5323</i>
</blockquote><HR>

<!nextperson><B>Girgin, S.</B>, Ph. Preux<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#eurogp2008>Feature discovery in reinforcement learning using genetic programming</A><BR>
<i>Proc. 11th European Conference on Genetic Programming (EUROGP)</i>
</blockquote><HR>

<!nextperson><B>Littman, 
Michael</B>
 , Anthony Cassandra and Leslie Kaelbling( <A
	   HREF=mailto:mlittman@cs.duke.edu>mlittman@cs.duke.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.duke.edu/~mlittman/docs/ml95.ps>Learning
policies for partially observable environments: Scaling up</A><BR>
<i>Proceedings of the Twelfth
International Conference on Machine Learning</i>

(Postscript - 315K)
<A HREF=http://web.cps.msu.edu/rlr/pub/Littman5.html>Abstract</A>: 
<BR>Partially observable Markov decision processes (POMDPs) model decision
problems in which an agent t...
</BLOCKQUOTE><HR>

<!nextperson><B>Loth, M.</B>, Ph. Preux, M. Davy<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#esann2007>A unified view of TD algorithms - Intro\
ducing full-gradient TD and Equi-gradient descent TD</A><BR>
<i>Proc. 11th European Conference on Genetic Programming (EUROGP) Springer, 2008</i>
</blockquote><HR>

<!nextperson><B>Loth, M.</B>, M. Davy, Ph. Preux<BR>
<blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#adprl2007>Sparse temporal difference learning using LASSO</A><BR>
<i>Proc. IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning 2007</i>
</blockquote><HR>

<!nextperson><B>Matt, 
Andreas</B>
 , Georg Regensburger( <A
	   HREF=mailto:andreas.matt@uibk.ac.at>andreas.matt@uibk.ac.at</A>)<BR>
<blockquote><A HREF=http://mathematik.uibk.ac.at/users/rl/papers/thesismattregensburger04.pdf>"Reinforcement Learning for Several Environments: Theory and Applications"</A><BR>
<i>A joint PhD thesis by Andreas Matt and Georg Regensburger </i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Matt1.html>Abstract</A>: 
<BR>Until now reinforcement learning has been applied to learn the optimal behavior for a single environ...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/nips97.ps>Reinforcement Learning for Continuous Stochastic Control Problems</A><BR>
<i>Neural Information Processing Systems, 1997</i>

(Postscript - 809KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos1.html>Abstract</A>: 
<BR>This paper is concerned with the problem of Reinforcement Learning for continuous state
 space and ...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/ecml97ps.zip>A convergent Reinforcement Learning algorithm in the continuous case based on a Finite Difference method</A><BR>
<i>IJCAI'1997</i>

(compressed Postscript - 225Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos2.html>Abstract</A>: 
<BR> In this paper, we propose a convergent Reinforcement Learning algorithm for solving optimal
 contr...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/icml96.ps>A Convergent Reinforcement Learning algorithm in the continuous case : the Finite-Element Reinforcement Learning</A><BR>
<i>International 
Conference on Machine Learning, 1996</i>

(Postscript - 197Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos3.html>Abstract</A>: 
<BR>
 This paper presents a direct reinforcement learning algorithm, called Finite-Element
 Reinforcem...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/ecml98ps.zip>A general convergence method for Reinforcement Learning in the continuous case</A><BR>
<i>European Conference on Machine Learning, 1998</i>

(compressed Postscript - 230Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos4.html>Abstract</A>: 
<BR>In this paper, we propose a general method for designing convergent Reinforcement Learning
 algorit...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/ecml97ps.zip>Finite-Element methods with local triangulation refinement for continuous Reinforcement Learning problems</A><BR>
<i>European Conference on
 Machine Learning, 1997</i>

(compressed Postscript - 283Kb)
<A HREF=http://web.cps.msu.edu/rlr/pub/Munos5.html>Abstract</A>: 
<BR>
 This paper presents a reinforcement learning algorithm for generating an adaptive control for a
...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
 , Andrew Moore( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/ijcai99.ps.gz>Variable resolution discretization for high-accuracy solutions of 
optimal control problems</A><BR>
<i>IJCAI'99</i>

( gzipped Postscript - 315KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Munos6.html>Abstract</A>: 
<BR>State abstraction is of central importance in reinforcement learning and Markov Decision Processes. ...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
 , Leemon Baird, Andrew Moore( <A
	   HREF=mailto:munos@cs.cmu.edu>munos@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~munos/papers/ijcnn99.ps.gz>Gradient Descent Approaches to Neural-Net-Based Solutions of 
the Hamilton-Jacobi-Bellman Equation. </A><BR>
<i>IJCNN'99</i>

( gzipped Postscript - 128KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Munos7.html>Abstract</A>: 
<BR>In this paper we investigate new approaches to 
dynamic-programming-based optimal control of contin...
</BLOCKQUOTE><HR>
<!nextperson><B>Munos, 
Remi</B>
( <A
	   HREF=mailto:remi.munos@polytechnique.fr>remi.munos@polytechnique.fr</A>)<BR>
<blockquote><A HREF=http://www.cmap.polytechnique.fr/~munos/papers/icml03.ps.gz>Error Bounds for Approximate Policy Iteration</A><BR>
<i>Icml 2003</i>

( gzipped Postscript - 80 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Munos8.html>Abstract</A>: 
<BR>In Dynamic Programming, convergence of algorithms such as Value Iteration
or Policy Iteration resul...
</BLOCKQUOTE><HR>
<!nextperson><B>Ormoneit, 
Dirk</B>
 , Saunak Sen( <A
	   HREF=mailto:ormoneit@stat.stanford.edu>ormoneit@stat.stanford.edu</A>)<BR>
<blockquote><A HREF=http://www.robotics.stanford.edu/~ormoneit/publications/tr-1999-8-updated.ps>Kernel-Based Reinforcement Learning</A><BR>
<i>Department of Statistics, Stanford University, Technical Report No. 1999-8</i>

(Postscript - 260 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Ormoneit1.html>Abstract</A>: 
<BR>Kernel-based methods have recently attracted increased attention in
the machine learning literature...


</BLOCKQUOTE><HR>
<!nextperson><B>Preux, Ph.</B>, Girgin, S., Loth, M.
<BR><blockquote>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/rech/publis.html#adprl2009> Feature Discovery in Approximate Dynamic Programming</A> 
<BR>in Proc. Approximate Dynamic Programming and Reinforcement Learning  (ADPRL), IEEE Press, Nashville, Mar-Apr. 2009

</BLOCKQUOTE><HR>
<!nextperson><B>Reynolds, 
Stuart</B>
( <A
	   HREF=mailto:sir@cs.bham.ac.uk>sir@cs.bham.ac.uk</A>)<BR>
<blockquote><A HREF=http://cs.bham.ac.uk/~sir/pub/ukci-02.ps.gz>The Stability of General Discounted Reinforcement Learning with Linear Function Approximation</A><BR>
<i>UKCI'02</i>

( gzipped Postscript - 80)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Reynolds1.html>Abstract</A>: 
<BR>  This paper shows that general discounted return estimating
  reinforcement learning algorithms ca...
</BLOCKQUOTE><HR>
<!nextperson><B>Reynolds, 
Stuart</B>
( <A
	   HREF=mailto:sir@cs.bham.ac.uk>sir@cs.bham.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.cs.bham.ac.uk/~sir/pub/ml2k_DBP.ps.gz>Decision Boundary Partitioning: Variable Resolution Model-Free Reinforcement Learning</A><BR>
<i>ICML-2k</i>

( gzipped Postscript - 241 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Reynolds4.html>Abstract</A>: 
<BR>This paper presents a method to refine the resolution of a continuous state Q-function. Q-functions ...
</BLOCKQUOTE><HR>
<!nextperson><B>Reynolds, 
Stuart</B>
( <A
	   HREF=mailto:sir@cs.bham.ac.uk>sir@cs.bham.ac.uk</A>)<BR>
<blockquote><A HREF=http://www.cs.bham.ac.uk/~sir/pub/>Reinforcement Learning with Exploration</A><BR>
<i>PhD Thesis, School of Computer Science, The University of Birmingham, B15 2TT, UK</i>

( gzipped Postscript - 1.1MB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Reynolds5.html>Abstract</A>: 
<BR>Reinforcement Learning (RL) techniques may be used to find optimal controllers for multistep decisio...
</BLOCKQUOTE><HR>
<!nextperson><B>Rivest, 
Francois</B>
 , Yoshua Bengio, John Kalask( <A
	   HREF=mailto:rivestfr@iro.umontreal.ca>rivestfr@iro.umontreal.ca</A>)<BR>
<blockquote><A HREF=http://www-etud.iro.umontreal.ca/~rivestfr/Publications/NIPS2004.pdf>Brain Inspired Reinforcement Learning</A><BR>
<i>NIPS 2004 (NIPS 17)</i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Rivest1.html>Abstract</A>: 
<BR>Successful application of reinforcement learning algorithms often involves considerable hand-craftin...
</BLOCKQUOTE><HR>
<!nextperson><B>Siebel, 
Nils T</B>
( <A
	   HREF=mailto:nils-NOSPAM@siebel-research.de>nils-NOSPAM@siebel-research.de</A>)<BR>
<blockquote><A HREF=http://www.ks.informatik.uni-kiel.de/>Learning neural networks for visual servoing using evolutionary methods</A><BR>
<i>Proceedings of the 6th International Conference on Hybrid Intelligent Systems (HIS'06), Auckland, New Zealand</i>

(PDF - 168 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Siebel1.html>Abstract</A>: 
<BR>In this article we introduce a method to learn neural networks that solve a visual servoing task.  O...
</BLOCKQUOTE><HR>
<!nextperson><B>Siebel, 
Nils T</B>
 , Kassahun, Yohannes<blockquote><A HREF=http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelKassahun2006-HIS06.pdf>Learning neural networks for visual servoing using evolutionary methods</A><BR>
<i>Proceedings of the 6th International Conference on Hybrid Intelligent Systems (HIS'06), Auckland, New Zealand</i>

(PDF - 168 KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Siebel2.html>Abstract</A>: 
<BR>In this article we introduce a method to learn neural networks that solve a visual servoing task.  O...
</BLOCKQUOTE><HR>
<!nextperson><B>Singh, Satinder</B><blockquote>
<A HREF= ftp://ftp.cs.colorado.edu/users/baveja/Papers/Nips94.ps.gz>
Reinforcement Learning With Soft State Aggregation</A><BR>
 
<I> NIPS 7 </I>
 
( gzipped Postscript -  )
 
<BR><BR><a href=http://www.cps.msu.edu/rlr/pub/Singh5.html>Abstract</a>:
It is widely accepted that the use of more
compact representations than lookup tables is crucial to scaling...

</BLOCKQUOTE>
<hr>

<!nextperson><B>Strens, 
Malcolm</B>
( <A
	   HREF=mailto:mjstrens@qinetiq.com>mjstrens@qinetiq.com</A>)<BR>
<blockquote><A HREF=http://uk.geocities.com/mjstrens/aisbj.pdf>Learning Multi-Agent Search Strategies</A><BR>
<i>The Interdisciplinary Journal of Artificial Intelligence and the Simulation of Behaviour, 1(4), 2003. </i>

(pdf - 305KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Strens3.html>Abstract</A>: 
<BR>We identify a specialised class of reinforcement learning problem in which the agent(s) have the goa...
</BLOCKQUOTE><HR>
<!nextperson><B>Sutton, 
Rich</B>
( <A
	   HREF=mailto:rich@cs.umass.edu>rich@cs.umass.edu</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/sutton-96.ps.Z>Generalization in Reinforcement Learning:
Successful Examples Using Sparse Coarse Coding</A><BR>
<i>Advances in
Neural Information Processing Systems 8, pp. 1038-1044, MIT
Press</i>

(compressed Postscript - 230 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Sutton3.html>Abstract</A>: 
<BR>On large problems, reinforcement learning
       systems must use parameterized function approximat...
</BLOCKQUOTE><HR>
<!nextperson><B>Tadepalli, 
Prasad</B>
 , DoKyeong Ok( <A
	   HREF=mailto:tadepall@cs.orst.edu>tadepall@cs.orst.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.orst.edu/~tadepall/research/papers/local-linear-regression.ps>Scaling up average reward reinforcement learning by approximating
the domain models and the value function</A><BR>
<i>Proceedings of the Thirteenth International Conference on Machine Learning, pages 471-479.  Morgan Kaufmann, 1996</i>

(Postscript - )
<A HREF=http://web.cps.msu.edu/rlr/pub/Tadepalli1.html>Abstract</A>: 
<BR>Almost all the work in Average-reward Reinforcement Learning (ARL) so
far has focused on table-base...
</BLOCKQUOTE><HR>
<!nextperson><B>Tadepalli, 
Prasad</B>
 , DoKyeong Ok( <A
	   HREF=mailto:tadepall@cs.orst.edu>tadepall@cs.orst.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.orst.edu/~tadepall/research/papers/arl-aij.ps>Model-based Average Reward Reinforcement Learning</A><BR>
<i>Artificial Intelligenec</i>

(Postscript - 53 pages)
<A HREF=http://web.cps.msu.edu/rlr/pub/Tadepalli2.html>Abstract</A>: 
<BR>Reinforcement Learning (RL) is the study of programs that improve their 
performance by receiving r...
</BLOCKQUOTE><HR>
<!nextperson><B>Tadepalli, 
Prasad</B>
 , DoKyeong Ok( <A
	   HREF=mailto:tadepall@cs.orst.edu>tadepall@cs.orst.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.orst.edu/~tadepall/research/papers/arl-aij.ps>Model-based Average Reward Reinforcement Learning
</A><BR>
<i>Artificial Intelligenec</i>

(Postscript - 53 pages)
<A HREF=http://web.cps.msu.edu/rlr/pub/Tadepalli3.html>Abstract</A>: 
<BR>Reinforcement Learning (RL) is the study of programs that improve their
performance by receiving re...
</BLOCKQUOTE><HR>
<!nextperson><B>Tsitsiklis, 
John</B>
 , Benjamin Van Roy( <A
	   HREF=mailto:jnt@mit.edu>jnt@mit.edu</A>)<BR>
<blockquote><A HREF=http://web.mit.edu/jnt/www/Papers/J060-96-bvr-feature-pre.pdf>Feature-Based Methods for Large Scale Dynamic Programming</A><BR>
<i>Machine Learning, Vol. 22,
 1996, pp. 59-94.
</i>

<A HREF=http://web.cps.msu.edu/rlr/pub/Tsitsiklis2.html>Abstract</A>: 
<BR>We develop a methodological framework and present a few 
different ways in which dynamic programmin...
( PDF - 2.8 MB)
</BLOCKQUOTE><HR>
<!nextperson><B>Van Roy, 
Benjamin</B>
( <A
	   HREF=mailto:bvr@stanford.edu>bvr@stanford.edu</A>)<BR>
<blockquote><A HREF=http://www.stanford.edu/~bvr/psfiles/thesis.ps>Learning and Value Function Approximation in Complex Decision Processes</A><BR>
<i>PhD Thesis</i>

(Postscript - 1691 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/VanRoy1.html>Abstract</A>: 
<BR>In principle, a wide variety of sequential decision problems
-- ranging from dynamic resource alloc...
</BLOCKQUOTE><HR>
<!nextperson><B>Wilson, 
Stewart</B>
( <A
	   HREF=mailto:wilson@smith.rowland.org>wilson@smith.rowland.org</A>)<BR>
<blockquote><A HREF=ftp://ftp.cs.bham.ac.uk/pub/authors/T.Kovacs/lcs.archive/Wilson1998a.ps.gz>
Generalization in the XCS classifier system
</A><BR>
<i>Genetic Programming 1998: Proceedings of the Third Annual Conference.  San Francisco, CA: Morgan Kaufmann.</i>

(gzipped Postscript - 61 KB)
<A HREF=http://web.cps.msu.edu/rlr/pub/Wilson1.html>Abstract</A>: 
<BR>This paper studies two changes to XCS, a classifier system in which 
fitness is based on prediction...
</BLOCKQUOTE><HR>
<!nextperson><B>Xu, 
Xin</B>
 , Han-gen He and Dewen Hu( <A
	   HREF=mailto:xuxin_mail@263.net>xuxin_mail@263.net</A>)<BR>
<blockquote><A HREF=http://www.jair.org>Efficient Reinforcement Learning Using Recursive Least-Squares Methods</A><BR>
<i>Journal of Artificial Intelligence Research, Vol.16,2002, pp:259-292</i>

( gzipped Postscript - 700)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Xu1.html>Abstract</A>: 
<BR>The recursive least-squares (RLS) algorithm is one of the most well-known algorithms used in adaptiv...
</BLOCKQUOTE><HR>
<!nextperson><B>Yin, 
ChangMing</B>
( <A
	   HREF=mailto:cmyin@cs167.net>cmyin@cs167.net</A>)<BR>
<blockquote><A HREF=http://www.csuep.edu.cn/cs/~cmyin></A>
<b>Forgetting Algorithm for Q-learning</b>
<BR>
<i>unpublished</i>

(Microsoft Word - 120)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Yin2.html>Abstract</A>: 
<BR>...
</BLOCKQUOTE><HR>
