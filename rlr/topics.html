<html>
<head>
<title>Reinforcement Learning Repository at UMass, Amherst - Topics</title>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body bgcolor="FFFFBB">
<base target="rl-main">
</head>

<body bgcolor="FFFFBB">
<h3>Reinforcement Learning Repository at UMass, Amherst</h3>
<img src="imgs/bookmark.gif">
<b><font size=6>Topics in Reinforcement Learning</font></b>
<p>Reinforcement learning is an area of machine learning which addresses
how an autonomous agent can learn long-term successful behavior
through interaction with its environment. The term reinforcement
learning has its roots in behavioral psychology, in particular to
Pavlovian models of reward learning in animals. The modern theory of
reinforcement learning, however, is much more influenced by
mathematical theories of optimal control in operations research, such
as dynamic programming.

<p>Reinforcement learning differs from the more well-studied problem of
supervised learning, in that the learner is not given input-output
samples of the desired behavior. Rather, the learner is only supplied
scalar feedback regarding the appropriateness of the actions, after  
they have been carried out. What makes this credit assignment problem
even harder is that the feedback could be significantly delayed 
(e.g. win/loss in an extended game).


<br><br>

<li><b>Applications to Robotics</b>: &nbsp
   <a href=ar-top.html>overview</a> &nbsp
   <a href=ar.html>publications</a>
<br>
<li><b>Average-reward/Undiscounted Methods</b>: 
    <a href=un-top.html>overview</a> &nbsp
    <a href=un.html>publications</a> 
<br>
<li><b>Distributed and Multi-Agent RL</b>: &nbsp
    <a href=di-top.html>overview</a> &nbsp
    <a href=di.html>publications</a> 
<br>
<li><b>DP/MDP</b>: &nbsp
    <a href=dp-top.html>overview</a> &nbsp
    <a href=dp.html>publications</a> 
<br>
<li><b>Function Approximation</b>: &nbsp
    <a href=fa-top.html>overview</a> 
    <a href=fa.html>publications</a> &nbsp
<br>
<li><b>Hierarchical Methods</b>: &nbsp
    <a href=hm-top.html>overview</a> &nbsp
    <a href=hm.html>publications</a> 
<br>
<li><b>Industrial Applications</b>: &nbsp
    <a href=in-top.html>overview</a> &nbsp
    <a href=in.html>publications</a> 
<br>
<li><b>Neuro-biological RL</b>: &nbsp
    <a href=nb-top.html>overview</a> &nbsp
    <a href=nb.html>publications</a> 
<br>
<li><b>Partially observable Problems</b>: &nbsp
    <a href=po-top.html>overview</a> &nbsp
    <a href=po.html>publications</a> 
<br>
<li><b>Planning</b>: &nbsp
    <a href=pl-top.html>overview</a> &nbsp
    <a href=pl.html>publications</a> 
<li><b>Policy-space Search Methods</b>: &nbsp
    <a href=ps-top.html>overview</a> &nbsp
    <a href=ps.html>publications</a> 
<br>
<li><b>Shaping</b>: &nbsp
    <a href=sh-top.html>overview</a> &nbsp
    <a href=sh.html>publications</a> 
<br>
<li><b>TD-learning</b>: &nbsp
    <a href=td-top.html>overview</a> &nbsp
    <a href=td.html>publications</a> 
<br>
<li><b>Theoretical analysis</b>: &nbsp
    <a href=th-top.html>overview</a> &nbsp
    <a href=th.html>publications</a> 


