 <HTML>
<HEAD>
<META HTTP-EQUIV=REFRESH>
<TITLE>Publications on Distributed and Multi-Agent RL </TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35723838-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<body bgcolor="#FFFFBB">
<CENTER>
<H1>Publications on Distributed and Multi-Agent RL</H1>
</CENTER>

<img align=right src="imgs/sower.gif">

<br><br>
<hr>

<!nextperson><B>Dowling, Jim</B> , Eoin Curran, Raymond Cunningham, Vinny Cahill (<A
HREF=mailto:jdowling@sics.se>jdowling@sics.se</A>)<BR>
<blockquote><A HREF=https://www.cs.tcd.ie/publications/tech-reports/reports.05/TCD-CS-2005-38.pdf>Using Feedback in Collaborative Reinforcement Learning to Adaptively Optimise MANET Routing</A><BR>
<i>IEEE Transactions on Systems, Man and Cybernetics (Part A), Special 
Issue on Engineering Self-Orangized Distributed Systems</i>, vol. 35, no. 3, 
pages 360-372, May 2005.
<BR>
<B>Abstract:</B> This work describes a decentralized, multi-agent learning algorithm, called collaborative reinforcement learning and demonstrates how it can be used to optimize the system properties (e.g., throughput) of a routing algorithm for Mobile Ad Hoc Networks (MANETs).

</BLOCKQUOTE><HR>

<!nextperson><B>Dowling, Jim</B> , Seif Haridi (<A
HREF=mailto:jdowling@sics.se>jdowling@sics.se</A>)<BR>
<blockquote><A HREF=http://s.i-techonline.com/Book/Reinforcement-Learning/Reinforcement-Learning.zip>Decentralized Reinforcement Learning for the Online Optimization of Distributed Systems</A><BR>
Chapter in <i>Reinforcement Learning: Theory and Applications, Advanced Robotic 
Systems Journal</i>, Editors Cornelius Weber, Mark Elshaw and Norbert 
Michael Mayer. I-Tech Education and Publishing, ISBN 978-3-902613-14-1, 
2008: 142-167.
</BLOCKQUOTE><HR>


<!nextperson><B>Goldberg, 
Dani</B>
 , Maja Mataric( <A
	   HREF=mailto:dani@usc.edu>dani@usc.edu</A>)<BR>
<blockquote><A HREF=http://www-robotics.usc.edu/~maja/publications/aa99-wdani.ps.gz>Coordinating Mobile Robot Group Behavior Using a Model of Interaction Dynamics</A><BR>
<i>unpublished</i>

( gzipped Postscript - 263 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Goldberg1.html>Abstract</A>: 
<BR>In this paper we show how various levels of coordinated behavior may 
be achieved in a group of mob...
</BLOCKQUOTE><HR>
<!nextperson><B>Leslie, 
David</B>
 , E. J. Collins<blockquote><B>E-mail:</B> <A
	   HREF=mailto:dleslie@stats.ox.ac.uk>dleslie@stats.ox.ac.uk</A><BR>
<A HREF=http://www.stats.ox.ac.uk/~dleslie/papers/LeslieCollinsSICON04.pdf>Individual Q-learning in normal form games</A><BR>
<i>unpublished</i>

(PDF - 210K)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Leslie1.html>Abstract</A>: 
<BR>The single-agent multi-armed bandit problem can be solved by an
  agent that learns the values of e...
</BLOCKQUOTE><HR>
<!nextperson><B>Strens, 
Malcolm</B>
<blockquote><B>E-mail:</B> <A
	   HREF=mailto:mjstrens@qinetiq.com>mjstrens@qinetiq.com</A><BR>
<A HREF=http://uk.geocities.com/mjstrens/aisbj.pdf>Learning Multi-Agent Search Strategies</A><BR>
<i>The Interdisciplinary Journal of Artificial Intelligence and the Simulation of Behaviour, 1(4), 2003. </i>

(pdf - 305KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Strens3.html>Abstract</A>: 
<BR>We identify a specialised class of reinforcement learning problem in which the agent(s) have the goa...
</BLOCKQUOTE><HR>
<!nextperson><B>Tambe, 
Milind</B>
 , Jafar Adibi, Yaser Al-Onaizan, Ali Erdem, Gal Kaminaka, Stacy Marsella, Ion Muslea, Marcello Tallis( <A
	   HREF=mailto:robocup-sim@isi.edu>robocup-sim@isi.edu</A>)<BR>
<blockquote><A HREF=http://www.isi.edu/teamcore/tambe/papers/99/AIJ.ps>Building Agent Teams Using an Explicit Teamwork Model and Learning</A><BR>
<i>Artificial Intelligence 1999</i>

(Postscript - 790 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Tambe1.html>Abstract</A>: 
<BR>Multi-agent collaboration or teamwork and learning are two critical research challenges in a large ...
</BLOCKQUOTE><HR>
<!nextperson><B>Tangamchit, 
Poj</B>
 , John M. Dolan, Pradeep K. Khosla<blockquote><B>E-mail:</B> <A
	   HREF=mailto:pojt@cmu.edu>pojt@cmu.edu</A><BR>
<A HREF=http://www.andrew.cmu.edu/~poj/paper/ICRA02.pdf>The Necessity of Average Rewards in Cooperative Multirobot Learning</A><BR>
<i>ICRA 2002</i>

(pdf - 176KB)
<A HREF=http://www-anw.cs.umass.edu/rlr/pub/Tangamchit1.html>Abstract</A>: 
<BR>Learning can be an effective way for robot systems to deal with dynamic environments and changing ta...
</BLOCKQUOTE><HR>
<!nextperson><B>Tumer, 
Kagan</B>
 , David Wolpert( <A
	   HREF=mailto:kagan@ptolemy.arc.nasa.gov>kagan@ptolemy.arc.nasa.gov</A>)<BR>
<blockquote><A HREF=http://ic.arc.nasa.gov/people/kagan/pubs/aaai00_braess.ps>Collective Intelligence and Braess' Paradox</A><BR>
<i>To appear in AAAI 2000 in Austin, Tx</i>

(Postscript - 330 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Tumer1.html>Abstract</A>: 
<BR>We consider the use of multi-agent systems to control network routing. Conventional 
approaches to ...
</BLOCKQUOTE><HR>
<!nextperson><B>Veloso, 
Manuela</B>
 , William Uther, Masahiro Fujita, Minoru Asada, Hiroaki Kitano( <A
	   HREF=mailto:veloso@cs.cmu.edu>veloso@cs.cmu.edu</A>)<BR>
<blockquote><A HREF=http://www.cs.cmu.edu/~mmv/papers/iros98.pdf>Playing Soccer with Legged Robots</A><BR>
<i>Proceedings of IROS-98, Intelligent Robots and Systems Conference</i>

( PDF - 278 KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Veloso1.html>Abstract</A>: 
<BR>Sony has provided a remarkable platform for research and development in robotic agents, namely fully...
</BLOCKQUOTE><HR>
<!nextperson><B>Wang, 
Gang</B>
 , Sridhar Mahadevan( <A
	   HREF=mailto:wanggan1@cse.msu.edu>wanggan1@cse.msu.edu</A>)<BR>
<blockquote><A HREF=http://www.cse.msu.edu/~mahadeva/papers/icml99.ps.gz>Hierarchical Optimization of Policy-Coupled Semi-Markov Decision Processes</A><BR>
<i>International Conference on Machine Learning (ICML-99)</i>

( gzipped Postscript - 250)
<A HREF=http://www.cse.msu.edu/rlr/pub/Wang1.html>Abstract</A>: 
<BR>Manufacturing is a challenging real-world domain for applying
MDP-based reinforcement learning algo...
</BLOCKQUOTE><HR>
<!nextperson><B>Wolpert, 
David</B>
 , Kagan Tumer( <A
	   HREF=mailto:dhw@ptolemy.arc.nasa.gov>dhw@ptolemy.arc.nasa.gov</A>)<BR>
<blockquote><A HREF=http://ic.arc.nasa.gov/people/kagan/pubs/coin_intro99.ps>An introduction to Collective Intelligence</A><BR>
<i>NASA tech rep NASA-ARC-IC-99-63, (to appear in J. M. Bradshaw, ed, handbook on agent technology)</i>

(Postscript - 1.4 MB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Wolpert1.html>Abstract</A>: 
<BR>This paper introduces the concept of  ``COllective INtelligence'' (COIN). A COIN is a large
multi-a...
</BLOCKQUOTE><HR>
<!nextperson><B>Wolpert, 
David</B>
 , Kevin Wheeler and Kagan Tumer( <A
	   HREF=mailto:dhw@ptolemy.arc.nasa.gov>dhw@ptolemy.arc.nasa.gov</A>)<BR>
<blockquote><A HREF=http://ic.arc.nasa.gov/people/kagan/pubs/bar_europhys2000.ps>Collective Intelligence for Control of Distributed Dynamical
Systems</A><BR>
<i>Europhysics Letters , Vol. 49, No. 6, March 2000.</i>

(Postscript - 350KB)
<A HREF=http://www.cse.msu.edu/rlr/pub/Wolpert2.html>Abstract</A>: 
<BR>We consider the El Farol bar problem (W. B. Arthur, The American Economic Review , 84(2): 406--411 (...
</BLOCKQUOTE><HR>
<!nextperson><B>preux, 
philippe</B>
 , samuel delepoulle, jean-claude darcheville<blockquote><B>E-mail:</B> <A
	   HREF=mailto:philippe.preux@univ-lille3.fr>philippe.preux@univ-lille3.fr</A><BR>
<A HREF=http://www.grappa.univ-lille3.fr/~ppreux/papiers/isj.draft.pdf>A Generic architecture for Adaptive Agents Based on Reinforcement Learning</A><BR>
<i>Information Sciences Journal</i>

<A HREF=http://www-anw.cs.umass.edu/rlr/pub/preux1.html>Abstract</A>: 
<BR>In this paper, we present MAABAC, a generic model for building adaptive agents: they learn new behav...
</BLOCKQUOTE><HR>
