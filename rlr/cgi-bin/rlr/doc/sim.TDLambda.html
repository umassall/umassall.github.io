<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<!--NewPage-->
<html>
<head>
<!-- Generated by javadoc on Tue Jul 29 22:00:59 GMT+01:00 1997 -->
<title>
  Class sim.TDLambda
</title>
</head>
<body>
<a name="_top_"></a>
<pre>
<a href="packages.html">All Packages</a>  <a href="tree.html">Class Hierarchy</a>  <a href="Package-sim.html">This Package</a>  <a href="sim.Simulator.html#_top_">Previous</a>  <a href="Package-sim.html">Next</a>  <a href="AllNames.html">Index</a></pre>
<hr>
<h1>
  Class sim.TDLambda
</h1>
<pre>
java.lang.Object
   |
   +----<a href="sim.Experiment.html#_top_">sim.Experiment</a>
           |
           +----sim.TDLambda
</pre>
<hr>
<dl>
  <dt> public class <b>TDLambda</b>
  <dt> extends <a href="sim.Experiment.html#_top_">Experiment</a>
</dl>
Perform Temporal Difference learning, TD(lambda), with a given Markov Decision
 Process or Markov chain and function approximator.  If the MDP is a Markov chain, then one
 can set the exploration factor to 0 and perform standard TD(lambda) for predicting the
 value of the states.  Given an MDP then the object implements TD(lambda) such that anytime
 the system explores the trace is set to 0.  This object has a decay factor for the
 exploration rate, so that one can explore extensively in the initial stages of learning
 and reduce the exploration rate in latter stages of learning.  The derivative
 calculations with respect to the inputs have not been fully implemented here.
    <p>This code is (c) 1996 Mance E. Harmon
    <<a href=mailto:harmonme@aa.wpafb.af.mil>harmonme@aa.wpafb.af.mil</a>>,
    <a href=http://www.cs.cmu.edu/~baird/java>http://www.cs.cmu.edu/~baird/java</a><br>
    The source and object code may be redistributed freely.
    If the code is modified, please state so in the comments.
<p>
<dl>
  <dt> <b>Version:</b>
  <dd> 1.05, 17 June 97
  <dt> <b>Author:</b>
  <dd> Mance E. Harmon
</dl>
<hr>
<a name="index"></a>
<h2>
  <img src="images/variable-index.gif" width=207 height=38 alt="Variable Index">
</h2>
<dl>
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#action"><b>action</b></a>
  <dd> An action possible in the MDP
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#dEdIn"><b>dEdIn</b></a>
  <dd> gradient of mean squared error  wrt inputs
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#dEdWeights"><b>dEdWeights</b></a>
  <dd> gradient of mean squared error wrt weights
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#dEdWeightsSum"><b>dEdWeightsSum</b></a>
  <dd> gradient of mean squared error summed for all training examples
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#dEdWeightsV1"><b>dEdWeightsV1</b></a>
  <dd> gradient of mean squared error wrt weights of maximum advantage in successor state
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#desiredOutputs"><b>desiredOutputs</b></a>
  <dd> The correct output that the function approximator learns to give
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#dt"><b>dt</b></a>
  <dd> The time step size used in transitioning from state x(t) to x(t+1)
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#error"><b>error</b></a>
  <dd> a noisy estimate of the error being gradient descended on
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#expDecay"><b>expDecay</b></a>
  <dd> The exploration decay rate.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#explore"><b>explore</b></a>
  <dd> The exploration rate
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#function"><b>function</b></a>
  <dd> the function approximator whose weights will be trained
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#gamma"><b>gamma</b></a>
  <dd> The discount factor
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#hessian"><b>hessian</b></a>
  <dd> hessian of mean squared error wrt weights
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#incremental"><b>incremental</b></a>
  <dd> The mode of learning: incremental or epoch-wise.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#inputs"><b>inputs</b></a>
  <dd> The input vector to the function approximator
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#lambda"><b>lambda</b></a>
  <dd> The weighting factor for gradients.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#logSmoothedError"><b>logSmoothedError</b></a>
  <dd> log base 10 of the smoothed error
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#mdp"><b>mdp</b></a>
  <dd> the mdp to control
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#oldState"><b>oldState</b></a>
  <dd> A copy of the original state.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#outputs"><b>outputs</b></a>
  <dd> The output vector from the function approximator
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#random"><b>random</b></a>
  <dd> The random number generator
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#rate"><b>rate</b></a>
  <dd> the learning rate, a small positive number
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#seed"><b>seed</b></a>
  <dd> the random number seed
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#smoothedError"><b>smoothedError</b></a>
  <dd> an exponentially smoothed estimate of the error
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#smoothingFactor"><b>smoothingFactor</b></a>
  <dd> the constant used to smooth the error (near 1 = long halflife)
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#state"><b>state</b></a>
  <dd> The state of the MDP
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#tcounter"><b>tcounter</b></a>
  <dd> When doing epoch-wise training (not updating the weights until the end of a trajectory,
 this variable keeps track of the number of transitions.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#time"><b>time</b></a>
  <dd> current time (increments once per weight change
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#tolerance"><b>tolerance</b></a>
  <dd> stop learning when smoothed error < tolerance
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#trace"><b>trace</b></a>
  <dd> The weighted average of the gradients.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#valueKnown"><b>valueKnown</b></a>
  <dd> A flag stating whether or not we know for certain the value of a state.
  <dt> <img src="images/magenta-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#weights"><b>weights</b></a>
  <dd> all the weights in the function approximator as a column vector
</dl>
<h2>
  <img src="images/constructor-index.gif" width=275 height=38 alt="Constructor Index">
</h2>
<dl>
  <dt> <img src="images/yellow-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#TDLambda()"><b>TDLambda</b></a>()
  <dd> 
</dl>
<h2>
  <img src="images/method-index.gif" width=207 height=38 alt="Method Index">
</h2>
<dl>
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#BNF(int)"><b>BNF</b></a>(int)
  <dd> Return the BNF description of how to parse the parameters of this object.
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#evaluate()"><b>evaluate</b></a>()
  <dd> return the scalar output for the current dInput vector
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#findGradient()"><b>findGradient</b></a>()
  <dd> update the fGradient vector based on the current fInput vector
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#findHessian()"><b>findHessian</b></a>()
  <dd> update the fHessian vector based on the current fInput vector
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#getGradient()"><b>getGradient</b></a>()
  <dd> The gradient of f(x) with respect to x (a column vector)
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#getHessian()"><b>getHessian</b></a>()
  <dd> The hessian of f(x) with respect to x (a square matrix)
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#getInput()"><b>getInput</b></a>()
  <dd> The input x sent to the function f(x) (a column vector)
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#initialize(int)"><b>initialize</b></a>(int)
  <dd> Initialize, either partially or completely.
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#parse(parse.Parser, int)"><b>parse</b></a>(Parser, int)
  <dd> Parse the input file to get the parameters for this object.
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#run()"><b>run</b></a>()
  <dd> This runs the simulation.
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#setWatchManager(watch.WatchManager, java.lang.String)"><b>setWatchManager</b></a>(WatchManager, String)
  <dd> Register all variables with this WatchManager.
  <dt> <img src="images/red-ball-small.gif" width=6 height=6 alt=" o ">
	<a href="#unparse(parse.Unparser, int)"><b>unparse</b></a>(Unparser, int)
  <dd> Output a description of this object that can be parsed with parse().
</dl>
<a name="variables"></a>
<h2>
  <img src="images/variables.gif" width=153 height=38 alt="Variables">
</h2>
<a name="mdp"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>mdp</b>
<pre>
 protected <a href="sim.mdp.MDP.html#_top_">MDP</a> mdp
</pre>
<dl>
  <dd> the mdp to control<p>
</dl>
<a name="function"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>function</b>
<pre>
 protected <a href="sim.funApp.FunApp.html#_top_">FunApp</a> function
</pre>
<dl>
  <dd> the function approximator whose weights will be trained<p>
</dl>
<a name="seed"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>seed</b>
<pre>
 protected IntExp seed
</pre>
<dl>
  <dd> the random number seed<p>
</dl>
<a name="weights"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>weights</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> weights
</pre>
<dl>
  <dd> all the weights in the function approximator as a column vector<p>
</dl>
<a name="dEdWeights"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>dEdWeights</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> dEdWeights
</pre>
<dl>
  <dd> gradient of mean squared error wrt weights<p>
</dl>
<a name="dEdWeightsSum"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>dEdWeightsSum</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> dEdWeightsSum
</pre>
<dl>
  <dd> gradient of mean squared error summed for all training examples<p>
</dl>
<a name="dEdIn"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>dEdIn</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> dEdIn
</pre>
<dl>
  <dd> gradient of mean squared error  wrt inputs<p>
</dl>
<a name="dEdWeightsV1"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>dEdWeightsV1</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> dEdWeightsV1
</pre>
<dl>
  <dd> gradient of mean squared error wrt weights of maximum advantage in successor state<p>
</dl>
<a name="trace"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>trace</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> trace
</pre>
<dl>
  <dd> The weighted average of the gradients.  The weighting factor is lambda.<p>
</dl>
<a name="hessian"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>hessian</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> hessian
</pre>
<dl>
  <dd> hessian of mean squared error wrt weights<p>
</dl>
<a name="inputs"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>inputs</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> inputs
</pre>
<dl>
  <dd> The input vector to the function approximator<p>
</dl>
<a name="outputs"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>outputs</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> outputs
</pre>
<dl>
  <dd> The output vector from the function approximator<p>
</dl>
<a name="state"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>state</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> state
</pre>
<dl>
  <dd> The state of the MDP<p>
</dl>
<a name="action"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>action</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> action
</pre>
<dl>
  <dd> An action possible in the MDP<p>
</dl>
<a name="explore"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>explore</b>
<pre>
 protected NumExp explore
</pre>
<dl>
  <dd> The exploration rate<p>
</dl>
<a name="expDecay"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>expDecay</b>
<pre>
 protected NumExp expDecay
</pre>
<dl>
  <dd> The exploration decay rate. A value of 0.9 means a half-life of approximately 7, and
 a value 0.99 means a half-life of approximately 70.<p>
</dl>
<a name="gamma"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>gamma</b>
<pre>
 protected NumExp gamma
</pre>
<dl>
  <dd> The discount factor<p>
</dl>
<a name="desiredOutputs"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>desiredOutputs</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> desiredOutputs
</pre>
<dl>
  <dd> The correct output that the function approximator learns to give<p>
</dl>
<a name="dt"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>dt</b>
<pre>
 protected NumExp dt
</pre>
<dl>
  <dd> The time step size used in transitioning from state x(t) to x(t+1)<p>
</dl>
<a name="oldState"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>oldState</b>
<pre>
 protected <a href="matrix.MatrixD.html#_top_">MatrixD</a> oldState
</pre>
<dl>
  <dd> A copy of the original state.<p>
</dl>
<a name="incremental"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>incremental</b>
<pre>
 protected boolean incremental
</pre>
<dl>
  <dd> The mode of learning: incremental or epoch-wise.<p>
</dl>
<a name="valueKnown"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>valueKnown</b>
<pre>
 protected <a href="pointer.PBoolean.html#_top_">PBoolean</a> valueKnown
</pre>
<dl>
  <dd> A flag stating whether or not we know for certain the value of a state.<p>
</dl>
<a name="lambda"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>lambda</b>
<pre>
 protected NumExp lambda
</pre>
<dl>
  <dd> The weighting factor for gradients.<p>
</dl>
<a name="random"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>random</b>
<pre>
 protected <a href="Random.html#_top_">Random</a> random
</pre>
<dl>
  <dd> The random number generator<p>
</dl>
<a name="error"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>error</b>
<pre>
 protected <a href="pointer.PDouble.html#_top_">PDouble</a> error
</pre>
<dl>
  <dd> a noisy estimate of the error being gradient descended on<p>
</dl>
<a name="smoothedError"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>smoothedError</b>
<pre>
 protected <a href="pointer.PDouble.html#_top_">PDouble</a> smoothedError
</pre>
<dl>
  <dd> an exponentially smoothed estimate of the error<p>
</dl>
<a name="smoothingFactor"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>smoothingFactor</b>
<pre>
 protected NumExp smoothingFactor
</pre>
<dl>
  <dd> the constant used to smooth the error (near 1 = long halflife)<p>
</dl>
<a name="tolerance"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>tolerance</b>
<pre>
 protected NumExp tolerance
</pre>
<dl>
  <dd> stop learning when smoothed error < tolerance<p>
</dl>
<a name="logSmoothedError"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>logSmoothedError</b>
<pre>
 protected <a href="pointer.PDouble.html#_top_">PDouble</a> logSmoothedError
</pre>
<dl>
  <dd> log base 10 of the smoothed error<p>
</dl>
<a name="time"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>time</b>
<pre>
 protected <a href="pointer.PInt.html#_top_">PInt</a> time
</pre>
<dl>
  <dd> current time (increments once per weight change<p>
</dl>
<a name="rate"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>rate</b>
<pre>
 protected NumExp rate
</pre>
<dl>
  <dd> the learning rate, a small positive number<p>
</dl>
<a name="tcounter"><img src="images/magenta-ball.gif" width=12 height=12 alt=" o "></a>
<b>tcounter</b>
<pre>
 protected int tcounter
</pre>
<dl>
  <dd> When doing epoch-wise training (not updating the weights until the end of a trajectory,
 this variable keeps track of the number of transitions.<p>
</dl>
<a name="constructors"></a>
<h2>
  <img src="images/constructors.gif" width=231 height=38 alt="Constructors">
</h2>
<a name="TDLambda"></a>
<a name="TDLambda()"><img src="images/yellow-ball.gif" width=12 height=12 alt=" o "></a>
<b>TDLambda</b>
<pre>
 public TDLambda()
</pre>
<a name="methods"></a>
<h2>
  <img src="images/methods.gif" width=151 height=38 alt="Methods">
</h2>
<a name="setWatchManager(watch.WatchManager, java.lang.String)"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="setWatchManager"><b>setWatchManager</b></a>
<pre>
 public void setWatchManager(<a href="watch.WatchManager.html#_top_">WatchManager</a> wm,
                             String name)
</pre>
<dl>
  <dd> Register all variables with this WatchManager.
 This will be called after all parsing is done.
 setWatchManager should be overridden and forced to
 call the same method on all the other objects in the experiment.
<p>
  <dd><dl>
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#setWatchManager(watch.WatchManager, java.lang.String)">setWatchManager</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
  </dl></dd>
</dl>
<a name="BNF(int)"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="BNF"><b>BNF</b></a>
<pre>
 public String BNF(int lang)
</pre>
<dl>
  <dd> Return the BNF description of how to parse the parameters of this object.
<p>
  <dd><dl>
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#BNF(int)">BNF</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
  </dl></dd>
</dl>
<a name="unparse(parse.Unparser, int)"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="unparse"><b>unparse</b></a>
<pre>
 public void unparse(<a href="parse.Unparser.html#_top_">Unparser</a> u,
                     int lang)
</pre>
<dl>
  <dd> Output a description of this object that can be parsed with parse().
<p>
  <dd><dl>
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#unparse(parse.Unparser, int)">unparse</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
    <dt> <b>See Also:</b>
    <dd> <a href="parse.Parsable.html#_top_">Parsable</a>
  </dl></dd>
</dl>
<a name="parse(parse.Parser, int)"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="parse"><b>parse</b></a>
<pre>
 public Object parse(<a href="parse.Parser.html#_top_">Parser</a> p,
                     int lang) throws <a href="parse.ParserException.html#_top_">ParserException</a>
</pre>
<dl>
  <dd> Parse the input file to get the parameters for this object.
<p>
  <dd><dl>
    <dt> <b>Throws:</b> <a href="parse.ParserException.html#_top_">ParserException</a>
    <dd> parser didn't find the required token
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#parse(parse.Parser, int)">parse</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
  </dl></dd>
</dl>
<a name="run()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="run"><b>run</b></a>
<pre>
 public void run()
</pre>
<dl>
  <dd> This runs the simulation.  The function returns when the simulation
 is completely done.  As the simulation is running, it should call
 the watchManager.update() function periodically so all the display
 windows can be updated.
<p>
  <dd><dl>
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#run()">run</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
  </dl></dd>
</dl>
<a name="getInput()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="getInput"><b>getInput</b></a>
<pre>
 public <a href="matrix.MatrixD.html#_top_">MatrixD</a> getInput()
</pre>
<dl>
  <dd> The input x sent to the function f(x) (a column vector)
<p>
</dl>
<a name="getGradient()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="getGradient"><b>getGradient</b></a>
<pre>
 public <a href="matrix.MatrixD.html#_top_">MatrixD</a> getGradient()
</pre>
<dl>
  <dd> The gradient of f(x) with respect to x (a column vector)
<p>
</dl>
<a name="evaluate()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="evaluate"><b>evaluate</b></a>
<pre>
 public double evaluate()
</pre>
<dl>
  <dd> return the scalar output for the current dInput vector
<p>
</dl>
<a name="findGradient()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="findGradient"><b>findGradient</b></a>
<pre>
 public void findGradient()
</pre>
<dl>
  <dd> update the fGradient vector based on the current fInput vector
<p>
</dl>
<a name="getHessian()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="getHessian"><b>getHessian</b></a>
<pre>
 public <a href="matrix.MatrixD.html#_top_">MatrixD</a> getHessian()
</pre>
<dl>
  <dd> The hessian of f(x) with respect to x (a square matrix)
<p>
</dl>
<a name="findHessian()"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="findHessian"><b>findHessian</b></a>
<pre>
 public void findHessian()
</pre>
<dl>
  <dd> update the fHessian vector based on the current fInput vector
<p>
</dl>
<a name="initialize(int)"><img src="images/red-ball.gif" width=12 height=12 alt=" o "></a>
<a name="initialize"><b>initialize</b></a>
<pre>
 public void initialize(int level)
</pre>
<dl>
  <dd> Initialize, either partially or completely.
<p>
  <dd><dl>
    <dt> <b>Overrides:</b>
    <dd> <a href="sim.Experiment.html#initialize(int)">initialize</a> in class <a href="sim.Experiment.html#_top_">Experiment</a>
    <dt> <b>See Also:</b>
    <dd> <a href="parse.Parsable.html#initialize">initialize</a>
  </dl></dd>
</dl>
<hr>
<pre>
<a href="packages.html">All Packages</a>  <a href="tree.html">Class Hierarchy</a>  <a href="Package-sim.html">This Package</a>  <a href="sim.Simulator.html#_top_">Previous</a>  <a href="Package-sim.html">Next</a>  <a href="AllNames.html">Index</a></pre>
</body>
</html>
