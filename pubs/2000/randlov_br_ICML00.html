<HTML>
<Head>
<Title>Publication: RandlovJ00</Title>
<META name="description" content="Combining reinforcement learning with a local control algorithm">

<META name="keywords" content="reinforcement learning, LQR control, chaos control">
</Head>
<BODY BGCOLOR="#FFFFFF">

<FONT SIZE="-1"><A HREF="http://www.cs.umass.edu/~mtr/">[Mike Rosenstein]</A></FONT>

<P>

<TABLE WIDTH="635" CELLPADDING=3 BORDER="0">
<TR><TD ALIGN="LEFT" COLSPAN="2">
<HR><FONT SIZE=+2><CENTER>Combining reinforcement learning with a local control 
algorithm</CENTER></FONT>
</TD></TR><TR><TD COLSPAN="2">
J. Randlov, A.G. Barto and M.T. Rosenstein. Combining
reinforcement learning with a local control algorithm.  In
<I>Proceedings of the Seventeenth International Conference on Machine
Learning</I>, 775-782, 2000.
</TD></TR>


<TR><TD COLSPAN="2"><B>Abstract: </B>
We explore combining reinforcement learning with a hand-crafted local
controller in a manner suggested by the chaotic control algorithm of
Vincent, Schmitt and Vincent (1994). A closed-loop controller is
designed using conventional means that creates a domain of attraction
about a target state. Chaotic behavior is used or induced to bring the
system into this region, at which time the local controller is turned
on to bring the system to the target state and stabilize it there. We
describe experiments in which we use reinforcement learning instead
of, and in addition to, chaotic behavior to learn an efficient policy
for driving the system into the local controller's domain of
attraction. Using a simulated double pendulum, we illustrate how this
method allows reinforcement learning to be effective in a problem that
cannot be easily solved by reinforcement learning alone, and we show
how reinforcement learning can improve upon the chaotic control
algorithm when the domain of attraction can only be approximately
determined. Similar results are shown using the Henon map. This is a
simple and effective way of extending reinforcement learning to more
difficult problems.
</TD></TR>

<TR><TD COLSPAN="2"><B>Download: </B>
<A HREF="RandlovJ00.pdf">pdf</A> (211KB),
<A HREF="RandlovJ00.ps.gz">ps.gz</A> (131KB)
</TD></TR>
<TR><TD COLSPAN="2"><B>See also: </B></TD>
</TR><TR><TD WIDTH="10">&nbsp</TD><TD>
<A HREF="RosensteinM02b.html">Supervised learning combined with an
actor-critic architecture</A><BR>
</TD>
</TR>
</TABLE>


<TABLE WIDTH="635" CELLPADDING=3 BORDER="0">
<TR><TD ALIGN="LEFT">
<HR><FONT SIZE=-2>updated 10-Oct-2002<BR>
<A HREF="mailto:mtr@cs.umass.edu">mtr@cs.umass.edu</A>
</FONT></TD></TR>
</TABLE>


</BODY></HTML>

