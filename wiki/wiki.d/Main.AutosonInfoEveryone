version=pmwiki-2.1.26 ordered=1 urlencoded=1
agent=Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.13pre) Gecko/20071129 CentOS/1.0.9-7.el4.centos SeaMonkey/1.0.9
author=
csum=
ctime=1210529882
host=128.119.241.208
name=Main.AutosonInfoEveryone
rev=8
targets=Main.WritingToLocalDrives
text=Unless otherwise noted, type the commands in your shell.%0a%0a'''Three simple commands: '''%0a* aulook: lists the job and machine they're running on. %0a* aulook -group or aulook -g : lists every possible machine or group.%0a* [[augui -> http://www-all.cs.umass.edu/augui/augui.html]]: brings up the the graphical interface (written by Amy McGovern)%0a%0a'''Run Autoson Remotely: '''Some people have problems running autoson remotely (i.e. ssh'ing into a lab machine and running autoson commands). That is because there is something weird with how the paths are defined when you ssh into a machine versus when you physically log in to a machine. To run autoson commands remotely, specifiy the full path name or mess with your .cshrc type of file so that it knows to look for those paths when you ssh. I don't know exactly what the problem is, but specifying the full path name is a solution. %0a* if you ssh into entropy, the path name is /anw/software/bin/x86_64/[autoson command]%0a* if you ssh into another lab machine, the path name is /anw/software/bin/i686/[autoson command]%0a%0a'''Create a Custom List of Machines: '''To add jobs to a custom subset of machines, separate them with commas in the auadd line like so: ''auadd -hosts @limbic,@arbor,@olive -cyc 1 -lim 30 -log nrn_echo.#.out run_command # ''(following Ash's earlier examples).%0a%0a'''Delete a job: ''' (as of now, Ash can't make auzap work) If a job is running through autoson and you wish to kill it, you have to literally ssh on over to that machine an kill it:%0a# use aulook to see at which machine the job is running%0a# ssh to that machine%0a# use ps x to see what the PID #s related to that job are%0a# kill the PID #s (kill #####)%0a# double check by doing aulook%0a%0a'''To delete a PEND list of jobs: ''' (suppose you typed in "auadd..." and then realized you fucked up):%0a* bring up the augui  (type in >augui &), click on the PEND job (on the left column), press the delete button (on the bottom)%0a* to delete it from the command line, find the job number of the PEND list (type "aulook") and then type this in the command line: aumod -delete -ent ######%0a  * note: do this fast, as the job number associated with the PEND is the number assigned to the next job to be run. If it is running, the number associated with the PEND changes to the next job. To delete a running job, you must ssh into the machine itself and kill it from there (see above). So, the number associated with the PEND changes as jobs are run; you can use this method to delete the PEND list of jobs only if the number actually refers to the PEND list. %0a* Note: if you're out of town you should leave yourself logged in at a physical computer in the lab. That way if you need to delete a PEND job, you can have someone run augui at your computer and delete the job that way.%0a%0a'''Always Define the Shell Variable: ''' for some reason, Ash had problems with the shell variable "TASK_NUM" (click [[here -> http://www-anw.cs.umass.edu/ash_runs_autoson.txt]] to see the shell script). I had to manually ssh to a machine, setenv TASK_NUM to some number, and then the shell script would work. this didn't always happen, but Emily, goddess that she is, suggested that I simply setenv TASK_NUM in my .cshrc file. This seemed to work%0a%0aalso note: in order for you job to be run on a machine through autoson, you must be able to run that job on that machine yourself. For example, Ash cannot run his matlab scripts on machines that he cannot ssh to and run matlab on manually.%0a%0a'''Dealing with LOST jobs: ''' Some hints from Pippin on how to deal with LOST jobs:%0a* Use aumod -ent %3cjob_id> -nolost to return the job to PEND status%0a* Use aumod -ent %3cjob_id> -delete to delete the job (this should work on anything not CURR)%0a* NOTE: this doesn't work with jobs that are still running. It might remove the job from the queue, but it won't actually delete the job. See "Delete a job" above. %0a%0a'''The queue is full of jobs that are hung, or that stopped on that machine, or otherwise are not properly marked.'''  (clean method) auadd -once _getlost -hosts thebe Run for each host where you think there might be an incorrect job. (for the dirty method, see below)%0a%0a'''[[Writing to Local Drives]]'''%0a
time=1212434412
author:1212434412=
diff:1212434412:1211221303:=37a38,48%0a> %0a> '''Jobs are distributed weirdly:''' reboot the machine (doesn't always work)%0a> * example: for some reason, somtimes autoson places more jobs on a machine than there are processors. In the past, autoson would place more than one job on hebb, which only has one processor, and recently, it placed five jobs on flow, which has four processors. %0a> * if you can't reboot the machine, or if that doesn't seem to work, you can avoid the problem this way: %0a> ** keep the machine off any group list you might use%0a> ** auadd only X number of jobs on the machine, where X is the number of processors. For example, I would only put four jobs at a time on flow. This is annoying, but it will prevent placing more jobs on the machine. %0a> * The number of jobs autoson will put on a machine is equal to the number autoson procs running on that machine. I don't know what proc means, but if you ssh into the machine as autouser (ssh autouser@machine), you can type "ps x" the look for output that looks like this: %0a> [@%0a> autouser  3503  0.0  0.0   5824  2264 ?        Ss   13:00   0:00 /anw/software/bin/i686/aurun0 -log /anw/autouser/logs/autoson.flow.cs.umass.edu0.run -noappend%0a> @]%0a> %0a
host:1212434412=128.119.241.208
author:1211221303=
diff:1211221303:1211221278:=48c48,49%0a%3c %0a---%0a> There should only be similar looking lines for each processor...%0a> %0a
host:1211221303=128.119.241.208
author:1211221278=
diff:1211221278:1211221088:=44,49c44%0a%3c * The number of jobs autoson will put on a machine is equal to the number autoson procs running on that machine. I don't know what proc means, but if you ssh into the machine as autouser (ssh autouser@machine), you can type "ps x" the look for output that looks like this: %0a%3c [@%0a%3c autouser  3503  0.0  0.0   5824  2264 ?        Ss   13:00   0:00 /anw/software/bin/i686/aurun0 -log /anw/autouser/logs/autoson.flow.cs.umass.edu0.run -noappend%0a%3c @]%0a%3c There should only be similar looking lines for each processor...%0a%3c %0a---%0a> %0a
host:1211221278=128.119.241.208
author:1211221088=
diff:1211221088:1210948373:=40,44c40,42%0a%3c * example: for some reason, somtimes autoson places more jobs on a machine than there are processors. In the past, autoson would place more than one job on hebb, which only has one processor, and recently, it placed five jobs on flow, which has four processors. %0a%3c * if you can't reboot the machine, or if that doesn't seem to work, you can avoid the problem this way: %0a%3c ** keep the machine off any group list you might use%0a%3c ** auadd only X number of jobs on the machine, where X is the number of processors. For example, I would only put four jobs at a time on flow. This is annoying, but it will prevent placing more jobs on the machine. %0a%3c %0a---%0a> * example: for some reason, autoson sometimes places several jobs at a time onto hebb, even though hebb has only one processor. Something called "autorun0" was starting multiple times. Anyways, rebooting hebb might help, but it's not a definate. To avoid this problem, you can simply submit one job at a time to hebb manually. That takes away most of the advantages of autoson, but it might still be worth it. %0a> * one way to avoid this problem is to keep the offending computers (hebb, in this case) off of any group list you use. Then, run jobs on hebb ONE AT A TIME. True, that's rather annoying and does eliminate some of the advantages of autoson (the whole "set it and forget it" thing), but it's one option. %0a> %0a
host:1211221088=128.119.241.208
author:1210948373=
diff:1210948373:1210795441:=24c24%0a%3c   * note: do this fast, as the job number associated with the PEND is the number assigned to the next job to be run. If it is running, the number associated with the PEND changes to the next job. To delete a running job, you must ssh into the machine itself and kill it from there (see above). So, the number associated with the PEND changes as jobs are run; you can use this method to delete the PEND list of jobs only if the number actually refers to the PEND list. %0a---%0a>   * note: do this fast, as the job number for PEND will be the job number for the actual job when it's running on a machine. Then, you'll have to physically log into that machine to kill the job. The number assigned to PEND will be a new number. %0a
host:1210948373=128.119.241.208
author:1210795441=
diff:1210795441:1210795413:=24c24%0a%3c   * note: do this fast, as the job number for PEND will be the job number for the actual job when it's running on a machine. Then, you'll have to physically log into that machine to kill the job. The number assigned to PEND will be a new number. %0a---%0a>   * note: do this fast, as the job number for PEND will be the job number for the actual job when it's running on a machine. Then, you'll have to physically log into that machine to kill the job.%0a
host:1210795441=128.119.241.208
author:1210795413=
diff:1210795413:1210529882:=22a23%0a> * Note: if you're out of town you should leave yourself logged in at a physical computer in the lab. That way if you need to delete a PEND job, you can have someone run augui at your computer and delete the job that way.%0a24,26c25%0a%3c   * note: do this fast, as the job number for PEND will be the job number for the actual job when it's running on a machine. Then, you'll have to physically log into that machine to kill the job.%0a%3c * Note: if you're out of town you should leave yourself logged in at a physical computer in the lab. That way if you need to delete a PEND job, you can have someone run augui at your computer and delete the job that way.%0a%3c %0a---%0a> %0a
host:1210795413=128.119.241.208
author:1210529882=
diff:1210529882:1210529882:=1,42d0%0a%3c Unless otherwise noted, type the commands in your shell.%0a%3c %0a%3c '''Three simple commands: '''%0a%3c * aulook: lists the job and machine they're running on. %0a%3c * aulook -group or aulook -g : lists every possible machine or group.%0a%3c * [[augui -> http://www-all.cs.umass.edu/augui/augui.html]]: brings up the the graphical interface (written by Amy McGovern)%0a%3c %0a%3c '''Run Autoson Remotely: '''Some people have problems running autoson remotely (i.e. ssh'ing into a lab machine and running autoson commands). That is because there is something weird with how the paths are defined when you ssh into a machine versus when you physically log in to a machine. To run autoson commands remotely, specifiy the full path name or mess with your .cshrc type of file so that it knows to look for those paths when you ssh. I don't know exactly what the problem is, but specifying the full path name is a solution. %0a%3c * if you ssh into entropy, the path name is /anw/software/bin/x86_64/[autoson command]%0a%3c * if you ssh into another lab machine, the path name is /anw/software/bin/i686/[autoson command]%0a%3c %0a%3c '''Create a Custom List of Machines: '''To add jobs to a custom subset of machines, separate them with commas in the auadd line like so: ''auadd -hosts @limbic,@arbor,@olive -cyc 1 -lim 30 -log nrn_echo.#.out run_command # ''(following Ash's earlier examples).%0a%3c %0a%3c '''Delete a job: ''' (as of now, Ash can't make auzap work) If a job is running through autoson and you wish to kill it, you have to literally ssh on over to that machine an kill it:%0a%3c # use aulook to see at which machine the job is running%0a%3c # ssh to that machine%0a%3c # use ps x to see what the PID #s related to that job are%0a%3c # kill the PID #s (kill #####)%0a%3c # double check by doing aulook%0a%3c %0a%3c '''To delete a PEND list of jobs: ''' (suppose you typed in "auadd..." and then realized you fucked up):%0a%3c * bring up the augui  (type in >augui &), click on the PEND job (on the left column), press the delete button (on the bottom)%0a%3c * Note: if you're out of town you should leave yourself logged in at a physical computer in the lab. That way if you need to delete a PEND job, you can have someone run augui at your computer and delete the job that way.%0a%3c * to delete it from the command line, find the job number of the PEND list (type "aulook") and then type this in the command line: aumod -delete -ent ######%0a%3c %0a%3c '''Always Define the Shell Variable: ''' for some reason, Ash had problems with the shell variable "TASK_NUM" (click [[here -> http://www-anw.cs.umass.edu/ash_runs_autoson.txt]] to see the shell script). I had to manually ssh to a machine, setenv TASK_NUM to some number, and then the shell script would work. this didn't always happen, but Emily, goddess that she is, suggested that I simply setenv TASK_NUM in my .cshrc file. This seemed to work%0a%3c %0a%3c also note: in order for you job to be run on a machine through autoson, you must be able to run that job on that machine yourself. For example, Ash cannot run his matlab scripts on machines that he cannot ssh to and run matlab on manually.%0a%3c %0a%3c '''Dealing with LOST jobs: ''' Some hints from Pippin on how to deal with LOST jobs:%0a%3c * Use aumod -ent %3cjob_id> -nolost to return the job to PEND status%0a%3c * Use aumod -ent %3cjob_id> -delete to delete the job (this should work on anything not CURR)%0a%3c * NOTE: this doesn't work with jobs that are still running. It might remove the job from the queue, but it won't actually delete the job. See "Delete a job" above. %0a%3c %0a%3c '''The queue is full of jobs that are hung, or that stopped on that machine, or otherwise are not properly marked.'''  (clean method) auadd -once _getlost -hosts thebe Run for each host where you think there might be an incorrect job. (for the dirty method, see below)%0a%3c %0a%3c %0a%3c '''Jobs are distributed weirdly:''' reboot the machine (doesn't always work)%0a%3c * example: for some reason, autoson sometimes places several jobs at a time onto hebb, even though hebb has only one processor. Something called "autorun0" was starting multiple times. Anyways, rebooting hebb might help, but it's not a definate. To avoid this problem, you can simply submit one job at a time to hebb manually. That takes away most of the advantages of autoson, but it might still be worth it. %0a%3c * one way to avoid this problem is to keep the offending computers (hebb, in this case) off of any group list you use. Then, run jobs on hebb ONE AT A TIME. True, that's rather annoying and does eliminate some of the advantages of autoson (the whole "set it and forget it" thing), but it's one option. %0a%3c %0a%3c '''[[Writing to Local Drives]]'''%0a
host:1210529882=128.119.241.208
